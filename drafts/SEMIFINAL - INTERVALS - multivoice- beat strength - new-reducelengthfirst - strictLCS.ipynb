{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1285b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21 as m21\n",
    "import re\n",
    "from collections import Counter\n",
    "from swalign_local import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1039d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read input data:\n",
    "import music21 as m21\n",
    "import re\n",
    "from collections import Counter\n",
    "from swalign_local import *\n",
    "import csv\n",
    "import glob\n",
    "\n",
    "#score_path = \"jkupddtest/bachmono/wtc2f20.krn\"\n",
    "score_path = \"jkupddtest/beethovenmono/sonata01-3.krn\"\n",
    "#score_path = \"jkupddtest/mozartmono/sonata04-2.krn\"\n",
    "#score_path = \"jkupddtest/gibbonsmono/silverswan.krn\"\n",
    "#score_path = \"jkupddtest/chopinmono/mazurka24-4.krn\"\n",
    "#score_path = '~/facets-search-engine/data/Beethoven9thOdeToJoy.xml'\n",
    "\n",
    "raw_score = m21.converter.parse(score_path)\n",
    "num_of_parts = len(raw_score.parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccee41a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51ea7e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "voices = []\n",
    "for part in raw_score.parts:\n",
    "    voices.append(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acce90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Get diatonic scale degree sequence from all voices\n",
    "\n",
    "def get_diatonic_intervals(voice):\n",
    "    \n",
    "    # get key / root information:\n",
    "    roots = [key.tonic for key in voice.recurse().getElementsByClass(m21.key.Key)]\n",
    "    diatonic_root = roots[0].diatonicNoteNum if roots != [] else voice.analyze('key').tonic.diatonicNoteNum\n",
    "    #print(diatonic_root)\n",
    "    key = voice.analyze('key')\n",
    "\n",
    "    noteoffset = []\n",
    "    midi = []\n",
    "    #timesig = m21_score.getContextByClass(m21.meter.TimeSignature)\n",
    "    #barlength = timesig.barduration\n",
    "\n",
    "    dict_wordtonum = {\"Unison\": '0', \"Second\": '1', \"Third\": '2', \"Fourth\": '3', \"Fifth\": '4', \"Sixth\": '5', \"Seventh\": '6'}\n",
    "        \n",
    "    dict_encode_dia_intervals = {\"6D\": 'A', '5D': 'B', '4D': 'C', '3D':'D', '2D':'E', '1D':'F', \n",
    "                                     '1A':'G', '2A':'H', '3A':'I', '4A':'J', '5A': 'K', '6A':'L', '0A': 'M'}\n",
    "        \n",
    "    diatonic_intervals = []\n",
    "    beatstrength = []\n",
    "    previous_note = None\n",
    "\n",
    "    onset = 0\n",
    "    for thisnote in voice.recurse().notes:\n",
    "        onset += thisnote.offset\n",
    "        \n",
    "        # We ignore rests\n",
    "        if thisnote.isRest: \n",
    "                # If the rest is a full measure, part of a multi-measure rest: we need to adjust\n",
    "                continue\n",
    "        \n",
    "        noteoffset.append(onset)\n",
    "        beatstrength.append(thisnote.beatStrength)\n",
    "        #if thisnote.isNote:\n",
    "        #    midi.append(thisnote.pitch.midi)\n",
    "        #elif thisnote.isChord:\n",
    "        #    midi.append(thisnote.root().midi)\n",
    "            \n",
    "        if previous_note is None:\n",
    "                previous_note = thisnote\n",
    "        else:\n",
    "                if thisnote.isNote and previous_note.isNote:\n",
    "                    # gap = number of semi-tones of the current interval \n",
    "                    gap = thisnote.pitch.diatonicNoteNum - previous_note.pitch.diatonicNoteNum\n",
    "                elif thisnote.isChord and previous_note.isNote:\n",
    "                    gap = thisnote.root().diatonicNoteNum - previous_note.pitch.diatonicNoteNum\n",
    "                elif thisnote.isChord and previous_note.isChord:\n",
    "                    gap = thisnote.root().diatonicNoteNum - previous_note.root().diatonicNoteNum\n",
    "                elif thisnote.isNote and previous_note.isChord:\n",
    "                    gap = thisnote.pitch.diatonicNoteNum - previous_note.root().diatonicNoteNum\n",
    "                # if a pitch change is detected\n",
    "                    \n",
    "                if gap != 0:\n",
    "                    \n",
    "                    if gap > 0:\n",
    "                        #  if the semi-tone difference between the current and the previous item > 0, it is an ascending interval.\n",
    "                        direction = 'A'\n",
    "                    else:\n",
    "                        #  otherwise, it is a descending interval.\n",
    "                        direction = 'D'\n",
    "\n",
    "                    # Get intervals using music21\n",
    "                    \"\"\"\n",
    "                            \"directedSimpleNiceName\" examples: \"Descending Doubly-Diminished Fifth\", \"Ascending Perfect Fourth\", \"Ascending Doubly-Augmented Fourth\"\n",
    "                            \"simpleName\" examples: dd5, P5, AA4. There's no direction information\n",
    "                            Since it only executes when a pitch interval is detected, \"unison\" refers to an augmented unison, a.k.a minor second\n",
    "                    \"\"\"\n",
    "                    # take intervals between root notes if there exists any chord\n",
    "                    if previous_note.isChord:\n",
    "                        startnote = previous_note.root()\n",
    "                    else:\n",
    "                        startnote = previous_note\n",
    "                    if thisnote.isChord:\n",
    "                        endnote = thisnote.root()\n",
    "                    else:\n",
    "                        endnote = thisnote\n",
    "                        \n",
    "                    m21_interval_directed = m21.interval.Interval(noteStart=startnote, noteEnd=endnote).directedSimpleNiceName\n",
    "\n",
    "                    arr_diatonic = m21_interval_directed.split(\" \")\n",
    "\n",
    "                    m21_generic = dict_wordtonum[arr_diatonic[-1]]\n",
    "                    \n",
    "                    # m21_interval: 2A, 3D etc...\n",
    "                    m21_interval = m21_generic+direction\n",
    "                    if m21_generic == \"0\":\n",
    "                        m21_interval = '0A'\n",
    "                    # to make each m21_interval unique, show direction and each as single character in string, we encode the diatonic intervals as letters\n",
    "                    encode_interval = dict_encode_dia_intervals[m21_interval]\n",
    "                    diatonic_intervals.append(encode_interval)\n",
    "\n",
    "                else:\n",
    "                    # We take the interval between two consecutive pitches as 0A\n",
    "                    encode_interval = dict_encode_dia_intervals['0A']\n",
    "                    diatonic_intervals.append(encode_interval)\n",
    "                previous_note = thisnote\n",
    "            \n",
    "    string = \"\"\n",
    "    for i in diatonic_intervals:\n",
    "        string += str(i)\n",
    "        \n",
    "    return string, key, noteoffset, midi, beatstrength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aea3f3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677 678\n",
      "GEGEMDIDLFHMGEGEMDIDLFHMIJMMBGGIFFIBHDGLFBHDGMGEGEMDIDLFHMGEGEMDIDLFHMIJMMBGGIFFIBHDGLFBHDGHGEGEJEGEMHDGKFCHDGHFFHFFHFFGGFFGFFFGFFFGGFHAGHGHHFGGEMFGGEMFGGEMFGGEMMHDGFFBHDGDCJGEGEJEGEMHDGKFCHDGHFFHFFHFFGGFFGFFFGFFFGGFHAGHGHHFGGEMFGGEMFGGEMFGGEMMHDGFFBHDGDCJKFGEGGGFGEGGGFGGFFFFGGFEHHIBFJHALFBJFCFHEEFHFMKFGEGGGFGEGGGFGGFFFFGGFEHHIBFJHALFBJFCFHEEFHFMHFGEGGGFGEGGGFGEGGGEHHIHBFMEGGGFGEGGHGGDFGEGGJFGEGGGFFGFFFGFFFGFFCIFGEGGGFGEGGGFGGFFFFGGFEHHIECFFHICDHFGEGGGFGEGGGFGEGGGEHHIHBFMEGGGFGEGGHGGDFGEGGJFGEGGGFFGFFFGFFFGFFCIFGEGGGFGEGGGFGGFFFFGGFEHHIECFFHICHGEGEMDIDLFHMGEGEMDIDLFHMIJMMBGGIFFIBHDGLFBHDGHGEGEJEGEMHDGKFCHDGHFFHFFHFFGGFFGFFFGFFFGGFHAGHGHHFGGEMFGGEMFGGEMFGGEMMHDGFFBHDGDC\n",
      "678\n",
      "[0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.25, 1.0, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.25, 1.0, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.25, 1.0, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0]\n",
      "549 550\n",
      "MGFFGBMGFFGHFFFGGGBIHBIEMGFFGBMGFFGHFFFGGGBIHBIFHFHEHFHMBIHBIDIDIHFFGGFFGFFFGFFFGGFHAGMKGEMGEMFHMFHKFMMGHMAMLGAMKEBBIDIGHFHEHFHMBIHBIDIDIHFFGGFFGFFFGFFFGGFHAGMKGEMGEMFHMFHKFMMGHMAMLGAMKEBBIDIMHHGCFFHICHHEFGEGGGFGEGGGFGEGGGDGEICGMIMIHHGCFFHICHHEFGEGGGFGEGGGFGEGGGDGEICGMIMMMLALAKBHFGEGGGFGEGGGFGEGGGFGEGGGFGEGGGFGEGGGFFGFFFGFFFGFFFCHHGCFFHICHHEFGEGGGFGEGGGFGFFFFMJMLALAKBHFGEGGGFGEGGGFGEGGGFGEGGGFGEGGGFGEGGGFFGFFFGFFFGFFFCHHGCFFHICHHEFGEGGGFGEGGGFGFFFFMMMGFFGBMGFFGHFFFGGGBIHBIFHFHEHFHMBIHBIDIDIHFFGGFFGFFFGFFFGGFHAGMKGEMGEMFHMFHKFMMGHMAMLGAMKEBBIDI\n",
      "550\n",
      "[0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "strings = []\n",
    "noteoffsets = []\n",
    "midis = []\n",
    "keys = []\n",
    "beatstrengths = []\n",
    "\n",
    "for voice in voices:\n",
    "    string, key, noteoffset, midi, beatstrength = get_diatonic_intervals(voice)\n",
    "    strings.append(string)\n",
    "    noteoffsets.append(noteoffset)\n",
    "    beatstrengths.append(beatstrength)\n",
    "    midis.append(midi)\n",
    "    keys.append(key)\n",
    "    print(len(string), len(beatstrength))#, len(midi))\n",
    "    print(string)\n",
    "    print(len(noteoffset))\n",
    "    #print(midi)\n",
    "    print(beatstrength)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a08b5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smith-Waterman alignment between the two input sequences\n",
    "def swm_alignment(string1, string2):\n",
    "    match = 2\n",
    "    mismatch = -2\n",
    "    scoring = NucleotideScoringMatrix(match, mismatch)\n",
    "    sw = LocalAlignment(scoring)#, gap_extension_penalty = -5) \n",
    "    \n",
    "    alignment = sw.align(string1, string2)\n",
    "    alignment_strings = alignment.dump()\n",
    "\n",
    "    simi_score = alignment.matches / (alignment.mismatches + alignment.matches)\n",
    "    \n",
    "    return alignment_strings, simi_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94591d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_gather_patterns(allthepatterns, fullseq):\n",
    "    pat = fullseq.split('-')\n",
    "    print(\"num of pat in this seq:\", len(pat))    \n",
    "    for pattern in pat:\n",
    "        # Get rid of the sequence shorter than 4; combine all alignment patterns into all pattern list\n",
    "        if len(pattern) > 2:\n",
    "            allthepatterns.append(pattern)\n",
    "    return allthepatterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ab996d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  66 HFFGGFFGFFFGFFFGGFHAGMKG-----EM--GEMF--HMFHKFMM--G---HMAMLG----------AM---KEBBIDIGH-FHEHFHMBIHBIDIDIHFFGGFFGFFFGFFFGGFHAGMKG-----EM--GEMF--HMFHKFMMGHMAMLGAMKEBBIDIMHHGCFF-H--ICHHEFGEGGGFGEGGGFGEG----GGDGEICGMIMIHHGCFFH-----IC-HHEF-----GEGGGFGEGGGFGEG----GGDGE--ICGMIMMMLALAKB----H--F-----GEGGGFGEGGGFGEGGG------FGEGGGFGEGG--G-FGEGGGFFG---FFFGFFFGFFFCHHGCFFHICHHEFGEGGGFGEGGGF-GFFFFMJMLALAKBH----F------GEGGGFGEGGGFGEGGG------FGEGGGFGEGG--G-FGEGGGFFG---FFFGFFFGFFFCHHGCFFHICHHEFGEGGGFGEGGGF-GFFFFMMMGFFGBMGFFGH---FF---FG-G---------G----BI---H-----B--I-F--H---F-H----E-------H---F-HMBIHBIDIDIHFF------GGFFGFFFGFFFGGFHAGMKG-----EM--GEMF--HMF 528\n",
      "           ||||||||||||||||||||| .|     ||  ||||  .||...||  |   |   .|          .|   | ...| || || .||           |||||||||||||||||||| .|     ||  ||||  .||     |     |.|       ||.| || |  .| ..|||||||||||||| |    || .|       ||..|.|     .| |.||     ||||||||||||| |    || .|  |    ....|| .|    |  |     |||||||||||||||||      |.|||||||||  | ||| ||.||   .||||||||||   | ||  |  .||||||||||||| |||||    .....|    |      |||||||||||||||||      |.|||||||||  | ||| ||.||   .||||||||||   | ||  |  .||||||||||||| |||||   |  |   |..|   ||   .| |         |    .|   |     |  | |  |   | |    |       |   | |      |  .|||      |||||||||||||||||| .|     ||  ||||  .||\n",
      "Ref  : 117 HFFGGFFGFFFGFFFGGFHAG-HGHHFGGEMFGGEMFGGEMFGGEMMHDGFFBH---DGDCJGEGEJEGEMHDGK-FCHD-GHFFH-FFH-----------FFGGFFGFFFGFFFGGFHAG-HGHHFGGEMFGGEMFGGEMF-----G-----GEM-------MHDG-FFBHDGDC-JKFGEGGGFGEGGGFG-GFFFFGG-FE-------HHIBFJHALFBJFCFHEEFHFMKFGEGGGFGEGGGFG-GFFFFGG-FEHHI----BFJHAL-FBJFCFHEEFHFMHFGEGGGFGEGGGFGEGGGEHHIHBFMEGGGFGEGGHGGDFGE-GGJFGEGGGFFGFFFGFFF---G-FF--C--IFGEGGGFGEGGGFGGFFFF----GGFEHHIECFFHICDHFGEGGGFGEGGGFGEGGGEHHIHBFMEGGGFGEGGHGGDFGE-GGJFGEGGGFFGFFFGFFF---G-FF--C--IFGEGGGFGEGGGFGGFFFF---G--G---FEHHIECFFHICHGEGEMDIDLFHMGEGEMDIDLFHMIJMMBGGIFFIBHDGLFBHDGHGEGEJEGEMHDGKFCH------D--GHFFHFFHFFGGFFGFFFGFFFGGFHAG-HGHHFGGEMFGGEMFGGEMF 661\n",
      "\n",
      "num of pat in this seq: 233\n",
      "num of pat in this seq: 215\n"
     ]
    }
   ],
   "source": [
    "# compare each pair of voices!\n",
    "allthepatterns = []\n",
    "\n",
    "for i in range(0, len(voices)-1):\n",
    "    for j in range(i+1, len(voices)):\n",
    "        alignment_strings, simi_score = swm_alignment(strings[i], strings[j])\n",
    "        if simi_score < 0.25:\n",
    "            print(\"ignoring voice pair:\", i, j)\n",
    "            # if two voices are very different, getting patterns from their alignment won't make sense\n",
    "            continue\n",
    "        # get the patterns from the first voice of this pair\n",
    "        fullseq1 = alignment_strings[0]\n",
    "        fullseq2 = alignment_strings[1]\n",
    "        #print(\"len:\", len(fullseq1), len(fullseq2))\n",
    "        \n",
    "        # what if we make sure to segment whenever there's not identical items\n",
    "        newseq1 = fullseq1[0]\n",
    "        newseq2 = fullseq2[0]\n",
    "        for temp in range(1, len(fullseq1)):\n",
    "            if fullseq1[temp] == '-' and fullseq1[temp-1] == '-':\n",
    "                newseq2+='-'\n",
    "            else:\n",
    "                newseq2+=fullseq2[temp]\n",
    "            if fullseq2[temp] == '-' and fullseq2[temp-1] == '-':\n",
    "                newseq1+='-'\n",
    "            else:\n",
    "                newseq1+=fullseq1[temp]\n",
    "        \n",
    "        allthepatterns = filter_and_gather_patterns(allthepatterns, newseq1)\n",
    "        allthepatterns = filter_and_gather_patterns(allthepatterns, newseq2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fb60700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638 638\n",
      "638 638\n",
      "HFFGGFFGFFFGFFFGGFHAGMKG-----EM--GEMF--HMFHKFMM--G---HM--LG----------AM---KEBBIDIGH-FHEHFHM----------FFGGFFGFFFGFFFGGFHAGMKG-----EM--GEMF--HMFH----GH----GAMK------MHHGCFF-H--ICHHEFGEGGGFGEGGGFGEG----GGDGEI------HHGCFFH-----IC-HHEF-----GEGGGFGEGGGFGEG----GGDGE--IC---MMMLALAKB----H--F-----GEGGGFGEGGGFGEGGG------FGEGGGFGEGG--G-FGEGGGFFG---FFFGFFFGFFFC--GCFFH-CH-EFGEGGGFGEGGGF-GFFFFM---ALAKBH----F------GEGGGFGEGGGFGEGGG------FGEGGGFGEGG--G-FGEGGGFFG---FFFGFFFGFFFC--GCFFH-CH-EFGEGGGFGEGGGF-GFFFFM--GF-GB--FFGH---FF---FG-G---------G----BI---H-----B--I-F--H---F-H----E-------H---F-HM-----DI-IHFF------GGFFGFFFGFFFGGFHAGMKG-----EM--GEMF--HMF\n",
      "\n",
      "\n",
      "HFFGGFFGFFFGFFFGGFHAG-HGH----EMF-GEMFG-EMFGGEMMH-GF--H---DGD---------EMH--K-FCHD-GHFFH-FFH-----------FFGGFFGFFFGFFFGGFHAG-HGH----EMF-GEMFG-EMF-----G-----GEM-------MHDG-FFBHD-DC-JKFGEGGGFGEGGGFG-GF---GG-FE-------HHIBFJHA----FCFHEEFH----GEGGGFGEGGGFG-GF---GG-FEH-I----BFJHAL-FBJ---HE-FH----GEGGGFGEGGGFGEGGGE-----FMEGGGFGEGGH-GDFGE-GGJFGE--GFFGFFFGFFF---G-FF--C--IFGEGGGFGEGGGFGGFFFF----GGFEHHI---FH-----GEGGGFGEGGGFGEGGGE-----FMEGGGFGEGGH-GDFGE-GGJFGE--GFFGFFFGFFF---G-FF--C--IFGEGGGFGEGGGFGGFFFF---G--G---FEHHI--FFH--HGEGE--------GE---DID--HM----BG-IFFI-HD--FBHD---EG------HD--FCH------D--GHFFH-----GGFFGFFFGFFFGGFHAG-HGH----EMF-GEMFG-EMF\n"
     ]
    }
   ],
   "source": [
    "print(len(fullseq1), len(fullseq2))\n",
    "print(len(newseq1), len(newseq2))\n",
    "print(newseq1)\n",
    "print('\\n')\n",
    "print(newseq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf861fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "allthepattern_count = dict(Counter(allthepatterns))\n",
    "# elimiate the repeated strings\n",
    "\n",
    "allthepatterns = list(set(allthepatterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c01a5bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allthepatterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01a18847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_substringandparents(allthepatterns, allthepattern_count):\n",
    "    \n",
    "    issubstring = {}\n",
    "    hassubstring = {}\n",
    "    count_as_substring = {}\n",
    "    count_as_parent = {}\n",
    "\n",
    "    for i in range(0, len(allthepatterns)-1):\n",
    "        for j in range(i+1, len(allthepatterns)):\n",
    "            if allthepatterns[i] in allthepatterns[j]:\n",
    "                parent = allthepatterns[j]\n",
    "                kid = allthepatterns[i]\n",
    "                times = parent.count(kid)\n",
    "\n",
    "                if kid not in issubstring:\n",
    "                    issubstring[kid] = 1\n",
    "                    count_as_substring[kid] = times * allthepattern_count[parent]\n",
    "                else:\n",
    "                    issubstring[kid] += 1\n",
    "                    count_as_substring[kid] += times * allthepattern_count[parent]\n",
    "\n",
    "                if parent not in hassubstring:\n",
    "                    hassubstring[parent] = 1\n",
    "                    count_as_parent[parent] = 1#times\n",
    "                else:\n",
    "                    hassubstring[parent] += 1\n",
    "                    count_as_parent[parent] += 1 \n",
    "\n",
    "            elif allthepatterns[j] in allthepatterns[i]:\n",
    "                parent = allthepatterns[i]\n",
    "                kid = allthepatterns[j]\n",
    "                times = parent.count(kid)\n",
    "\n",
    "                if kid not in issubstring:\n",
    "                    issubstring[kid] =1\n",
    "                    count_as_substring[kid] = times * allthepattern_count[parent]\n",
    "                else:\n",
    "                    issubstring[kid] += 1\n",
    "                    count_as_substring[kid] += times * allthepattern_count[parent]\n",
    "\n",
    "                if parent not in hassubstring:\n",
    "                    hassubstring[parent] = 1\n",
    "                    count_as_parent[parent] = 1 #times\n",
    "                else:\n",
    "                    hassubstring[parent] += 1\n",
    "                    count_as_parent[parent] += 1 #times\n",
    "\n",
    "    return issubstring, hassubstring, count_as_substring, count_as_parent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a53e7221",
   "metadata": {},
   "outputs": [],
   "source": [
    "issubstring, hassubstring, count_as_substring, count_as_parent = count_substringandparents(allthepatterns, allthepattern_count)\n",
    "onlyassubstring = set(issubstring) - set(hassubstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2922422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_strings(string):\n",
    "    \n",
    "    decode_dia_intervals = {'A': '6D', 'B': '5D', 'C': '4D', 'D': '3D', 'E': '2D', 'F': '1D', \n",
    "                            'G': '1A', 'H': '2A', 'I': '3A', 'J': '4A', 'K': '5A', 'L': '6A', 'M': '0A'}\n",
    "    \n",
    "    decode_string = \"\"\n",
    "\n",
    "    for letter in string:\n",
    "        trans = decode_dia_intervals[letter]\n",
    "        decode_string+=trans\n",
    "\n",
    "    return decode_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5d072e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printLCSSubStr(X: str, Y: str,\n",
    "                   m: int, n: int):\n",
    " \n",
    "    # Create a table to store lengths of longest common suffixes of substrings.\n",
    "    # Note that LCSuff[i][j] contains length of longest common suffix of X[0..i-1] and\n",
    "    # Y[0..j-1]. The first row and first column entries have no logical meaning,\n",
    "    # they are used only for simplicity of program\n",
    "    LCSuff = [[0 for i in range(n + 1)]\n",
    "                 for j in range(m + 1)]\n",
    " \n",
    "    # To store length of the\n",
    "    # longest common substring\n",
    "    length = 0\n",
    " \n",
    "    # To store the index of the cell\n",
    "    # which contains the maximum value.\n",
    "    # This cell's index helps in building\n",
    "    # up the longest common substring\n",
    "    # from right to left.\n",
    "    row, col = 0, 0\n",
    " \n",
    "    # Following steps build LCSuff[m+1][n+1]\n",
    "    # in bottom up fashion.\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if i == 0 or j == 0:\n",
    "                LCSuff[i][j] = 0\n",
    "            elif X[i - 1] == Y[j - 1]:\n",
    "                LCSuff[i][j] = LCSuff[i - 1][j - 1] + 1\n",
    "                if length < LCSuff[i][j]:\n",
    "                    length = LCSuff[i][j]\n",
    "                    row = i\n",
    "                    col = j\n",
    "            else:\n",
    "                LCSuff[i][j] = 0\n",
    " \n",
    "    # if true, then no common substring exists\n",
    "    if length == 0:\n",
    "        #print(\"No common substring\")\n",
    "        return \"\"\n",
    " \n",
    "    # allocate space for the longest\n",
    "    # common substring\n",
    "    resultStr = ['0'] * length\n",
    " \n",
    "    # traverse up diagonally form the\n",
    "    # (row, col) cell until LCSuff[row][col] != 0\n",
    "    while LCSuff[row][col] != 0:\n",
    "        length -= 1\n",
    "        resultStr[length] = X[row - 1] # or Y[col-1]\n",
    " \n",
    "        # move diagonally up to previous cell\n",
    "        row -= 1\n",
    "        col -= 1\n",
    " \n",
    "    # required longest common substring\n",
    "    return ''.join(resultStr) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "164a2096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_pattern_length(seq):\n",
    "        # the function returns the longest substring that appeared at least once\n",
    "        # if there is length 4 substring repeated 4 times and a length 7 substring repeated 2 times, we take the length 7\n",
    "        best_performance = \"\"\n",
    "        candidates = []\n",
    "        for length in range(int(0.3*len(seq)), int(len(seq)*0.5)+1): \n",
    "            for start in range(0, len(seq)-length):\n",
    "                # get all the substrings of this length within the string, save in candidates\n",
    "                candidates.append(seq[start:start+length])\n",
    "        count_can = {}\n",
    "        allthepattern_count = dict(Counter(allthepatterns))\n",
    "\n",
    "        for candidate in candidates:\n",
    "                count_can[candidate] = seq.count(candidate)\n",
    "                if count_can[candidate] > 1:\n",
    "                    # if it is repeated more than once in the string\n",
    "                    if len(candidate) > len(best_performance):\n",
    "                        best_performance = candidate\n",
    "                    elif len(candidate) == len(best_performance) and count_can[candidate] > count_can[best_performance]:\n",
    "                        best_performance = candidate\n",
    "        \n",
    "        return best_performance\n",
    "\n",
    "def check_reduction(item):\n",
    "    success = False\n",
    "    frequent_substr = reduce_pattern_length(item)\n",
    "    if len(frequent_substr) > 4 and len(frequent_substr) > 0.3*len(item):\n",
    "        print(\"extracted\", frequent_substr, \"from\", item)\n",
    "        # sucessfully reduced the pattern\n",
    "        return frequent_substr\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59573055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_length_of_each_pattern(onlyassubstring, patterns_to_reduce):\n",
    "    beforereduction = {}\n",
    "    # reducedfinalpat is the new list that contains all valid patterns after reduction plus the ones that does not need to be reduced\n",
    "    reducedfinalpat = []\n",
    "\n",
    "    for item in patterns_to_reduce:\n",
    "        # check the ones that has substring, see if their length can be reduced\n",
    "        if len(item) > 11  and item not in onlyassubstring:\n",
    "            #if the extracted pattern is too long, find longest repeated pattern within it\n",
    "            frequent_substr = check_reduction(item)\n",
    "            if frequent_substr != None:\n",
    "                if len(frequent_substr) > 23:\n",
    "                    # second attempt, if a frequent substring is takend and it is still quite long\n",
    "                    new_frequent_substr = check_reduction(frequent_substr)\n",
    "                    if new_frequent_substr != None:\n",
    "                        # if the second attempt is a success, take the twice reduced pattern\n",
    "                        reducedfinalpat.append(new_frequent_substr)\n",
    "                        beforereduction[new_frequent_substr] = item\n",
    "                    else:\n",
    "                        # if the second attempt failed, take the result of first reduction\n",
    "                        reducedfinalpat.append(frequent_substr)\n",
    "                        beforereduction[frequent_substr] = item\n",
    "                else:\n",
    "                    # if the extracted pattern is already not very long\n",
    "                    reducedfinalpat.append(frequent_substr)\n",
    "                    beforereduction[frequent_substr] = item\n",
    "            else:\n",
    "                # if the reduction failed, take the original\n",
    "                reducedfinalpat.append(item)\n",
    "        else:\n",
    "            # otherwise keep it without reduction\n",
    "            reducedfinalpat.append(item)\n",
    "    \n",
    "    return reducedfinalpat, beforereduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "415284e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted FGEGGG from EFGEGGGFGEGGGF\n",
      "extracted GEGGGF from GEGGGFGEGGGFGEGGG\n"
     ]
    }
   ],
   "source": [
    "reducedpat, beforereduction = reduce_length_of_each_pattern(onlyassubstring, allthepatterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "7df8d5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GGFFGFFFGFFFGGFHAG 1A1A1D1D1A1D1D1D1A1D1D1D1A1A1D2A6D1A 2\n"
     ]
    }
   ],
   "source": [
    "lcscount = {}\n",
    "dictoflcs = {}\n",
    "for i in range(0, len(reducedpat)-1):\n",
    "    for j in range(i+1, len(reducedpat)):\n",
    "        #print(i, j)\n",
    "        pat1 = reducedpat[i]\n",
    "        pat2 = reducedpat[j]\n",
    "        if len(pat1) > 11 and len(pat2) > 11 and pat1 != pat2:\n",
    "            lcs = printLCSSubStr(pat1, pat2, len(pat1), len(pat2))\n",
    "            if len(lcs) >= 4: # this can change... I guess? but better not\n",
    "                if pat1 not in dictoflcs:\n",
    "                    dictoflcs[pat1] = []\n",
    "                if pat2 not in dictoflcs:\n",
    "                    dictoflcs[pat2] = []\n",
    "                dictoflcs[pat1].append(lcs)\n",
    "                dictoflcs[pat2].append(lcs)\n",
    "                if lcs in lcscount:\n",
    "                    lcscount[lcs] +=1\n",
    "                else:\n",
    "                    lcscount[lcs] = 1\n",
    "\n",
    "newdict = {}\n",
    "# print out the common strings that appeared more than 3 times\n",
    "for temp in lcscount:\n",
    "    if lcscount[temp] >= 2:\n",
    "        if temp not in reducedpat:\n",
    "            print(\"new pattern:\")\n",
    "        newdict[temp] = lcscount[temp]\n",
    "        print(temp, decode_strings(temp), lcscount[temp])\n",
    "\n",
    "# note to self: many of them are substring of themselves, take the longer or shorter?\n",
    "# take the shorter ones and elimiate the longer ones can be practical but can miss information..\n",
    "# only for the ones that are not reduceable? only between long strings? does it make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "13a49f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for pattern: GEGGGF\n",
      "was reduced from GEGGGFGEGGGFG\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: MHHG\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: FFGH\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: HFH\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: FGEGGG\n",
      "was reduced from EFGEGGGFGEGGGF\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: HMF\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: ALAKBH\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: HFFGGFFGFFFGFFFGGFHAG\n",
      "best lcs: \n",
      "for pattern: HMFHKFMM\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: FFGGFFGFFFGFFFGGFHAG\n",
      "best lcs: \n",
      "for pattern: FGEGGGFGEGG\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: FGEGGG\n",
      "was reduced from EFGEGGGFGEGGGF\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: IHFF\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: GGFFG\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: HHEF\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: MMMLAL\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: GAM\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: BBID\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: FFFGFFFGFFF\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: FGE\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: HHGCFFH\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: GFFFF\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: GGFFGFFFGFFFGGFHAG\n",
      "best lcs: \n",
      "for pattern: GEMF\n",
      "no lcs that is longer than 4 for this pattern\n",
      "for pattern: GEGGGF\n",
      "was reduced from GEGGGFGEGGGFG\n",
      "no lcs that is longer than 4 for this pattern\n"
     ]
    }
   ],
   "source": [
    "bestlcss=[]\n",
    "for pattern in reducedpat:\n",
    "    #if len(pattern) > 11:\n",
    "        print(\"for pattern:\", pattern)\n",
    "        if pattern in beforereduction:\n",
    "            print(\"was reduced from\", beforereduction[pattern])\n",
    "        if pattern in dictoflcs:\n",
    "            baseline = 2\n",
    "            bestlcs = \"\"\n",
    "            for lcs in dictoflcs[pattern]:\n",
    "                #print(lcs, lcscount[lcs])\n",
    "                if lcscount[lcs] > baseline and len(lcs) > len(bestlcs):\n",
    "                    bestlcs = lcs\n",
    "                    baseline = lcscount[lcs]\n",
    "            print(\"best lcs:\", bestlcs)\n",
    "            if bestlcs!= \"\":\n",
    "                bestlcss.append(bestlcs)\n",
    "        else:\n",
    "            print(\"no lcs that is longer than 4 for this pattern\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "293bd700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcstaken = list(set(bestlcss))\n",
    "lcstaken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "37c72d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testpat, count_pattern_test, startonsetstest,  endonsetstest = count_final_pattern(lcstaken, strings, beatstrengths)\n",
    "testpat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "2980dc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern GGFFGFFFGFFFGGFHAG appears in voice no. 1 , first pos starts at  119 end at 137\n",
      "Pattern GGFFGFFFGFFFGGFHAG appears in voice no. 2 , first pos starts at  68 end at 86\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['GGFFGFFFGFFFGGFHAG']"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newlist = list(newdict)\n",
    "testpat, count_pattern_test, startonsetstest,  endonsetstest = count_final_pattern(newlist, strings, beatstrengths)\n",
    "testpat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "aa51fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_pattern_count = dict(Counter(reducedpat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "9194c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pattern in reducedpat:\n",
    "    if pattern in beforereduction:\n",
    "        # if it was reduced, then it at least appeared more than once in the original string, \n",
    "        # which should be extrac counted here\n",
    "        reduced_pattern_count[pattern] +=1\n",
    "        if pattern in allthepattern_count:\n",
    "            # if it was also originally a pattern\n",
    "            reduced_pattern_count[pattern]+=allthepattern_count[pattern]-1\n",
    "    else:\n",
    "        reduced_pattern_count[pattern]+=allthepattern_count[pattern]-1\n",
    "        # if it was not reduced, let's check if it was repeated at first, we should add them here minus the once that is counted already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "6f7546d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "issubstring, hassubstring, count_as_substring, count_as_parent = count_substringandparents(reducedpat, reduced_pattern_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "2695cea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# rank the ones that are substrings of another detected pattern\n",
    "sortis = dict(Counter(issubstring))\n",
    "sorthas = dict(Counter(hassubstring))\n",
    "print(len(sorthas))\n",
    "print(len(sortis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "7579ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This counts the times each pattern appeared after original segmentation plus the times they are in other patterns,\n",
    "# plus the times other patterns showed up in them.\n",
    "\n",
    "def combined_count(sorthas, sortis, count_as_parent, count_as_substring, reduced_pattern_count):\n",
    "    refined_combined = {}\n",
    "\n",
    "    for item in reducedpat:\n",
    "        refined_combined[item] = reduced_pattern_count[item]\n",
    "        if item in count_as_parent:\n",
    "            refined_combined[item]+=count_as_parent[item]\n",
    "        if item in count_as_substring:\n",
    "            refined_combined[item]+=count_as_substring[item]\n",
    "    \"\"\"\n",
    "    refined_combined = {}\n",
    "\n",
    "    for item in sorthas:\n",
    "        if item in sortis:\n",
    "            # the ones that has substring and also are the substrings\n",
    "            refined_combined[item] = count_as_parent[item] + count_as_substring[item] + reduced_pattern_count[item]\n",
    "        else:\n",
    "            # the ones that has substrings\n",
    "            refined_combined[item] = count_as_parent[item] + reduced_pattern_count[item]\n",
    "    # the patterns that are substrings of other patterns but none of the others are substrings of it\n",
    "    for item in sortis:\n",
    "        if item not in refined_combined:\n",
    "            refined_combined[item] = count_as_substring[item] + reduced_pattern_count[item]\n",
    "        # otherwise is already counted\n",
    "    \"\"\"\n",
    "    return refined_combined\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "a213b4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined_count(sorthas, sortis, count_as_parent, count_as_substring, reduced_pattern_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "3ed173cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_combined_patterns(combined):\n",
    "    \n",
    "    finalpattern = []\n",
    "    for i in combined: \n",
    "\n",
    "        if len(i) < 3:\n",
    "            # if the length is shorter than 4 notes, discard\n",
    "            continue\n",
    "\n",
    "        if combined[i] > 1:\n",
    "            # keep the ones that has substring or is substring more than once\n",
    "            finalpattern.append(i)\n",
    "\n",
    "    finalpattern_combined = {}\n",
    "        \n",
    "    for thisone in finalpattern:\n",
    "        finalpattern_combined[thisone] = combined[thisone]\n",
    "\n",
    "    dict(Counter(finalpattern_combined))\n",
    "        \n",
    "    if len(finalpattern) > 30:\n",
    "        # if more than 30 patterns, only take the top 30\n",
    "        finalpattern_combined = dict(sorted(finalpattern_combined.items(), key = lambda x:-x[1], reverse = True)[-20:])\n",
    "    \n",
    "    return finalpattern_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "4be71143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the short ones\n",
    "top20patterns_combined = filter_combined_patterns(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "3d8ef126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FMMMIMDI': 3, 'MMMM': 2, 'IMDI': 2, 'MMM': 3}\n"
     ]
    }
   ],
   "source": [
    "print(dict(Counter(top20patterns_combined)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "17194f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D0A0A0A3A0A3D3A\n",
      "0A0A0A0A\n",
      "3A0A3D3A\n",
      "0A0A0A\n"
     ]
    }
   ],
   "source": [
    "for printpattern in list(top20patterns_combined):\n",
    "    print(decode_strings(printpattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "2c321d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3A0A3D3A\n",
      "1D5A0A5D3A\n",
      "1D0A0A0A3A0A3D3A\n",
      "0A0A5D0A\n",
      "0A0A0A\n",
      "0A4A0A\n",
      "0A2D0A\n",
      "0A0A0A0A\n",
      "0A1A0A\n"
     ]
    }
   ],
   "source": [
    "for printpattern in reducedpat:\n",
    "    print(decode_strings(printpattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "42b4c71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the followings are not ranked well thus discarded in the count\n",
      "1D5A0A5D3A\n",
      "0A0A5D0A\n",
      "0A4A0A\n",
      "0A2D0A\n",
      "0A1A0A\n"
     ]
    }
   ],
   "source": [
    "print(\"the followings are not ranked well thus discarded in the count\")\n",
    "for i in reducedpat:\n",
    "    if i not in top20patterns_combined:\n",
    "        print(decode_strings(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "fa53f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pattern_pos(string, pattern, beatstrength):\n",
    "    patpos_start = []\n",
    "    patpos_end = []\n",
    "    count = 0\n",
    "    beatcount = 0\n",
    "    for m in re.finditer(pattern, string):\n",
    "        count +=1\n",
    "        if beatstrength[m.start()] == 1: # if it starts in the beginning of the score, exception\n",
    "            beatcount += 1\n",
    "        elif m.start() < 8: # if it starts in the beginning for two times, also count\n",
    "            beatcount += 0.5\n",
    "        patpos_start.append(m.start())\n",
    "        patpos_end.append(m.end())\n",
    "    return patpos_start, patpos_end, count, beatcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "527abc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_final_pattern(reducedfinalpat, strings, beatstrengths):\n",
    "\n",
    "    count_pattern = {}\n",
    "    refined_finalpat = []\n",
    "    startonsets = []\n",
    "    startpitches = []\n",
    "    endonsets = []\n",
    "    endpitches = []\n",
    "\n",
    "    for pattern in reducedfinalpat:\n",
    "        stringnum = 0\n",
    "        beat_importance = 0\n",
    "        for string in strings:\n",
    "            # find the pattern in eachvoice\n",
    "            patpos_start, patpos_end, count, beatcount = find_pattern_pos(string, pattern, beatstrengths[stringnum])\n",
    "            beat_importance += beatcount\n",
    "            if pattern not in count_pattern:\n",
    "                count_pattern[pattern] = count\n",
    "            else:\n",
    "                count_pattern[pattern] += count\n",
    "            if count != 0:\n",
    "                print(\"Pattern\", pattern, \"appears in voice no.\", stringnum+1, \", first pos starts at \", patpos_start[0], \"end at\", patpos_end[0])\n",
    "            num = 0\n",
    "            for startpos in patpos_start:\n",
    "                startonsets.append(noteoffsets[stringnum][startpos])\n",
    "                endonsets.append(noteoffsets[stringnum][patpos_end[num]])\n",
    "                num+=1\n",
    "            stringnum+=1\n",
    "        if count_pattern[pattern] >= 2 and beat_importance >= 1:\n",
    "            # get rid of the ones that actually appeared less than 2 times in total\n",
    "            refined_finalpat.append(pattern)\n",
    "        else:\n",
    "            if count_pattern[pattern] < 2:\n",
    "                print(\"discard pattern\", pattern, \"because it only appered once in total.\")\n",
    "            elif beat_importance == 0:\n",
    "                print(\"discard pattern\", pattern, \"because it never appeared at the start of a bar.\")\n",
    "                print(\"this pattern can be decoded as\", decode_strings(pattern))\n",
    "            \n",
    "    return refined_finalpat, count_pattern, startonsets, endonsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "d10503af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern FMMMIMDI appears in voice no. 2 , first pos starts at  452 end at 460\n",
      "discard pattern FMMMIMDI because it only appered once in total.\n",
      "Pattern MMMM appears in voice no. 1 , first pos starts at  0 end at 4\n",
      "Pattern MMMM appears in voice no. 2 , first pos starts at  481 end at 485\n",
      "Pattern IMDI appears in voice no. 2 , first pos starts at  247 end at 251\n",
      "Pattern MMM appears in voice no. 1 , first pos starts at  0 end at 3\n",
      "Pattern MMM appears in voice no. 2 , first pos starts at  39 end at 42\n"
     ]
    }
   ],
   "source": [
    "#finalpat, count_pattern, startonsets,  endonsets = count_final_pattern(reducedfinalpat, strings, beatstrengths)\n",
    "#\n",
    "finalpat, count_pattern, startonsets,  endonsets = count_final_pattern(list(top20patterns_combined), strings, beatstrengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "2aacc75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_results(finalpat, count_pattern, combined, beforereduction):\n",
    "    \n",
    "    decoded_patterns = []\n",
    "    decoded_patterns_weighed = {}\n",
    "    decoded_patterns_count = {}\n",
    "    decoded_patterns_combined = {}\n",
    "    \n",
    "    decode_dia_intervals = {'A': '6D', 'B': '5D', 'C': '4D', 'D': '3D', 'E': '2D', 'F': '1D', \n",
    "                            'G': '1A', 'H': '2A', 'I': '3A', 'J': '4A', 'K': '5A', 'L': '6A', 'M': '0A'}\n",
    "\n",
    "    # decode all the candidates for patterns\n",
    "    for pattern in finalpat:\n",
    "        trans_pattern = \"\"\n",
    "        for letter in pattern:\n",
    "            trans = decode_dia_intervals[letter]\n",
    "            trans_pattern += trans\n",
    "\n",
    "        decoded_patterns_count[trans_pattern] = count_pattern[pattern]\n",
    "        \n",
    "        if pattern in combined:\n",
    "            # some might be reduced to a shorter pattern\n",
    "            decoded_patterns_combined[trans_pattern] = combined[pattern]\n",
    "        else:\n",
    "            decoded_patterns_combined[trans_pattern] = combined[beforereduction[pattern]]\n",
    "        decoded_patterns.append(trans_pattern)\n",
    "        \n",
    "    return decoded_patterns, decoded_patterns_combined, decoded_patterns_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d1bacd",
   "metadata": {},
   "source": [
    "Strings of intervals of each voice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "52f91910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0A0A0A0A0A6A0A6D0A0A6A0A6D1A0A4A0A4D0A0A4A0A4D1A0A3A3D1A0A0A4A0A4D1A0A3A3D1A0A0A4A0A4D1A0A3A3D1A0A0A0A1A0A1A0A2A1D1D1D4A3D3A3D2D1A1D1D3A1A0A0A4D1D0A3A6A3D3A3D2D1A1D1D3A1A0A0A4D1D0A3A6A3D3A3D2D1A1D1D3A1A0A4D1D0A5A2A1D0A6D1A0A1D5D5A4A3D3D2D2A0A4D1D5D5A6A2A0A1D5D5A6D0A6A6D0A6A6D0A5A5D0A5A6D0A6A6D0A5A6D0A6A6D0A6A6D0A5A6D0A6A1D1A1D1D1D3D0A1D4A1D5D5A5D0A2A3D3D2D2A0A4D1D5D5A6A2A0A1D5D5A6D0A6A6D0A6A6D0A5A5D0A5A6D0A6A6D0A5A6D0A5A5D0A5A6D0A5A5D0A5A6D0A6A6D0A6A0A3D3A3D3D2A1D1D3A1A0A0A4D1D0A3A6A3D3A3D2D1A1D1D3A1A0A0A4D1D0A3A6A3D3A3D2D1A1D1D3A1A0A4D1D0A5A0A1A0A6D2A1D0A1D1D4A3D3A3D2D1A1D1A1D1D3A1A0A0A1A1D4D1D0A3A6A3D3A3D2D1A1D1A1D1D3A1A0A0A1A1D4D1D0A3A6A3D3A3D2D1A1D1A1D1D3A1A0A4D1D0A5A2A1D0A6D1A0A1D5D5A4A3D3D2D2A0A4D1D5D5A6A2A0A1D5D5A6D0A6A6D0A6A6D0A5A5D0A5A6D0A6A6D0A5A6D0A6A6D0A6A6D0A5A6D0A6A1D1A1D1D1D3D0A1D4A1D5D5A5D0A2A3D3D2D2A0A4D1D5D5A6A2A0A1D5D5A6D0A6A6D0A6A6D0A5A5D0A5A6D0A6A6D0A5A6D0A5A5D0A5A6D0A5A5D0A5A6D0A6A6D0A6A0A3D3A3D3D2A1D1D3A1A0A0A4D1D0A3A6A3D3A3D2D1A1D1D3A1A0A0A4D1D0A3A6A3D3A3D2D1A1D1D3A1A0A4D1D0A5A0A1A0A6D2A1D0A1D1D4A3D3A3D2D1A1D1A1D1D3A1A0A0A1A1D4D1D0A3A6A3D3A3D2D1A1D1A1D1D3A1A0A0A1A1D4D1D0A3A6A3D3A3D2D1A1D1A1D1D3A1A0A4D1D0A5A2A1D0A6D1A4A0A1A3D1A2D1D0A4A2A1D0A3D1A2D1D4D1A0A4A1D4A0A1D1A0A2A1D1D1D4D5A1A3D1A2D1D0A4A2A1D0A3D1A2D1D4D1A0A4A1D4A0A1D1A0A2A1D1D0A1D4D5A1A1D1D1A1A1A2A1D1D6A0A1A1D1D1D1A2D2A1A1D1D1A1A1A2A1D1D6A0A1A1D1D1D1A2D3A1A1D1D1A1A1A2A1D1D6A0A1A1D1D1D1A2D1A1A1D1D1A1A1A2A1D1D6A0A1A1D1D1D4A1D2D1A1D1D1A1A1A2A1D1D6A0A1A1D1D1D1A2D2A1A1D1D1A1A1A2A1D1D6A0A1A1D1D1D1A2D3A1A1D1D1A1A1A2A1D1D6A0A1A1D1D1D1A2D1A1D1A1A1A2A1D1D6A0A1A1D1D1D4D6A0A3A1D3D1D4D4A0A1A1D1D1D3D0A1A1D6D6A5D4A1D2A5D0A5A5D0A5A5D0A5A5D0A5A6D0A5A6D0A5A5D0A5A6D0A5A5D0A5A6D0A6A6D0A6A0A3D3A3D3D2A1D1D3A1A0A0A4D1D0A3A6A3D3A3D2D1A1D1D3A1A0A0A4D1D0A3A6A3D3A3D2D1A1D1D3A1A0A0A4D1D0A5A1A0A6D2A1D0A1D1D4A3D3A3D2D1A1D1A1D1D3A1A0A0A1A1D4D1D0A3A6A3D3A3D2D1A1D1A1D1D3A1A0A0A1A1D4D1D0A3A6A3D3A3D2D1A1D1A1D1D3A1A0A0A4D1D0A0A1D0A6D1A0A1A0A0A0A1A0A0A1D0A1D0A2D0A3A1D0A2D0A1D0A4A1D0A4D0A1D0A5A1A0A0A0A1A0A0A1D0A1D0A2D0A3A1D0A2D0A1D0A0A0A0A4A1A1D3A3D1A1D0A1D0A2D0A1D0A0A4A1A1D3A3D1A1D0A1D0A2D0A1D0A0A0A0A0A0A4A1D0A2D0A1D0A\n",
      "\n",
      "0A0A4D2A6D4D0A0A4D2A6D4D6A6D5A0A2D0A2A2A1D2A0A2D4A0A4D0A4D4D0A0A4D0A4D4D0A0A3A0A0A0A2A2D4D2A6D4D0A0A4D2A5A3D0A0A4D2A2D1A0A5D1A3A0A3D0A0A3A0A4D1A0A0A4D2A5A3D0A0A4D2A2D1A0A5D1A3A0A3D2A4D0A0A4D0A4D4D0A0A4D0A4D4D0A0A3A2A2D0A2A2A1D2A0A2D4A0A4D0A4D4D0A0A4D0A4D4D0A0A4D0A0A0A2A2D4D2A6D4D0A0A4D2A5A3D0A0A4D2A2D1A0A5D1A3A0A3D0A0A3A0A4D1A0A0A4D2A5A3D0A0A4D2A2D1A0A5D1A3A0A3D2A4D0A0A4D0A4D4D0A0A4D0A4D4D0A0A3A2A2D0A2A2A1D2A0A2D4A0A4D0A4D4D0A0A4D0A4D4D0A0A4D0A0A0A2A2D4D2A2A0A1A3D1A2D1D0A4A2A1D0A3D1A2D1D6D3A0A3D3A0A3D3A0A3D3A0A1A3D1A2D1D0A4A2A1D0A3D1A2D1D6D3A0A3D3A0A3D3A0A3D3A6D5A0A5D5A0A4D2A0A6D2A0A6D5A0A5D5A0A4D2A0A6D2A0A5D5A0A5D5A0A4D2A0A6D2A0A0A5A0A5D5A0A4D2A0A2D2A0A2D2A0A2D2A0A2D2A0A6D2A0A6D5A0A5D5A0A4D2A0A6D2A0A5D5A0A5D5A0A4D2A0A6D2A0A0A5A0A5D5A0A4D2A2D2A2D0A0A2A2D2A4D0A0A4D0A4D4D0A0A4D0A4D4D0A0A3A2A2D0A2A2A1D2A0A2D4A0A4D0A4D4D0A0A4D0A4D4D0A0A3A0A0A0A2A2D4D2A0A2D3A0A3D3A0A3D1A0A1D5A0A5D1A0A1A0A2D0A1A0A1D0A0A0A3A0A3D3A0A3D1A0A1D5A0A5D3A0A3D2A0A2D4A0A4D0A0A0A4A0A0A0A0A4D3A0A3D0A0A0A4A0A0A0A0A4D5A0A0A0A3A1D2A0A0A0A0A5D0A0A2D0A0A2D0A0A0A0A0A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Strings of intervals of each voice\n",
    "decoded_strings = []\n",
    "for string in strings:\n",
    "    decoded = decode_strings(string)\n",
    "    decoded_strings.append(decoded)\n",
    "    print(decoded)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "e3811e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern: 0A0A0A0A\n",
      "importance score: 2 occurrence: 7\n",
      "Pattern: 3A0A3D3A\n",
      "importance score: 2 occurrence: 6\n",
      "Pattern: 0A0A0A\n",
      "importance score: 3 occurrence: 19\n"
     ]
    }
   ],
   "source": [
    "# Decode patterns\n",
    "decoded_patterns, decoded_patterns_combined, decoded_patterns_count = decode_results(finalpat, count_pattern, combined, beforereduction)\n",
    "\n",
    "for pattern in decoded_patterns:\n",
    "        print(\"Pattern:\", pattern)\n",
    "        print(\"importance score:\", decoded_patterns_combined[pattern],\n",
    "              \"occurrence:\", decoded_patterns_count[pattern])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "01510636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0A0A0A0A', '3A0A3D3A', '0A0A0A']"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "31669153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jkupddtest/chopinmono/D', 'jkupddtest/chopinmono/A', 'jkupddtest/chopinmono/mazurka24-4.krn']\n"
     ]
    }
   ],
   "source": [
    "# Get patterns from ground truth\n",
    "\n",
    "dict_wordtonum = {\"Unison\": '0', \"Second\": '1', \"Third\": '2', \"Fourth\": '3', \"Fifth\": '4', \"Sixth\": '5', \"Seventh\": '6'}\n",
    "\n",
    "groundtruthpatterns = []\n",
    "print(glob.glob(\"jkupddtest/chopinmono/*\"))\n",
    "filenames = glob.glob(\"jkupddtest/chopinmono/B/*.csv\")\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    with open(filename, 'r') as file:\n",
    "        csvreader = csv.reader(file)\n",
    "        gts = []\n",
    "        gtm = []\n",
    "        pattern_gt = []\n",
    "        for row in csvreader:\n",
    "            gts.append(float(row[0]))\n",
    "            gtm.append(float(row[1]))\n",
    "        for i in gtm:\n",
    "            pattern_gt.append(m21.note.Note(i))\n",
    "        pattern_string = \"\"\n",
    "        interval_string = \"\"\n",
    "        for i in pattern_gt:\n",
    "            pattern_string += str(i)\n",
    "            \n",
    "        for i in range(1, len(pattern_gt)):           \n",
    "            gap = pattern_gt[i].pitch.diatonicNoteNum - pattern_gt[i-1].pitch.diatonicNoteNum\n",
    "            if gap >= 0:\n",
    "                direction = 'A'\n",
    "            else:\n",
    "                direction = 'D'\n",
    "            m21_interval_directed = m21.interval.Interval(noteStart=pattern_gt[i-1], noteEnd=pattern_gt[i]).directedSimpleNiceName\n",
    "            arr_diatonic = m21_interval_directed.split(\" \")\n",
    "            m21_generic = dict_wordtonum[arr_diatonic[-1]]\n",
    "            m21_interval = m21_generic+direction\n",
    "            \n",
    "            interval_string+=m21_interval\n",
    "            \n",
    "        print(interval_string)\n",
    "\n",
    "        groundtruthpatterns.append(interval_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "1f292cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(groundtruthpatterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b761cec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pattern in groundtruthpatterns:\n",
    "    count = 0\n",
    "    for decodedstring in decoded_strings:\n",
    "        count += decodedstring.count(pattern)\n",
    "    if count == 0:\n",
    "        print(\"pattern\", pattern, \"not in original score\")\n",
    "    elif count == 1:\n",
    "        print(\"pattern\", pattern, \"only appeared once\")\n",
    "    else:\n",
    "        print(\"pattern\", pattern, \"appeared\", count, \"times in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d4b47c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "##CHECK IF THERE IS A MATCH\n",
    "\n",
    "for i in groundtruthpatterns:\n",
    "    if i in finalpat: #refined_finalpat:\n",
    "        print(\"found a match:\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7ba74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "90018dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5dfb1b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jkupddtest/gibbonsmono/H/midi/occ1.midi_part1_DD.csv', 'jkupddtest/gibbonsmono/H/midi/occ2.midi_part1_DD.csv']\n",
      "jkupddtest/gibbonsmono/H/midi/occ1.midi_part1_DD.csv\n",
      "0A1D1D1D1D0A7A1D1D4D3A1D1A2D1A3D1A0A4D\n",
      "jkupddtest/gibbonsmono/H/midi/occ2.midi_part1_DD.csv\n",
      "0A1D1D1D1D0A7A1D1D4D3A1D1A2D1A3D1A0A4D\n"
     ]
    }
   ],
   "source": [
    "#groundtruthpath1 = \"jkupddtest/gibbonsmono/silverswan.krn\"\n",
    "import pandas as pd\n",
    "gtfiles = glob.glob(\"jkupddtest/gibbonsmono/H/midi/*.csv\")\n",
    "print(gtfiles)\n",
    "gtstrings = []\n",
    "for gtfile in gtfiles:\n",
    "    print(gtfile)\n",
    "    with open(gtfile, 'r') as file:\n",
    "        df = pd.read_csv(file)\n",
    "        #print(df)\n",
    "        #for midi_note_num in df[\"midi_note_num\"]:\n",
    "        #    print(midi_note_num)\n",
    "        count = 0\n",
    "        gtstring = \"\"\n",
    "        for diatonic in df[\"diatonic_interval\"]:\n",
    "            if count == 0:\n",
    "                # ignore the first \"interval\" number which is always 0\n",
    "                count+=1\n",
    "                continue\n",
    "            count+=1\n",
    "            # just to format the input\n",
    "            if diatonic < 0:\n",
    "                dia = str(abs(diatonic)) + 'D'\n",
    "            else:\n",
    "                dia = str(abs(diatonic)) + 'A'\n",
    "            gtstring += dia\n",
    "        gtstrings.append(gtstring)\n",
    "        print(gtstring)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "ec20cf94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0A1D1D1D1D0A7A1D1D4D3A1D1A2D1A3D1A0A4D'}\n"
     ]
    }
   ],
   "source": [
    "print(set(gtstrings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "2e0df0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 0A1D1D1D1D0A7A1D1D4D3A1D1A2D1A3D1A0A4D not in original score\n",
      "pattern 0A1D1D1D1D0A7A1D1D4D3A1D1A2D1A3D1A0A4D not in original score\n"
     ]
    }
   ],
   "source": [
    "for pattern in gtstrings:\n",
    "    count = 0\n",
    "    for decodedstring in decoded_strings:\n",
    "        count += decodedstring.count(pattern)\n",
    "    if count == 0:\n",
    "        print(\"pattern\", pattern, \"not in original score\")\n",
    "    elif count == 1:\n",
    "        print(\"pattern\", pattern, \"only appeared once\")\n",
    "    else:\n",
    "        print(\"pattern\", pattern, \"appeared\", count, \"times in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e070111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee6b243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278cc728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c251380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
