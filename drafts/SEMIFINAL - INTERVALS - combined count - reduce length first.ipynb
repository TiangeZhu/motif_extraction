{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1285b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21 as m21\n",
    "import re\n",
    "from collections import Counter\n",
    "from swalign_local import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1039d2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the score\n",
    "score = '~/facets-search-engine/data/Beethoven9thOdeToJoy.xml'\n",
    "#score = '~/jupyternotebooks/bwv1046a.mei'\n",
    "full_score = m21.converter.parse(score)\n",
    "len(full_score.parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccee41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first voice as the first doc in alignment\n",
    "m21_score = full_score.parts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51ea7e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the second voice as the second doc in alignment\n",
    "compared_score = full_score.parts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e74c05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(full_score.parts) > 2:\n",
    "    print(\"More than 2 voices! We should compare all the voices.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aea3f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intervals(m21_score):\n",
    "        \n",
    "        noteoffset = []\n",
    "        beatstrength = []\n",
    "        \n",
    "        dict_wordtonum = {\"Unison\": '2', \"Second\": '2', \"Third\": '3', \"Fourth\": '4', \"Fifth\": '5', \"Sixth\": '6', \"Seventh\": '7'}\n",
    "        #P.S.: Unison as \"2\" instead of \"0\" for a reason, see explanation later\n",
    "        \n",
    "        # encoding the diatonic intervals. not 1A and 1D are represented as 2A and 2D here...\n",
    "        dict_encode_dia_intervals = {\"7D\": 'A', '6D': 'B', '5D': 'C', '4D':'D', '3D':'E', '2D':'F', \n",
    "                                     '2A':'G', '3A':'H', '4A':'I', '5A':'J', '6A': 'K', '7A':'L', '0A': 'M'}\n",
    "        \n",
    "        diatonic_intervals = []\n",
    "        \n",
    "        previous_note = None\n",
    "        \n",
    "        # Scan the items        \n",
    "        for thisnote in m21_score.recurse().notes:\n",
    "            \n",
    "            # We ignore rests\n",
    "            if thisnote.isRest: \n",
    "                # If the rest is a full measure, part of a multi-measure rest: we need to adjust\n",
    "                continue\n",
    "            \n",
    "            noteoffset.append(thisnote.offset)\n",
    "            beatstrength.append(thisnote.beatStrength)\n",
    "            #\"duration:\", thisnote.duration.quarterLength)\n",
    "            #print(\"offset:\", thisnote.offset, \"beat strength\", thisnote.beatStrength)\n",
    "            if previous_note is None:\n",
    "                previous_note = thisnote\n",
    "            else:\n",
    "                if thisnote.isNote and previous_note.isNote:\n",
    "                    # gap = number of semi-tones of the current interval \n",
    "                    gap = thisnote.pitch.diatonicNoteNum - previous_note.pitch.diatonicNoteNum\n",
    "                elif thisnote.isChord and previous_note.isNote:\n",
    "                    gap = thisnote.root().diatonicNoteNum - previous_note.pitch.diatonicNoteNum\n",
    "                elif thisnote.isChord and previous_note.isChord:\n",
    "                    gap = thisnote.root().diatonicNoteNum - previous_note.root().diatonicNoteNum\n",
    "                elif thisnote.isNote and previous_note.isChord:\n",
    "                    gap = thisnote.pitch.diatonicNoteNum - previous_note.root().diatonicNoteNum\n",
    "                # if a pitch change is detected\n",
    "                    \n",
    "                if gap != 0:\n",
    "                    if gap > 0:\n",
    "                        #  if the semi-tone difference between the current and the previous item > 0, it is an ascending interval.\n",
    "                        direction = 'A'\n",
    "                    else:\n",
    "                        #  otherwise, it is a descending interval.\n",
    "                        direction = 'D'\n",
    "\n",
    "                    # Get intervals using music21\n",
    "                    \"\"\"\n",
    "                            \"directedSimpleNiceName\" examples: \"Descending Doubly-Diminished Fifth\", \"Ascending Perfect Fourth\", \"Ascending Doubly-Augmented Fourth\"\n",
    "                            \"simpleName\" examples: dd5, P5, AA4. There's no direction information\n",
    "                            Since it only executes when a pitch interval is detected, \"unison\" refers to an augmented unison, a.k.a minor second\n",
    "                    \"\"\"\n",
    "                    # take intervals between root notes if there exists any chord\n",
    "                    if previous_note.isChord:\n",
    "                        startnote = previous_note.root()\n",
    "                    else:\n",
    "                        startnote = previous_note\n",
    "                    if thisnote.isChord:\n",
    "                        endnote = thisnote.root()\n",
    "                    else:\n",
    "                        endnote = thisnote\n",
    "                        \n",
    "                    m21_interval_directed = m21.interval.Interval(noteStart=startnote, noteEnd=endnote).directedSimpleNiceName\n",
    "\n",
    "                    arr_diatonic = m21_interval_directed.split(\" \")\n",
    "\n",
    "                    m21_generic = dict_wordtonum[arr_diatonic[-1]]\n",
    "                    \n",
    "                    # m21_interval: 2A, 3D etc...\n",
    "                    m21_interval = m21_generic+direction\n",
    "                    # to make each m21_interval unique, show direction and each as single character in string, we encode the diatonic intervals as letters\n",
    "                    encode_interval = dict_encode_dia_intervals[m21_interval]\n",
    "                    diatonic_intervals.append(encode_interval)\n",
    "\n",
    "                else:\n",
    "                    # We take the interval between two consecutive pitches as 0A\n",
    "                    encode_interval = dict_encode_dia_intervals['0A']\n",
    "                    diatonic_intervals.append(encode_interval)\n",
    "                previous_note = thisnote\n",
    "                    \n",
    "\n",
    "        return diatonic_intervals, noteoffset, beatstrength\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86d364f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_string(list_intervals):\n",
    "    \n",
    "    string = \"\"\n",
    "    for i in list_intervals:\n",
    "        string += str(i)\n",
    "    print(len(string))\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a08b5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swm_alignment(string1, string2):\n",
    "    \n",
    "    match = 2\n",
    "    mismatch = -2\n",
    "    scoring = NucleotideScoringMatrix(match, mismatch)\n",
    "    sw = LocalAlignment(scoring)#, gap_extension_penalty = -5) \n",
    "    \n",
    "    alignment = sw.align(string2, string1)\n",
    "    alignment_strings = alignment.dump()\n",
    "    return alignment_strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5ce6803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pattern_beat_weighed(beatstrength, string, pattern):\n",
    "    \n",
    "    weighedscore = 0\n",
    "    count = 0\n",
    "    #match = re.search(pattern, string)\n",
    "    #if match != None:\n",
    "    #    print(\"no match in this one\")\n",
    "    for m in re.finditer(pattern, string):\n",
    "        count +=1\n",
    "        if beatstrength[m.start()] == 1.0:\n",
    "            weighedscore += 1.5\n",
    "        elif beatstrength[m.start()] >= 0.5:\n",
    "            weighedscore += 1\n",
    "        else:\n",
    "            weighedscore += beatstrength[m.start()]\n",
    "        #print(m.start(), beatstrength[m.start()])\n",
    "    return weighedscore, count\n",
    "\n",
    "def count_pattern_beat_weighed(reducedfinalpat, string1, string2, beatstrength1, beatstrength2):\n",
    "    \n",
    "    weighed_score = {}\n",
    "    count_pattern = {}\n",
    "    \n",
    "    for pattern in reducedfinalpat: # finalpattern\n",
    "        # initialize the weighed value\n",
    "        weighed_score[pattern] = 0\n",
    "        count_pattern[pattern] = 0\n",
    "\n",
    "        # find the pattern in the first score\n",
    "        weighedscore, count = find_pattern_beat_weighed(beatstrength1, string1, pattern)\n",
    "        weighed_score[pattern] += weighedscore\n",
    "        count_pattern[pattern] += count\n",
    "    \n",
    "        # find the pattern in the second score\n",
    "        weighedscore, count = find_pattern_beat_weighed(beatstrength2, string2, pattern)\n",
    "        weighed_score[pattern] += weighedscore\n",
    "        count_pattern[pattern] += count\n",
    "    \n",
    "    return count_pattern, weighed_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "164a2096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_pattern_length(seq):\n",
    "    \n",
    "        # the function returns the longest substring that appeared at least once\n",
    "        # if there is length 4 substring repeated 4 times and a length 7 substring repeated 2 times, we take the length 7\n",
    "        best_performance = \"\"\n",
    "        candidates = []\n",
    "        for length in range(int(0.2*len(seq)), int(len(seq)*0.5)+1): \n",
    "            for start in range(0, len(seq)-length):\n",
    "                # get all the substrings of this length within the string, save in candidates\n",
    "                candidates.append(seq[start:start+length])\n",
    "        count_can = {}\n",
    "        for candidate in candidates:\n",
    "                count_can[candidate] = seq.count(candidate)\n",
    "                if count_can[candidate] > 1:\n",
    "                    # if it is repeated more than once in the string\n",
    "                    if len(candidate) > len(best_performance):\n",
    "                        best_performance = candidate\n",
    "                    elif len(candidate) == len(best_performance) and count_can[candidate] > count_can[best_performance]:\n",
    "                        best_performance = candidate\n",
    "        \n",
    "        return best_performance\n",
    "\n",
    "def check_reduction(item):\n",
    "    \n",
    "    frequent_substr = reduce_pattern_length(item)\n",
    "    times = item.count(frequent_substr) \n",
    "    if len(frequent_substr) >= 4:\n",
    "        # if it is a large part of the string, or it appeared more than 3 times in the string\n",
    "        if len(frequent_substr) > 0.2*len(item) or times >= 3:\n",
    "            print(\"extracted\", frequent_substr, \"from\", item)\n",
    "            # sucessfully reduced the pattern\n",
    "            return frequent_substr\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59573055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_length_of_the_pattern(item):\n",
    "    \n",
    "    # reduce the length of this item\n",
    "    frequent_substr = check_reduction(item)\n",
    "    #startpos = []\n",
    "    \n",
    "    if frequent_substr != None:\n",
    "        if len(frequent_substr) > 23:\n",
    "            # second attempt, if a frequent substring is still quite long\n",
    "            new_frequent_substr = check_reduction(frequent_substr)\n",
    "            if new_frequent_substr != None:\n",
    "                # if the second attempt is a success, take the twice reduced pattern\n",
    "                \"\"\"\n",
    "                # FIND START POS OF THE NEW ITEMS\n",
    "                for m in re.finditer(new_frequent_substr, item):\n",
    "                    print(frequent_substr, item, m.start(), pos)\n",
    "                    startpos.append(pos+m.start())\n",
    "                \"\"\"\n",
    "                return new_frequent_substr #, startpos\n",
    "            else:\n",
    "                # if the second attempt failed, take the result of first reduction\n",
    "                \"\"\"\n",
    "                for m in re.finditer(frequent_substr, item):\n",
    "                    print(frequent_substr, item, m.start(), pos)\n",
    "                    startpos.append(pos+m.start())\n",
    "                \"\"\"\n",
    "                return frequent_substr #, startpos\n",
    "        else:\n",
    "            # if the extracted pattern does not need further reduction\n",
    "            \"\"\"\n",
    "            for m in re.finditer(frequent_substr, item):\n",
    "                print(frequent_substr, item, m.start(), pos)\n",
    "                startpos.append(pos+m.start()) \n",
    "            \"\"\"\n",
    "            return frequent_substr #, startpos\n",
    "    \n",
    "    # if the reduction failed, return the original, startpos will be an empty list\n",
    "    return None #, startpos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf82de9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef add_item_to_list(startposinseq1, startpos, pattern_to_add, pattern1):\\n    \\n    # add the pattern to the list\\n    pattern1.append(pattern_to_add)\\n    \\n    if pattern_to_add not in startposinseq1:\\n        # save this pattern\\n        startposinseq1[pattern_to_add] = startpos\\n    else:\\n        # if this pattern already existed, add the new positions to the list\\n        startposinseq1[pattern_to_add] += startpos\\n\\n    return startposinseq1, pattern1\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def add_item_to_list(startposinseq1, startpos, pattern_to_add, pattern1):\n",
    "    \n",
    "    # add the pattern to the list\n",
    "    pattern1.append(pattern_to_add)\n",
    "    \n",
    "    if pattern_to_add not in startposinseq1:\n",
    "        # save this pattern\n",
    "        startposinseq1[pattern_to_add] = startpos\n",
    "    else:\n",
    "        # if this pattern already existed, add the new positions to the list\n",
    "        startposinseq1[pattern_to_add] += startpos\n",
    "\n",
    "    return startposinseq1, pattern1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "daa33e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patterns_from_alignment(alignment_strings):\n",
    "    \n",
    "    fullseq1 = alignment_strings[0]\n",
    "    pat1 = fullseq1.split('-')\n",
    "    fullseq2 = alignment_strings[1]\n",
    "    pat2 = fullseq2.split('-')\n",
    "\n",
    "    pattern1 = []\n",
    "    pattern2 = []\n",
    "    \n",
    "    # startpos_pat saves all the start position of the pattern(if it appears only once, then it's a list of one element)\n",
    "    # this dictionary saves the pattern appears from the Xth note, instead of offset. \n",
    "    \n",
    "    #startposinseq1_pat = {}\n",
    "    #startposinseq2_pat = {}\n",
    "\n",
    "    for pattern in pat1:\n",
    "        if len(pattern) > 2:\n",
    "            # Get rid of sequences shorter than 3 intervals\n",
    "            if len(pattern) > 11:\n",
    "                #if the pattern is too long, find longest repeated pattern within it\n",
    "                newpattern = reduce_length_of_the_pattern(pattern)\n",
    "                if newpattern != None:\n",
    "                    # if the extraction succeeded\n",
    "                    pattern1.append(newpattern)\n",
    "                    #pattern1 = add_item_to_list(startposinseq1_pat, startpos, newpattern, pattern1)\n",
    "                else:\n",
    "                    # add the original position to the list\n",
    "                    #startpos.append(pos)\n",
    "                    print(\"not extractable:\", pattern)\n",
    "                    pattern1.append(pattern)\n",
    "                    #pattern1 = add_item_to_list(startposinseq1_pat, startpos, pattern, pattern1)\n",
    "            else:\n",
    "                # no need to extract a shorter one from this pattern\n",
    "                # add the original position to the list\n",
    "                pattern1.append(pattern)\n",
    "                #startposinseq1_pat, pattern1 = add_item_to_list(startposinseq1_pat, startpos, pattern, pattern1)\n",
    "\n",
    "    for pattern in pat2:\n",
    "        if len(pattern) > 2:\n",
    "            if len(pattern) > 11:\n",
    "                #if the pattern is too long, find longest repeated pattern within it\n",
    "                newpattern = reduce_length_of_the_pattern(pattern)\n",
    "                if newpattern != None:\n",
    "                    # if the extraction succeeded\n",
    "                    pattern2.append(newpattern)\n",
    "                else:\n",
    "                    print(\"not extractable:\", pattern)\n",
    "                    pattern2.append(pattern)\n",
    "            else:\n",
    "                # no need to extract a shorter one from this pattern\n",
    "                pattern2.append(pattern)\n",
    "    \n",
    "    tempallpatterns = pattern1 + pattern2\n",
    "    \n",
    "    allthepattern_count = dict(Counter(tempallpatterns))\n",
    "\n",
    "    # Get the number of distinctive ones\n",
    "    allthepatterns = list(set(tempallpatterns))\n",
    "    len(allthepatterns)\n",
    "    \n",
    "    return allthepatterns, allthepattern_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01a18847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_substringandparents(allthepatterns, allthepattern_count):\n",
    "    \n",
    "    issubstring = {}\n",
    "    hassubstring = {}\n",
    "    count_as_substring = {}\n",
    "    count_as_parent = {}\n",
    "\n",
    "    for i in range(0, len(allthepatterns)):\n",
    "        for j in range(i+1, len(allthepatterns)):\n",
    "            if allthepatterns[i] in allthepatterns[j]:\n",
    "                # if pattern i is substring of pattern j\n",
    "                parent = allthepatterns[j]\n",
    "                kid = allthepatterns[i]\n",
    "                times = parent.count(kid)\n",
    "\n",
    "                if kid not in issubstring:\n",
    "                    issubstring[kid] = 1\n",
    "                    count_as_substring[kid] = times * allthepattern_count[parent]\n",
    "                else:\n",
    "                    issubstring[kid] += 1\n",
    "                    count_as_substring[kid] += times * allthepattern_count[parent]\n",
    "\n",
    "                if parent not in hassubstring:\n",
    "                    hassubstring[parent] = 1\n",
    "                    count_as_parent[parent] = 1#times\n",
    "                else:\n",
    "                    hassubstring[parent] += 1\n",
    "                    count_as_parent[parent] += 1 \n",
    "\n",
    "            elif allthepatterns[j] in allthepatterns[i]:\n",
    "                # if pattern j is substring of pattern i\n",
    "\n",
    "                parent = allthepatterns[i]\n",
    "                kid = allthepatterns[j]\n",
    "                times = parent.count(kid)\n",
    "\n",
    "                if kid not in issubstring:\n",
    "                    issubstring[kid] =1\n",
    "                    count_as_substring[kid] = times * allthepattern_count[parent]\n",
    "                else:\n",
    "                    issubstring[kid] += 1\n",
    "                    count_as_substring[kid] += times * allthepattern_count[parent]\n",
    "\n",
    "                if parent not in hassubstring:\n",
    "                    hassubstring[parent] = 1\n",
    "                    count_as_parent[parent] = 1 #times\n",
    "                else:\n",
    "                    hassubstring[parent] += 1\n",
    "                    count_as_parent[parent] += 1 #times\n",
    "\n",
    "    return issubstring, hassubstring, count_as_substring, count_as_parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7579ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This counts the times each pattern appeared after original segmentation plus the times they are in other patterns,\n",
    "# plus the times other patterns showed up in them.\n",
    "\n",
    "def combined_count(sorthas, sortis, count_as_parent, count_as_substring, allthepattern_count):\n",
    "    \n",
    "    refined_combined = {}\n",
    "\n",
    "    for item in sorthas:\n",
    "        if item in sortis:\n",
    "            # the ones that has substring and also are the substrings\n",
    "            refined_combined[item] = count_as_parent[item] + count_as_substring[item] + allthepattern_count[item]\n",
    "        else:\n",
    "            # the ones that has substrings\n",
    "            refined_combined[item] = count_as_parent[item] + allthepattern_count[item]\n",
    "\n",
    "    # the patterns that are substrings of other patterns but none of the others are substrings of it\n",
    "    for item in sortis:\n",
    "        if item not in refined_combined:\n",
    "            refined_combined[item] = count_as_substring[item] + allthepattern_count[item]\n",
    "        # otherwise is already counted\n",
    "    return refined_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2d41dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_combined_result(finalpattern_combined, allthepattern_count):\n",
    "    print(dict(Counter(finalpattern_combined)))\n",
    "    for i in finalpattern_combined:\n",
    "        print(i, allthepattern_count[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ed173cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_combined_patterns(combined):\n",
    "    \n",
    "    finalpattern = []\n",
    "    for i in combined: \n",
    "\n",
    "        if len(i) < 3:\n",
    "            # if the length is shorter than 4 notes, discard\n",
    "            continue\n",
    "\n",
    "        if combined[i] > 1:\n",
    "            # keep the ones that has substring or is substring or appeared more than once\n",
    "            finalpattern.append(i)\n",
    "            \n",
    "    finalpattern_combined = {}\n",
    "        \n",
    "    for thisone in finalpattern:\n",
    "        finalpattern_combined[thisone] = combined[thisone]\n",
    "\n",
    "    dict(Counter(finalpattern_combined))\n",
    "        \n",
    "    if len(finalpattern) > 20:\n",
    "        # if more than 20 patterns, only take the top 20\n",
    "        finalpattern_combined = dict(sorted(finalpattern_combined.items(), key = lambda x:-x[1], reverse = True)[-20:])\n",
    "    \n",
    "    return finalpattern_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2aacc75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_results(finalpat, weighed_score, count_pattern, combined):\n",
    "    \n",
    "    decoded_patterns = []\n",
    "    decoded_patterns_weighed = {}\n",
    "    decoded_patterns_count = {}\n",
    "    decoded_patterns_combined = {}\n",
    "    \n",
    "    decode_dia_intervals = {'A': '7D', 'B': '6D', 'C': '5D', 'D': '4D', 'E': '3D', 'F': '2D', \n",
    "                            'G': '2A', 'H': '3A', 'I': '4A', 'J': '5A', 'K': '6A', 'L': '7A', 'M': '0A'}\n",
    "\n",
    "    # decode all the candidates for patterns\n",
    "    for pattern in finalpat:\n",
    "        trans_pattern = \"\"\n",
    "        for letter in pattern:\n",
    "            trans = decode_dia_intervals[letter]\n",
    "            trans_pattern += trans\n",
    "\n",
    "        decoded_patterns_weighed[trans_pattern] = weighed_score[pattern]\n",
    "        decoded_patterns_count[trans_pattern] = count_pattern[pattern]\n",
    "        decoded_patterns_combined[trans_pattern] = combined[pattern]\n",
    "        decoded_patterns.append(trans_pattern)\n",
    "        \n",
    "    return decoded_patterns, decoded_patterns_combined, decoded_patterns_weighed, decoded_patterns_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2922422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_strings(string1, string2):\n",
    "    \n",
    "    decode_dia_intervals = {'A': '7D', 'B': '6D', 'C': '5D', 'D': '4D', 'E': '3D', 'F': '2D', \n",
    "                            'G': '2A', 'H': '3A', 'I': '4A', 'J': '5A', 'K': '6A', 'L': '7A', 'M': '0A'}\n",
    "    \n",
    "    decode_string1 = \"\"\n",
    "    decode_string2 = \"\"\n",
    "\n",
    "    for letter in string1:\n",
    "        trans = decode_dia_intervals[letter]\n",
    "        decode_string1+=trans\n",
    "\n",
    "    for letter in string2:\n",
    "        trans = decode_dia_intervals[letter]\n",
    "        decode_string2+=trans\n",
    "    \n",
    "    return decode_string1, decode_string2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3811e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_two_voices(m21_score, compared_score):\n",
    "    \n",
    "    # Get diatonic intervals, beat strength and other information from scores.\n",
    "    dia_intervals1, noteoffset1, beatstrength1 = get_intervals(m21_score)\n",
    "    dia_intervals2, noteoffset2, beatstrength2 = get_intervals(compared_score)\n",
    "\n",
    "    string1 = to_string(dia_intervals1)\n",
    "    string2 = to_string(dia_intervals2)\n",
    "\n",
    "    # Smith waterman alignment of two strings\n",
    "    alignment_strings = swm_alignment(string1, string2)\n",
    "    \n",
    "    \"\"\"\n",
    "    startposinseq1 saves the starting position of each pattern in seq1\n",
    "    startposinseq2 saves the starting position of each pattern in seq2\n",
    "    allthepatterns is a list of unique candidate patterns(that will go through parent-child count)\n",
    "    allthepatterns_count counts the times each candidate pattern in allthepatterns appear in both seqs.       \n",
    "    \"\"\"\n",
    "    \n",
    "    # get patterns and their start positions, and reduce the long ones to \"longest repeated substring\"\n",
    "    allthepatterns, allthepattern_count = get_patterns_from_alignment(alignment_strings)\n",
    "        \n",
    "    # find substring relationships between all pairs of candidate patterns\n",
    "    issubstring, hassubstring, count_as_substring, count_as_parent = count_substringandparents(allthepatterns, allthepattern_count)\n",
    "    \n",
    "    # sort the ones that are substrings\n",
    "    sortis = dict(Counter(issubstring))\n",
    "    # sort the ones that have substrings\n",
    "    sorthas = dict(Counter(hassubstring))\n",
    "    \n",
    "    combined = combined_count(sorthas, sortis, count_as_parent, count_as_substring, allthepattern_count)\n",
    "    \n",
    "    # filter out the short ones\n",
    "    top20patterns_combined = filter_combined_patterns(combined)\n",
    "    \n",
    "    # just print what's going on\n",
    "    show_combined_result(top20patterns_combined, allthepattern_count)\n",
    "    \n",
    "    # count patterns in origianl strings and weigh them with their beat strength\n",
    "    count_pattern, weighed_scores = count_pattern_beat_weighed(top20patterns_combined, string1, string2, beatstrength1, beatstrength2)\n",
    "    \n",
    "    # Decode patterns\n",
    "    decoded_patterns, decoded_patterns_combined, decoded_patterns_weighed, decoded_patterns_count = decode_results(top20patterns_combined, weighed_scores, count_pattern, combined)\n",
    "    \n",
    "    decode_string1, decode_string2 = decode_strings(string1, string2)\n",
    "        \n",
    "    for pattern in decoded_patterns:\n",
    "        print(\"Pattern:\", pattern)\n",
    "\n",
    "        print(\"importance score:\", decoded_patterns_combined[pattern],\n",
    "              \"weighed score:\", decoded_patterns_weighed[pattern], \n",
    "              \"occurrence:\", decoded_patterns_count[pattern],\n",
    "              \"average weigh:\", decoded_patterns_weighed[pattern]/decoded_patterns_count[pattern])\n",
    "\n",
    "        match1 = re.search(pattern, decode_string1)\n",
    "        if match1 != None:\n",
    "            print(\"first occurrence in decoded string1: % s, % s\" % (match1.start(), match1.end()))\n",
    "        else:\n",
    "            print(\"the pattern does not exist in decoded string1.\")\n",
    "        match2 = re.search(pattern, decode_string2)\n",
    "        if match2 != None:\n",
    "            print(\"first occurrence in decoded string2: % s, % s\" % (match2.start(), match2.end()))\n",
    "        else:\n",
    "            print(\"the pattern does not exist in decoded string2.\")\n",
    "            \n",
    "    return decoded_patterns, decoded_patterns_combined, decoded_patterns_weighed, decoded_patterns_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e6100d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2487\n",
      "2623\n",
      "Query:    1 GGMFFFFGGMFMGGGMFFFFGGFFMGGEGGGFEGGGFFFGCKMMGGMFFFFGGFFMGGEGGGFEGGGFFFGCKMMGGMFFFFGGFFMJKGGEHFFFFGGCHGGCFFFGFMAHIFIGGCGGHFFFFGGCHGG-CFFFKFHFMEGGGGEGGGFEDFG-JGGFFDG-GGMGEGCIHMGGCDIMGG-HFFFGEGGCHGGCFFFKFHFMEGGGGEGGGFEDMEG-GJGGFFDGGGMGEGCIHMGGCDIMGG--HFFFGEGGBGGGGGCFFKFKFFBGGHGGCG---GBG---F-F-FFGGEEGGGGBMKFMCDGGLGGCGGBGFFF-F-GGEEGGGGEFFFF----FLFMFJFMMFFGGECGIGGGFECF-GGJG--GFFDGG-GFFGGCKCMFKMGGCGGBGFFFFGCGGGGGEDGF--FFLFMFJFMMFFGGECGIGGGFECF-GGJG--GFFDGG-GFFGGCKCMFKMGGCGGBGFFFFGCGGGGGEDGF--FFLFMFJFMIFFJGG-MFFDCMJIMFMGGGMFFDCMJIDCMJIFJIGF-M-DI-GAJF-CI--I-M---MG--GMFFDCMJIDCMHFFDIF--JIGF-MDIGAJFCIIM---MG--GMFFDCMJIDCMHF-FMKF-FMMFFKBGICFMJIBICMMKMCMMKMCKFDFHFIGEFHFIGGCMFKCMLECMLF---FFFFGGG--GGAGGGGG-GMGBAGGAGGAG-GAKGGAD--MMEKAGFJEKAGF--FGEEGGFFMEEGLFMAHMIMEMHMHMIMB----MHMCMHMBMIFGMMMCMMMMMJMDCHBKGMAGMEHEMMMMGIMMCGGBMGGMFFFGMGGMFG-FMMDMGMGMEMFJMMMBMGGIFJCEFMGCM-----------D----MGFBMM--GIF---FMBGGH-------MGMMG--GAMF-----MG-CGHBM-MLCG--GF------G---GBMMMLCGGFIAMMMLFGEFFHFDMMMGMMMCMGGIMMGCFCLJDG-FF--FFFI-F---MEGGDGMBGGLCGG--G-BMMMLCGG----F---GGBMMMLCGG-F---G--GG------AM-----------------MMLFGEF-F--H------FDM-M-MGM-M-MCMGGIM-MGCFCGHDGFFFFFHAGLFMKCIGMJIMM-MCMKM-MMMFDCDF--FEMGGM---F--F-FGF-FFIHFMIFE---FMGGMFFFGMGGFF---MMCMFMH-FF-LMGEAIMEHHGGFM----D--M---MDGLGGF-FEGGEMGGCIEEGM---IMGGBMMMKFFFEM-MMIMGGBE-GGJ--M-FMMFG-------CMFMHMIMFGGF-M-----DM---MFFHIGGFICIKEHM-GG------C----MDKHFFFG-BIDIMGFDEGGFIMGMHAFMLM--FMKFFMG---EFFH-----EFFG-GGHF-EGDGG--GGEG----GGGFMFHEF---F--H----F-FG-G-GGGGGM-FHFIFHFCMIG-MGFG-GFCMMMJFHEFFHEDMGMGFGF-KG-GGMF--FGGMGGEFFG--HF--FGMFFG-HFFGM--FFGH-FMFMGMG--CIBF----IGHGEGGGGFMFHEFFHM--M--FFGHFHFFGGIFGMGFBG---FMHIFF-GHF-GFD--MMIFFGHFGFDMMIFF-GHFMF-EMMMHFM----IC--JFFGGEGGGG--FHFHEDFHE--HFFGMFHFM------FE---IHFGF-MLF-M--KF----FM-MEFFHEFFGGHFHEFFH--E---DM---HFHE---F--F--G---G-BFMGF---H-EFFGGAMMMKEMMMKMMGGMMBMGGMAMMLGMMFMALMGMM--------GG----MM-FMFDM-----CMM--LG-M---DMCGAMLFMMMGFLM----MM------------G----GF-FLG-GF-FLG-GF-FMF-FGCCG-G-G-G-GMKMMGFMMIFGLBCMFMMLGMFMAGFMGFMMBKG-G------MMF--C-JF----D-MIM-MLGM---MF------------MALMG--------------MM-G-G-MMFMFDMCMMLGMFMAMFMGFGMMGFLMMMG-GF--MFG-GF--M---FGG--F----FM---F---F----G-----I--CG-G-G--GGMKMMGF---MMCMHCMF--MMLG---MF---MAMF-M--G-F-GMMGF---J--H-------MMG-G--F-M-F-----------G--G---F---M---F----GGFFM-FF----G-----ICG----G---G--G--GMKMMGF-MM-CMHCM-F-----MMLGMF---MAMFM----GHF--FM-FMKFFMGMEM-FFHEMFFGGG-G-GMFEGG-GMFEAFMMG--MMGI---FF---F-----JM---M-----MGGMGFFFFFFGMGGFCMIDMICMIDMICMIDMIIGGMMMGMMMEHEICI--FHGGGDCMMJFFJFIBJFFIAMM---G-M--MGIBIFEFMG---DM---L--IBIFFDMHEM---IMMM-FM--D-----MGJG-CMFLFFDIF-GEKFCIGCDIFFGG------FCKF------------CIM-F-G-M--MBHM--M-F--FKMMBMMMGGIGMDEMM-FF----G--MM--FMMMGGKM----M-CMM--M--FFLM---M-FDF---FM------M-M--LM--MMGGMGFFFFAGF--MGGFG----F--MGGGFEG-GGFGEG-GGFGEGGGFFGBMKMGGEEHCJFGMMMGGMGFF---FFFGMMGGMG--FFFFFJFFFFFJFFFFFIFFFMGCJMGAMLFFMMGCJMGAMLFFMMGCJMGGFF-FGMMGFGGKGMAGMEFFIGBGFIJMGFFFFLMM-MFFCMMHGM-MGGBGMGGMG---GDGBJCMKFFMCMKFFMCMKFF---MCMKFFFLGF--BK-FFMMMGKMDGG-MMMG--G-EGFFFFHEMBG--GMMMIMGAGFF-FFKFMMMIMBKMGMAMGKMGMAMGKMGMDMCG-MGMDMCGMMMFMMMKCMMMG----MMFMMFMMGMMGMMFMMFMMGM-MMMMMMMMMM-MIGGBMMMMMMMMMM-MIGGBMMMMMMMMMM--MKGG 2368\n",
      "            |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| ..|     ||   ..|||  |   |         || ||.|| .||| | |          |  || .||   | || | |  .|||.|..|| .|||         ||| |       |||||     | | ||    |||| |     | |..||  .|||           || |    |.||| |   | |   | | ||           ||            ||| | ||   ..|.||||    | | | |  |||||..|...|| | || |  ||..|| .||   |  .| ||..| .||||         .|  || | | |    |||..|...|| | || |  ||..|| .||   |  .| ||..| .||||         .|  || | | |     || .|| |  | |   |  |   |      |  || | || |.|| .|  | |   ||  || ..|  |     | ||  |.|| |||  .| ..|   ||  || ..|  |    | | .| |      |  |  |    |          |.||   | | ||  |  | ....|   .||||||  || ||||| | |  || || | |  || |  .|   |   .|||  || |||     |            ....|    ...| |   | |                |  |        |...|||  ||    | || .| ...| | |.| |   ...||.|     | |           |    ||  ||  | |   |    |       || ||  |  |     .| ..|.| |  |  ||      |   ..|||    |    |  |  |      |     ||   |      | ||  |||| |   |.|| || || .||  | .|.| |||    |   ||     .|| |   |  ||      ||                 .|.|| | |  |      .|| | |.| | |.|  || |     |            | |.||  || | | | ||||  .|  | .|||   |  | |.| .| | |  |   ..||    | .|||   .|  ||| || .|| .|    ||||    |  |   |     | |    | |  ||||   .|...||||    | || |   | ..|  | | | |       ||..|| .|  | |     ||   |   .|||    |.| ||      |    ||| |..| |  .|.|    | .|||  |.|  .| .|||   |  |     |  | .| | ..|||  |.||    .||| |  |   |  |    | || | |..||| |.| ...||.| .||| |      ..|     || |||| .| |.||  | ||   |||  .|  |||||| ..| |  || | | | |.|  ||.|    .| | ||||    |  .|  |  |.|.| ||||  | | .|   |   || .|| |||  .|   | .| .||.|| |.| | ||||..|    ||  .|||| ||||  | |  |  |  |     |||      .|   ...|| |.| |  .|    || |.|| ...||...| .|  |   .|   ...|   |  |  |   | .| ||   | | |   |||  ||| ||  || |  | ||  ||.|..|.||        ||    || | |||     .||  .| |   .| | |.||||| .|    ||            |    || | | || | | || |.| || .| | | | |   .||  .||    |   | |  || ||    | |      .||  | .|    | ||| |.||   .|            |  .|              || | | || |  | ||  | | | |||| .||    | ||  .|| ||  |   |||  |    .|   |   |    |     |  || | |  ||   .||   |||   .|  .|.|   ||   ...| |  | | | .||   |  |       ||| |  | | |           |  |   |   |   |    || || ||    |     ..|    |   |  |  .||.| | || ||  | |     || | |   | | |    | |  || | .|||||.| .|..|  ||| | |   || |||   |.|  .| |   ||   |     .|   |     |||||||||||||||||||.| .|  ||.|  |   |       .|.|||  .|.|| | |     | .||..||   | |  ||   |  ||   ||   |  .|    |..|   |||| .|  |     || | ||     || ||..| ..||||||      |..|            | | | | |  |..|  | |  | || |||||  | .|| ||    |  ||  |||||| |    | .||  |  || |   | | |   ||      | |  .|  ||||||||||  |  |||.|    |  |||| .| || |.| || | .||    |.||| |     ||||| .||   .||.||  ||  ||.||            |  ||  .|  |    || .||   ||        || |.|||     |  | ...| |   |||||| || |   || || | |  | .||   |     |  .| | ||    ||   |.|.||| .|  || |.|||  .||| ||||  | .|||.||   |  |   ..| ||| .|       |  |   |..|   |..|    | .|  ..|   |       .|    |||||||||||||||||||||| |||||||||| |   .|||||||||| |   .||||||||||  |.||\n",
      "Ref  :    1 GGMFFFFGGMFMGGGMFFFFGGFFMGGEGGGFEGGGFFFGCKMMGGMFFFFGGFFMGGEGGGFEGGGFFFGCKMMGGMFFFFGGFFMJ-MCE-----GG---IMFFF--M---F---------FF-GCEGGIMFFF-F-F----------F--FGFLGG---GAGG-G-G--GMGGGDBFGGIMFFF---------FFF-F-------GEGGG-----GAG-GG----GGMG-G-----G-DBFGGIMLFFF-----------FF-F----GEHGG-GMFKG-GIDIFDFHFF-----------FM------------FFFLFKGG---IDGIFFFFGMMGF-F-F-F--FFGGEHFIJHHFE-FHGG-GBMGFEIGGEEFF---K--AK-GGIDG-IFFFF---------HFMMFF-F-F-F----GGEHFIJHHFE-FHGG-GBMGFEIGGEEFF---K--AK-GGIDG-IFFFF---------HFMMFF-F-F-F-----GGCIFF-C--I-F---G--F---J------F--GFIMGDIFGFJFGFIMDIDMGCDMGCDGM-EIC--I-----F-IFGFJFGFIMDI--HF-FDMGCDMGCDGM-EIC--I----FIF-GFJF------G--F--I----M----------DIHF---F-F-GG--F--M-DGGGFGGGHFFFGGGCCGG-GGGGGFG-G--GG-GG-GBG--GG-DGGGM---G---GAGFHEFG-EGG-----G------------GGGGBGGGGGGGC-H---I-G----------------G--G--------GGGGCGG--GG----G-GG-BGHGGGD-G-GGE-F---GGGGGGF-----G-MHHHEEEHFHHIDEEHDMG--MMHHG-FEEHF----HIHEDEHDMG-MGHHG--FEEHFHHGFEEHDMGM--GHHGFEEHEHHGFEEHEMMM----F----M--G--F------G-----GG---G------GMFFGFFFFIMFDCDMCGG-GM-GG-MGGEGGKIMFM-CGGIEIMFELFGG-----AGGEFKMCGEEGGCJBJCJAMHJCJCJCJDHEHEGFGDCMGFG-FGFGCHEHEHEHEDMIMBMHMCMHMBM--IMBM-----H------------M-CMGM--MMEM-M-MFMMMF--GFKMF-FGGMBMHFDHFEFMFDMF-H-M--ELECJEGG----G-BGFFGEEEM--FMHFFFDFMG-HI----GGFMFMFGDFFMFFFM-----FKF----M-G--EEGMDMMMMMMMMMMK----MHMM-M---EHCMJEHMEF-M-GKDKMBIDCMJEHM-KF--FAMFMLEMDMGEJM---DGGF----EJMDGGFFIMMMCGCKKMDK-FMGGKB--MMMF----F-FGMH--MCMGGHM-DFMGIDIE--HCJDMGE--GIEG-FHCJDGGFEGIEGFHDIDGGF-F--FJDIFGEHCGCKFGFGAGAGEMGGMGFLF-GGECMEGEFGFGAG------AGE-----MG-GFGFLFGDGCMFMJF-GM---FFGEGCFMKFGMFFGEEEF-MKEFF-HEF-F-GGGHFCIHFCCFFFG-G-GGGG----E--LMDIMDMFGGGF-FFGG--G-G-GGEIIF---FFMHHFMGFDCJHM---G-DG-MMMDFFGGGF-FMEMMMEIMGEGCICMGFFFGG-GGGGELF-F--D--EJMH-----HFMDMCDMMJEKMKEDMGFGMJFDMGHIFICIGFMIMMFF-BJGGGGGGE-GHIBEJKEJMJCIJIMELGCFGGFCJGCFJGCGF-GFIDCHGE-F---MMM--MMM-MM--MM-M--M-MM--MMMMMMMMMMKFFFFFMMGGHFFEMMHF-FDMHGGGBMMMHGGGBMKGGFM-G-MMFMMMG-GMEGCJMMCMMMMMMMMMMMGDIMDGFGF-GFGFGF-GFGFGFGFGFG-FGFGFGFGFG---CGF--GFG----F---G-F--GF-GF----GFGFGFGFGGMFGDCMMFGGGGDMMIMGMCGMIGFFFGFFFGFFFGFFJM--IGFFFGFFFGFFFGFFMMEGFGCMM-M--M-MM--M-M-M-MGFG-DGF----GCGFGDGFGCGFGDMHHIFGGAGFGDGCJMIDGFCJGFCJIDGDGHFFIMMCGFGFGEMGG---FGFGCJMMC---GFGDGMGGEGIMFGGGEGHFCMJFGCFDG-FGFGFGJFHHIFHHFDCMMGFGJFFBMKFMCIDMJCMMJFGDCGCMGFIJFMCJEFCMIFGG-FMHFFBFFFGHFFFMJMGAMEMGMFMGFMGFFBMKFM-FDMMJCM--MJFGDCGCMM-G-FIJFM-M-MIFKFG-FGIFMIF-FFFMGMIMGAFICM--GGGEGIG---GGAGMF---MHGJCDM-IJCMFFGCGFGAGFGGMCDGMCDEMMMGGMGFFFFFFGMGGFCMIFM-JM--MIEM--M---G-------IHDICICICHMGG-C-M-----I-HFFDGMMFKBGCMIFMG---F--MGFMIDMGFMLAMKB----MJCMJCMIMMMGGMGGDFFGFGMG-GFCM-----IFMGEMJC-MMDIFFGGMMMMGFFFFFGFMGGFDMGFMGC-MGFMGFMGFMGFMGFMGFMJF-MM-MMMGG--M-MMMFFFMMMGGMMMMFFFMMMGG-MGGFGMIFMMGMMGIFF-MIFFMIF-FMIFFMGFFEFGMFMKFFMBMMMGGMGFFFF--FMMMGGMGFFFFFGMMGGG-BGMGG-GBGMGG-G-AGG----MMMGG-E-----MMMGG-EFFHGGMFFEMM--MGMMFFMFF------------I--FM--KM--M----MG-GMG---FF--------FFMFIMMG-----M--M-MMMG-G---MGFFFF-MMLM---MM-GMEM-G--M-EMGMEMG-----M--IM-M-FF----FFGGMMMMGFFF-FFKMBKGFGMMM--LDGGMMMMGFFGFHGFFGFH---GFFG---FBG-GFFGGF-------B--G---GFFG---GFFG----GFFG--FFG---F-------FGFFGGMMFMMFMMGMMGMMFMMFMMGMGMMMMMMMMMMCM---JMMMMMMMMMMAM---LMMMMMMMMMMBMMAGG 2317\n",
      "\n",
      "!: GGMFFFFGGFFMGGEGGGFEGGGFFFGCKMM\n",
      "extracted GGMFFFFGGFFMGGEGGGFEGGGFFFGCKMM from GGMFFFFGGMFMGGGMFFFFGGFFMGGEGGGFEGGGFFFGCKMMGGMFFFFGGFFMGGEGGGFEGGGFFFGCKMMGGMFFFFGGFFMJKGGEHFFFFGGCHGGCFFFGFMAHIFIGGCGGHFFFFGGCHGG\n",
      "not extractable: CFFFKFHFMEGGGGEGGGFEDFG\n",
      "not extractable: GGMGEGCIHMGGCDIMGG\n",
      "not extractable: HFFFGEGGCHGGCFFFKFHFMEGGGGEGGGFEDMEG\n",
      "not extractable: GJGGFFDGGGMGEGCIHMGGCDIMGG\n",
      "not extractable: HFFFGEGGBGGGGGCFFKFKFFBGGHGGCG\n",
      "not extractable: FFGGEEGGGGBMKFMCDGGLGGCGGBGFFF\n",
      "not extractable: GGEEGGGGEFFFF\n",
      "not extractable: FLFMFJFMMFFGGECGIGGGFECF\n",
      "not extractable: GFFGGCKCMFKMGGCGGBGFFFFGCGGGGGEDGF\n",
      "not extractable: FFLFMFJFMMFFGGECGIGGGFECF\n",
      "not extractable: GFFGGCKCMFKMGGCGGBGFFFFGCGGGGGEDGF\n",
      "not extractable: FFLFMFJFMIFFJGG\n",
      "extracted MFFDCMJI from MFFDCMJIMFMGGGMFFDCMJIDCMJIFJIGF\n",
      "not extractable: GMFFDCMJIDCMHFFDIF\n",
      "not extractable: GMFFDCMJIDCMHF\n",
      "not extractable: FMMFFKBGICFMJIBICMMKMCMMKMCKFDFHFIGEFHFIGGCMFKCMLECMLF\n",
      "not extractable: GMGBAGGAGGAG\n",
      "extracted EKAGF from MMEKAGFJEKAGF\n",
      "not extractable: FGEEGGFFMEEGLFMAHMIMEMHMHMIMB\n",
      "not extractable: MHMCMHMBMIFGMMMCMMMMMJMDCHBKGMAGMEHEMMMMGIMMCGGBMGGMFFFGMGGMFG\n",
      "not extractable: FMMDMGMGMEMFJMMMBMGGIFJCEFMGCM\n",
      "not extractable: GBMMMLCGGFIAMMMLFGEFFHFDMMMGMMMCMGGIMMGCFCLJDG\n",
      "not extractable: MEGGDGMBGGLCGG\n",
      "not extractable: MGCFCGHDGFFFFFHAGLFMKCIGMJIMM\n",
      "not extractable: FMGGMFFFGMGGFF\n",
      "not extractable: LMGEAIMEHHGGFM\n",
      "not extractable: FEGGEMGGCIEEGM\n",
      "not extractable: IMGGBMMMKFFFEM\n",
      "not extractable: CMFMHMIMFGGF\n",
      "not extractable: MFFHIGGFICIKEHM\n",
      "not extractable: BIDIMGFDEGGFIMGMHAFMLM\n",
      "not extractable: GFCMMMJFHEFFHEDMGMGFGF\n",
      "not extractable: IGHGEGGGGFMFHEFFHM\n",
      "not extractable: FFGHFHFFGGIFGMGFBG\n",
      "extracted MMIFF from MMIFFGHFGFDMMIFF\n",
      "extracted FHEFF from MEFFHEFFGGHFHEFFH\n",
      "not extractable: EFFGGAMMMKEMMMKMMGGMMBMGGMAMMLGMMFMALMGMM\n",
      "not extractable: DMCGAMLFMMMGFLM\n",
      "not extractable: GMKMMGFMMIFGLBCMFMMLGMFMAGFMGFMMBKG\n",
      "not extractable: MMFMFDMCMMLGMFMAMFMGFGMMGFLMMMG\n",
      "not extractable: MGGMGFFFFFFGMGGFCMIDMICMIDMICMIDMIIGGMMMGMMMEHEICI\n",
      "not extractable: FHGGGDCMMJFFJFIBJFFIAMM\n",
      "not extractable: GEKFCIGCDIFFGG\n",
      "not extractable: FKMMBMMMGGIGMDEMM\n",
      "not extractable: MMGGMGFFFFAGF\n",
      "not extractable: GGFGEGGGFFGBMKMGGEEHCJFGMMMGGMGFF\n",
      "extracted MGCJMGAMLFFM from FFFFFJFFFFFJFFFFFIFFFMGCJMGAMLFFMMGCJMGAMLFFMMGCJMGGFF\n",
      "not extractable: FGMMGFGGKGMAGMEFFIGBGFIJMGFFFFLMM\n",
      "extracted CMKFFM from GDGBJCMKFFMCMKFFMCMKFF\n",
      "extracted KMGMAMG from FFKFMMMIMBKMGMAMGKMGMAMGKMGMDMCG\n",
      "not extractable: MGMDMCGMMMFMMMKCMMMG\n",
      "extracted MMFMMFMMGM from MMFMMFMMGMMGMMFMMFMMGM\n",
      "extracted MMMMM from MIGGBMMMMMMMMMM\n",
      "extracted MMMMM from MIGGBMMMMMMMMMM\n",
      "extracted GGMFFFFGGFFMGGEGGGFEGGGFFFGCKMM from GGMFFFFGGMFMGGGMFFFFGGFFMGGEGGGFEGGGFFFGCKMMGGMFFFFGGFFMGGEGGGFEGGGFFFGCKMMGGMFFFFGGFFMJ\n",
      "not extractable: GMGGGDBFGGIMFFF\n",
      "not extractable: IDGIFFFFGMMGF\n",
      "not extractable: FFGGEHFIJHHFE\n",
      "not extractable: GBMGFEIGGEEFF\n",
      "not extractable: GBMGFEIGGEEFF\n",
      "not extractable: GFIMGDIFGFJFGFIMDIDMGCDMGCDGM\n",
      "not extractable: IFGFJFGFIMDI\n",
      "extracted DMGC from FDMGCDMGCDGM\n",
      "extracted FGGG from DGGGFGGGHFFFGGGCCGG\n",
      "extracted GGGG from GGGGBGGGGGGGC\n",
      "not extractable: MHHHEEEHFHHIDEEHDMG\n",
      "extracted FEEH from FEEHFHHGFEEHDMGM\n",
      "extracted HHGFEEHE from GHHGFEEHEHHGFEEHEMMM\n",
      "not extractable: GMFFGFFFFIMFDCDMCGG\n",
      "not extractable: CGGIEIMFELFGG\n",
      "not extractable: AGGEFKMCGEEGGCJBJCJAMHJCJCJCJDHEHEGFGDCMGFG\n",
      "not extractable: FGFGCHEHEHEHEDMIMBMHMCMHMBM\n",
      "not extractable: FGGMBMHFDHFEFMFDMF\n",
      "not extractable: GGFMFMFGDFFMFFFM\n",
      "extracted MMMMM from EEGMDMMMMMMMMMMK\n",
      "not extractable: GKDKMBIDCMJEHM\n",
      "not extractable: FAMFMLEMDMGEJM\n",
      "not extractable: EJMDGGFFIMMMCGCKKMDK\n",
      "not extractable: FHCJDGGFEGIEGFHDIDGGF\n",
      "not extractable: FJDIFGEHCGCKFGFGAGAGEMGGMGFLF\n",
      "not extractable: GGECMEGEFGFGAG\n",
      "not extractable: GFGFLFGDGCMFMJF\n",
      "extracted FFGE from FFGEGCFMKFGMFFGEEEF\n",
      "not extractable: GGGHFCIHFCCFFFG\n",
      "not extractable: LMDIMDMFGGGF\n",
      "not extractable: FFMHHFMGFDCJHM\n",
      "not extractable: FMEMMMEIMGEGCICMGFFFGG\n",
      "not extractable: HFMDMCDMMJEKMKEDMGFGMJFDMGHIFICIGFMIMMFF\n",
      "not extractable: GHIBEJKEJMJCIJIMELGCFGGFCJGCFJGCGF\n",
      "not extractable: MMMMMMMMMMKFFFFFMMGGHFFEMMHF\n",
      "extracted MHGGGBM from FDMHGGGBMMMHGGGBMKGGFM\n",
      "not extractable: GMEGCJMMCMMMMMMMMMMMGDIMDGFGF\n",
      "not extractable: GFGFGFGFGGMFGDCMMFGGGGDMMIMGMCGMIGFFFGFFFGFFFGFFJM\n",
      "extracted GFFFGFF from IGFFFGFFFGFFFGFFMMEGFGCMM\n",
      "not extractable: GCGFGDGFGCGFGDMHHIFGGAGFGDGCJMIDGFCJGFCJIDGDGHFFIMMCGFGFGEMGG\n",
      "not extractable: GFGDGMGGEGIMFGGGEGHFCMJFGCFDG\n",
      "not extractable: FGFGFGJFHHIFHHFDCMMGFGJFFBMKFMCIDMJCMMJFGDCGCMGFIJFMCJEFCMIFGG\n",
      "not extractable: FMHFFBFFFGHFFFMJMGAMEMGMFMGFMGFFBMKFM\n",
      "not extractable: FFFMGMIMGAFICM\n",
      "not extractable: IJCMFFGCGFGAGFGGMCDGMCDEMMMGGMGFFFFFFGMGGFCMIFM\n",
      "not extractable: IHDICICICHMGG\n",
      "not extractable: HFFDGMMFKBGCMIFMG\n",
      "extracted MGFM from MGFMIDMGFMLAMKB\n",
      "not extractable: MJCMJCMIMMMGGMGGDFFGFGMG\n",
      "not extractable: MMDIFFGGMMMMGFFFFFGFMGGFDMGFMGC\n",
      "extracted MGFMGFMGF from MGFMGFMGFMGFMGFMGFMJF\n",
      "extracted MMMFFFMMMGG from MMMFFFMMMGGMMMMFFFMMMGG\n",
      "not extractable: MGGFGMIFMMGMMGIFF\n",
      "not extractable: FMIFFMGFFEFGMFMKFFMBMMMGGMGFFFF\n",
      "extracted MMGG from FMMMGGMGFFFFFGMMGGG\n",
      "not extractable: EFFHGGMFFEMM\n",
      "not extractable: FFGGMMMMGFFF\n",
      "not extractable: FFKMBKGFGMMM\n",
      "extracted GFFGFH from LDGGMMMMGFFGFHGFFGFH\n",
      "extracted GMMFMMFMMGM from FGFFGGMMFMMFMMGMMGMMFMMFMMGMGMMMMMMMMMMCM\n",
      "extracted MMMMM from JMMMMMMMMMMAM\n",
      "extracted MMMMM from LMMMMMMMMMMBMMAGG\n",
      "{'FMF': 15, 'IJCMFFGCGFGAGFGGMCDGMCDEMMMGGMGFFFFFFGMGGFCMIFM': 16, 'GFGFGFGFGGMFGDCMMFGGGGDMMIMGMCGMIGFFFGFFFGFFFGFFJM': 16, 'MMGG': 16, 'MMFMFDMCMMLGMFMAMFMGFGMMGFLMMMG': 17, 'GGGG': 19, 'MGM': 21, 'FFGG': 22, 'MMF': 23, 'MMMG': 25, 'EGG': 26, 'GMG': 29, 'GGE': 30, 'FGF': 31, 'FGG': 37, 'GFG': 40, 'MMG': 46, 'FFF': 55, 'FFG': 59, 'MMM': 64}\n",
      "FMF 1\n",
      "IJCMFFGCGFGAGFGGMCDGMCDEMMMGGMGFFFFFFGMGGFCMIFM 1\n",
      "GFGFGFGFGGMFGDCMMFGGGGDMMIMGMCGMIGFFFGFFFGFFFGFFJM 1\n",
      "MMGG 1\n",
      "MMFMFDMCMMLGMFMAMFMGFGMMGFLMMMG 1\n",
      "GGGG 2\n",
      "MGM 1\n",
      "FFGG 1\n",
      "MMF 1\n",
      "MMMG 2\n",
      "EGG 1\n",
      "GMG 1\n",
      "GGE 1\n",
      "FGF 1\n",
      "FGG 1\n",
      "GFG 1\n",
      "MMG 1\n",
      "FFF 1\n",
      "FFG 1\n",
      "MMM 2\n",
      "Pattern: 2D0A2D\n",
      "importance score: 15 weighed score: 20.5 occurrence: 27 average weigh: 0.7592592592592593\n",
      "first occurrence in decoded string1: 644, 650\n",
      "first occurrence in decoded string2: 194, 200\n",
      "Pattern: 4A5A5D0A2D2D2A5D2A2D2A7D2A2D2A2A0A5D4D2A0A5D4D3D0A0A0A2A2A0A2A2D2D2D2D2D2D2A0A2A2A2D5D0A4A2D0A\n",
      "importance score: 16 weighed score: 1 occurrence: 1 average weigh: 1.0\n",
      "the pattern does not exist in decoded string1.\n",
      "first occurrence in decoded string2: 3536, 3630\n",
      "Pattern: 2A2D2A2D2A2D2A2D2A2A0A2D2A4D5D0A0A2D2A2A2A2A4D0A0A4A0A2A0A5D2A0A4A2A2D2D2D2A2D2D2D2A2D2D2D2A2D2D5A0A\n",
      "importance score: 16 weighed score: 0.25 occurrence: 1 average weigh: 0.25\n",
      "the pattern does not exist in decoded string1.\n",
      "first occurrence in decoded string2: 2820, 2920\n",
      "Pattern: 0A0A2A2A\n",
      "importance score: 16 weighed score: 9.25 occurrence: 35 average weigh: 0.2642857142857143\n",
      "first occurrence in decoded string1: 84, 92\n",
      "first occurrence in decoded string2: 84, 92\n",
      "Pattern: 0A0A2D0A2D4D0A5D0A0A7A2A0A2D0A7D0A2D0A2A2D2A0A0A2A2D7A0A0A0A2A\n",
      "importance score: 17 weighed score: 1 occurrence: 1 average weigh: 1.0\n",
      "first occurrence in decoded string1: 3216, 3278\n",
      "the pattern does not exist in decoded string2.\n",
      "Pattern: 2A2A2A2A\n",
      "importance score: 19 weighed score: 39.0 occurrence: 43 average weigh: 0.9069767441860465\n",
      "first occurrence in decoded string1: 282, 290\n",
      "first occurrence in decoded string2: 246, 254\n",
      "Pattern: 0A2A0A\n",
      "importance score: 21 weighed score: 46.125 occurrence: 41 average weigh: 1.125\n",
      "first occurrence in decoded string1: 1532, 1538\n",
      "first occurrence in decoded string2: 1086, 1092\n",
      "Pattern: 2D2D2A2A\n",
      "importance score: 22 weighed score: 28.375 occurrence: 50 average weigh: 0.5675\n",
      "first occurrence in decoded string1: 10, 18\n",
      "first occurrence in decoded string2: 10, 18\n",
      "Pattern: 0A0A2D\n",
      "importance score: 23 weighed score: 28.875 occurrence: 42 average weigh: 0.6875\n",
      "first occurrence in decoded string1: 654, 660\n",
      "first occurrence in decoded string2: 534, 540\n",
      "Pattern: 0A0A0A2A\n",
      "importance score: 25 weighed score: 42.25 occurrence: 34 average weigh: 1.2426470588235294\n",
      "first occurrence in decoded string1: 1474, 1482\n",
      "first occurrence in decoded string2: 2674, 2682\n",
      "Pattern: 3D2A2A\n",
      "importance score: 26 weighed score: 27.25 occurrence: 36 average weigh: 0.7569444444444444\n",
      "first occurrence in decoded string1: 54, 60\n",
      "first occurrence in decoded string2: 54, 60\n",
      "Pattern: 2A0A2A\n",
      "importance score: 29 weighed score: 20.4375 occurrence: 41 average weigh: 0.49847560975609756\n",
      "first occurrence in decoded string1: 324, 330\n",
      "first occurrence in decoded string2: 254, 260\n",
      "Pattern: 2A2A3D\n",
      "importance score: 30 weighed score: 36.1875 occurrence: 41 average weigh: 0.8826219512195121\n",
      "first occurrence in decoded string1: 50, 56\n",
      "first occurrence in decoded string2: 50, 56\n",
      "Pattern: 2D2A2D\n",
      "importance score: 31 weighed score: 32.125 occurrence: 55 average weigh: 0.5840909090909091\n",
      "first occurrence in decoded string1: 212, 218\n",
      "first occurrence in decoded string2: 230, 236\n",
      "Pattern: 2D2A2A\n",
      "importance score: 37 weighed score: 35.375 occurrence: 78 average weigh: 0.453525641025641\n",
      "first occurrence in decoded string1: 12, 18\n",
      "first occurrence in decoded string2: 12, 18\n",
      "Pattern: 2A2D2A\n",
      "importance score: 40 weighed score: 49.6875 occurrence: 62 average weigh: 0.8014112903225806\n",
      "first occurrence in decoded string1: 1656, 1662\n",
      "first occurrence in decoded string2: 850, 856\n",
      "Pattern: 0A0A2A\n",
      "importance score: 46 weighed score: 38.25 occurrence: 81 average weigh: 0.4722222222222222\n",
      "first occurrence in decoded string1: 84, 90\n",
      "first occurrence in decoded string2: 84, 90\n",
      "Pattern: 2D2D2D\n",
      "importance score: 55 weighed score: 88.75 occurrence: 117 average weigh: 0.7585470085470085\n",
      "first occurrence in decoded string1: 6, 12\n",
      "first occurrence in decoded string2: 6, 12\n",
      "Pattern: 2D2D2A\n",
      "importance score: 59 weighed score: 69.0 occurrence: 112 average weigh: 0.6160714285714286\n",
      "first occurrence in decoded string1: 10, 16\n",
      "first occurrence in decoded string2: 10, 16\n",
      "Pattern: 0A0A0A\n",
      "importance score: 64 weighed score: 103.75 occurrence: 111 average weigh: 0.9346846846846847\n",
      "first occurrence in decoded string1: 1424, 1430\n",
      "first occurrence in decoded string2: 1206, 1212\n"
     ]
    }
   ],
   "source": [
    "decoded_patterns, decoded_patterns_combined, decoded_patterns_weighed, decoded_patterns_count = process_two_voices(m21_score, compared_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2c2a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
