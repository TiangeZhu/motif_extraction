{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1285b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21 as m21\n",
    "import re\n",
    "from collections import Counter\n",
    "from swalign_local import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "1039d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read input data:\n",
    "import music21 as m21\n",
    "import re\n",
    "from collections import Counter\n",
    "from swalign_local import *\n",
    "import csv\n",
    "import glob\n",
    "\n",
    "#score_path = \"jkupddtest/bachmono/wtc2f20.krn\"\n",
    "#score_path = \"jkupddtest/beethovenmono/sonata01-3.krn\"\n",
    "#score_path = \"jkupddtest/mozartmono/sonata04-2.krn\"\n",
    "#score_path = \"jkupddtest/gibbonsmono/silverswan.krn\"\n",
    "score_path = \"jkupddtest/chopinmono/mazurka24-4.krn\"\n",
    "#score_path = '~/facets-search-engine/data/Beethoven9thOdeToJoy.xml'\n",
    "\n",
    "raw_score = m21.converter.parse(score_path)\n",
    "num_of_parts = len(raw_score.parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "ccee41a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "51ea7e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "voices = []\n",
    "for part in raw_score.parts:\n",
    "    voices.append(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "acce90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Get diatonic scale degree sequence from all voices\n",
    "\n",
    "def get_diatonic_intervals(voice):\n",
    "    \n",
    "    # get key / root information:\n",
    "    roots = [key.tonic for key in voice.recurse().getElementsByClass(m21.key.Key)]\n",
    "    diatonic_root = roots[0].diatonicNoteNum if roots != [] else voice.analyze('key').tonic.diatonicNoteNum\n",
    "    #print(diatonic_root)\n",
    "    key = voice.analyze('key')\n",
    "\n",
    "    noteoffset = []\n",
    "    midi = []\n",
    "    #timesig = m21_score.getContextByClass(m21.meter.TimeSignature)\n",
    "    #barlength = timesig.barduration\n",
    "\n",
    "    dict_wordtonum = {\"Unison\": '0', \"Second\": '1', \"Third\": '2', \"Fourth\": '3', \"Fifth\": '4', \"Sixth\": '5', \"Seventh\": '6'}\n",
    "        \n",
    "    dict_encode_dia_intervals = {\"6D\": 'A', '5D': 'B', '4D': 'C', '3D':'D', '2D':'E', '1D':'F', \n",
    "                                     '1A':'G', '2A':'H', '3A':'I', '4A':'J', '5A': 'K', '6A':'L', '0A': 'M'}\n",
    "        \n",
    "    diatonic_intervals = []\n",
    "    beatstrength = []\n",
    "    previous_note = None\n",
    "\n",
    "    onset = 0\n",
    "    for thisnote in voice.recurse().notes:\n",
    "        onset += thisnote.offset\n",
    "        \n",
    "        # We ignore rests\n",
    "        if thisnote.isRest: \n",
    "                # If the rest is a full measure, part of a multi-measure rest: we need to adjust\n",
    "                continue\n",
    "        \n",
    "        noteoffset.append(onset)\n",
    "        beatstrength.append(thisnote.beatStrength)\n",
    "        #if thisnote.isNote:\n",
    "        #    midi.append(thisnote.pitch.midi)\n",
    "        #elif thisnote.isChord:\n",
    "        #    midi.append(thisnote.root().midi)\n",
    "            \n",
    "        if previous_note is None:\n",
    "                previous_note = thisnote\n",
    "        else:\n",
    "                if thisnote.isNote and previous_note.isNote:\n",
    "                    # gap = number of semi-tones of the current interval \n",
    "                    gap = thisnote.pitch.diatonicNoteNum - previous_note.pitch.diatonicNoteNum\n",
    "                elif thisnote.isChord and previous_note.isNote:\n",
    "                    gap = thisnote.root().diatonicNoteNum - previous_note.pitch.diatonicNoteNum\n",
    "                elif thisnote.isChord and previous_note.isChord:\n",
    "                    gap = thisnote.root().diatonicNoteNum - previous_note.root().diatonicNoteNum\n",
    "                elif thisnote.isNote and previous_note.isChord:\n",
    "                    gap = thisnote.pitch.diatonicNoteNum - previous_note.root().diatonicNoteNum\n",
    "                # if a pitch change is detected\n",
    "                    \n",
    "                if gap != 0:\n",
    "                    \n",
    "                    if gap > 0:\n",
    "                        #  if the semi-tone difference between the current and the previous item > 0, it is an ascending interval.\n",
    "                        direction = 'A'\n",
    "                    else:\n",
    "                        #  otherwise, it is a descending interval.\n",
    "                        direction = 'D'\n",
    "\n",
    "                    # Get intervals using music21\n",
    "                    \"\"\"\n",
    "                            \"directedSimpleNiceName\" examples: \"Descending Doubly-Diminished Fifth\", \"Ascending Perfect Fourth\", \"Ascending Doubly-Augmented Fourth\"\n",
    "                            \"simpleName\" examples: dd5, P5, AA4. There's no direction information\n",
    "                            Since it only executes when a pitch interval is detected, \"unison\" refers to an augmented unison, a.k.a minor second\n",
    "                    \"\"\"\n",
    "                    # take intervals between root notes if there exists any chord\n",
    "                    if previous_note.isChord:\n",
    "                        startnote = previous_note.root()\n",
    "                    else:\n",
    "                        startnote = previous_note\n",
    "                    if thisnote.isChord:\n",
    "                        endnote = thisnote.root()\n",
    "                    else:\n",
    "                        endnote = thisnote\n",
    "                        \n",
    "                    m21_interval_directed = m21.interval.Interval(noteStart=startnote, noteEnd=endnote).directedSimpleNiceName\n",
    "\n",
    "                    arr_diatonic = m21_interval_directed.split(\" \")\n",
    "\n",
    "                    m21_generic = dict_wordtonum[arr_diatonic[-1]]\n",
    "                    \n",
    "                    # m21_interval: 2A, 3D etc...\n",
    "                    m21_interval = m21_generic+direction\n",
    "                    if m21_generic == \"0\":\n",
    "                        m21_interval = '0A'\n",
    "                    # to make each m21_interval unique, show direction and each as single character in string, we encode the diatonic intervals as letters\n",
    "                    encode_interval = dict_encode_dia_intervals[m21_interval]\n",
    "                    diatonic_intervals.append(encode_interval)\n",
    "\n",
    "                else:\n",
    "                    # We take the interval between two consecutive pitches as 0A\n",
    "                    encode_interval = dict_encode_dia_intervals['0A']\n",
    "                    diatonic_intervals.append(encode_interval)\n",
    "                previous_note = thisnote\n",
    "            \n",
    "    string = \"\"\n",
    "    for i in diatonic_intervals:\n",
    "        string += str(i)\n",
    "        \n",
    "    return string, key, noteoffset, midi, beatstrength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "aea3f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = []\n",
    "noteoffsets = []\n",
    "midis = []\n",
    "keys = []\n",
    "beatstrengths = []\n",
    "\n",
    "for voice in voices:\n",
    "    string, key, noteoffset, midi, beatstrength = get_diatonic_intervals(voice)\n",
    "    strings.append(string)\n",
    "    noteoffsets.append(noteoffset)\n",
    "    beatstrengths.append(beatstrength)\n",
    "    midis.append(midi)\n",
    "    keys.append(key)\n",
    "    #print(len(string), len(beatstrength))#, len(midi))\n",
    "    #print(string)\n",
    "    #print(len(noteoffset))\n",
    "    #print(midi)\n",
    "    #print(beatstrength)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "a08b5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smith-Waterman alignment between the two input sequences\n",
    "\n",
    "def swm_alignment(string1, string2):\n",
    "    match = 2\n",
    "    mismatch = -2\n",
    "    scoring = NucleotideScoringMatrix(match, mismatch)\n",
    "    sw = LocalAlignment(scoring) \n",
    "    \n",
    "    alignment = sw.align(string1, string2)\n",
    "    alignment_strings = alignment.dump()\n",
    "\n",
    "    simi_score = alignment.matches / (alignment.mismatches + alignment.matches)\n",
    "    \n",
    "    return alignment_strings, simi_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "94591d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_gather_patterns(allthepatterns, fullseq):\n",
    "    pat = fullseq.split('-')\n",
    "    print(\"num of pat in this seq:\", len(pat))    \n",
    "    for pattern in pat:\n",
    "        # Get rid of the sequence shorter than 3 intervals; put all alignment patterns into all pattern list\n",
    "        if len(pattern) > 2:\n",
    "            allthepatterns.append(pattern)\n",
    "    return allthepatterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9ab996d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  431 MEIMDIMD-GMFKMBG--MGMEMGMFMMMIMDIMD-GMFKMBI-MDHMEJMC-MM-M-JM-MMMCIMDM-M-MJM--M-M-M---CKM-M--MIFHMM-MMBM-MEM--MEM-MMMM 521\n",
      "            | |.|| | | |   |  .|| || |..||.|| | | |...| |  |   | || | .| ||| .| | | |.|  | | |   | | |  |   || ||.| |||  ||| ||||\n",
      "Ref  :  913 M-ILDI-DEG-F---GFFIGM-MG-FCFMILDI-DEG-FGFFIGM--M---CFMMFMAGMGMMM-GM-MFMFMEMIFMEMFMJFMC-MFMKGM---MMGMMFMFMEMIFMEMFMMMM 1008\n",
      "\n",
      "num of pat in this seq: 27\n",
      "num of pat in this seq: 22\n"
     ]
    }
   ],
   "source": [
    "# compare each pair of voices!\n",
    "allthepatterns = []\n",
    "\n",
    "for i in range(0, len(voices)-1):\n",
    "    for j in range(i+1, len(voices)):\n",
    "        alignment_strings, simi_score = swm_alignment(strings[i], strings[j])\n",
    "        if simi_score < 0.25:\n",
    "            # if two voices are too different, getting patterns from their alignment won't make sense\n",
    "            print(\"ignoring voice pair:\", i, j)\n",
    "            continue\n",
    "        # get the patterns from the first voice of this pair\n",
    "        fullseq1 = alignment_strings[0]\n",
    "        fullseq2 = alignment_strings[1]\n",
    "        allthepatterns = filter_and_gather_patterns(allthepatterns, fullseq1)\n",
    "        allthepatterns = filter_and_gather_patterns(allthepatterns, fullseq2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "cf861fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "allthepattern_count = dict(Counter(allthepatterns))\n",
    "\n",
    "# get a pattern set P of patterns p\n",
    "allthepatterns = list(set(allthepatterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "c01a5bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allthepatterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "2922422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_strings(string):\n",
    "    \n",
    "    decode_dia_intervals = {'A': '6D', 'B': '5D', 'C': '4D', 'D': '3D', 'E': '2D', 'F': '1D', \n",
    "                            'G': '1A', 'H': '2A', 'I': '3A', 'J': '4A', 'K': '5A', 'L': '6A', 'M': '0A'}\n",
    "    \n",
    "    decode_string = \"\"\n",
    "\n",
    "    for letter in string:\n",
    "        trans = decode_dia_intervals[letter]\n",
    "        decode_string+=trans\n",
    "\n",
    "    return decode_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a5d072e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printLCSSubStr(X: str, Y: str,\n",
    "                   m: int, n: int):\n",
    " \n",
    "    # Create a table to store lengths of longest common suffixes of substrings.\n",
    "    # Note that LCSuff[i][j] contains length of longest common suffix of X[0..i-1] and\n",
    "    # Y[0..j-1]. The first row and first column entries have no logical meaning,\n",
    "    # they are used only for simplicity of program\n",
    "    LCSuff = [[0 for i in range(n + 1)]\n",
    "                 for j in range(m + 1)]\n",
    " \n",
    "    # To store length of the longest common substring\n",
    "    length = 0\n",
    " \n",
    "    # To store the index of the cell which contains the maximum value.\n",
    "    # This cell's index helps in building up the longest common substring from right to left.\n",
    "    row, col = 0, 0\n",
    " \n",
    "    # Following steps build LCSuff[m+1][n+1]\n",
    "    # in bottom up fashion.\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if i == 0 or j == 0:\n",
    "                LCSuff[i][j] = 0\n",
    "            elif X[i - 1] == Y[j - 1]:\n",
    "                LCSuff[i][j] = LCSuff[i - 1][j - 1] + 1\n",
    "                if length < LCSuff[i][j]:\n",
    "                    length = LCSuff[i][j]\n",
    "                    row = i\n",
    "                    col = j\n",
    "            else:\n",
    "                LCSuff[i][j] = 0\n",
    " \n",
    "    # if true, then no common substring exists\n",
    "    if length == 0:\n",
    "        #print(\"No common substring\")\n",
    "        return \"\"\n",
    " \n",
    "    # allocate space for the longest common substring\n",
    "    resultStr = ['0'] * length\n",
    " \n",
    "    # traverse up diagonally form the (row, col) cell until LCSuff[row][col] != 0\n",
    "    while LCSuff[row][col] != 0:\n",
    "        length -= 1\n",
    "        resultStr[length] = X[row - 1] # or Y[col-1]\n",
    "        # move diagonally up to previous cell\n",
    "        row -= 1\n",
    "        col -= 1\n",
    " \n",
    "    # required longest common substring\n",
    "    return ''.join(resultStr) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d504c19b",
   "metadata": {},
   "source": [
    "The following function returns the longest substring that appeared at least once.\n",
    "\n",
    "So, if there is length 4 substring repeated 4 times and a length 7 substring repeated 2 times, we take the length 7.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "164a2096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_pattern_length(seq):\n",
    "        best_performance = \"\"\n",
    "        candidates = []\n",
    "        for length in range(4, int(len(seq)*0.5)+1): \n",
    "            for start in range(0, len(seq)-length):\n",
    "                # get all the substrings of this length within the string, save in candidates\n",
    "                candidates.append(seq[start:start+length])\n",
    "        count_can = {}\n",
    "        allthepattern_count = dict(Counter(allthepatterns))\n",
    "\n",
    "        for candidate in candidates:\n",
    "                count_can[candidate] = seq.count(candidate)\n",
    "                if count_can[candidate] > 1:\n",
    "                    # if it is repeated more than once in the string\n",
    "                    if len(candidate) > len(best_performance):\n",
    "                        best_performance = candidate\n",
    "                    elif len(candidate) == len(best_performance) and count_can[candidate] > count_can[best_performance]:\n",
    "                        best_performance = candidate\n",
    "        \n",
    "        if best_performance == \"\":\n",
    "            return \"\", 0\n",
    "        return best_performance, count_can[best_performance]\n",
    "    \n",
    "def check_reduction(item):\n",
    "    success = False\n",
    "    frequent_substr, timesitappear = reduce_pattern_length(item)\n",
    "    if len(frequent_substr) > 4:\n",
    "        #print(frequent_substr, item, timesitappear)\n",
    "        if len(frequent_substr)*timesitappear >= 0.6*len(item):\n",
    "            print(\"extracted\", frequent_substr, \"from\", item)\n",
    "            # sucessfully reduced the pattern\n",
    "            return frequent_substr\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "59573055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_length_of_each_pattern(patterns_to_reduce, allthepattern_count):\n",
    "    beforereduction = {}\n",
    "    # reducedfinalpat is the new list that contains all valid patterns after reduction plus the ones that does not need to be reduced\n",
    "    reducedfinalpat = []\n",
    "    extracount_reducedpat = {}\n",
    "\n",
    "    for item in patterns_to_reduce:\n",
    "        # check the ones that has substring, see if their length can be reduced\n",
    "        if len(item) > 11:\n",
    "            #if the extracted pattern is too long, find longest repeated pattern within it\n",
    "            frequent_substr = check_reduction(item)\n",
    "            if frequent_substr != None:\n",
    "                if len(frequent_substr) > 23:\n",
    "                    # second round, if a frequent substring is takend and it is still quite long\n",
    "                    new_frequent_substr = check_reduction(frequent_substr)\n",
    "                    if new_frequent_substr != None:\n",
    "                        # if the second attempt is a success, take the twice reduced pattern\n",
    "                        if new_frequent_substr not in extracount_reducedpat:\n",
    "                            # this extracted pattern should have an extra count: \n",
    "                            # the times it appeared in item * times the item appeared in alignment segmentation\n",
    "                            extracount_reducedpat[new_frequent_substr] = allthepattern_count[item] * item.count(new_frequent_substr)\n",
    "                        else:\n",
    "                            #it has already been a reduction of another pattern, just add\n",
    "                            extracount_reducedpat[new_frequent_substr] += allthepattern_count[item] * item.count(new_frequent_substr)\n",
    "                        reducedfinalpat.append(new_frequent_substr)\n",
    "                        beforereduction[new_frequent_substr] = item\n",
    "                    else:\n",
    "                        # if the second attempt failed, take the result of first reduction\n",
    "                        if frequent_substr not in extracount_reducedpat:\n",
    "                            # this extracted pattern should have an extra count: \n",
    "                            # the times it appeared in item * times the item appeared in alignment segmentation\n",
    "                            extracount_reducedpat[frequent_substr] = allthepattern_count[item] * item.count(frequent_substr)\n",
    "                        else:\n",
    "                            #it has already been a reduction of another pattern, just add\n",
    "                            extracount_reducedpat[frequent_substr] += allthepattern_count[item] * item.count(frequent_substr) \n",
    "                        reducedfinalpat.append(frequent_substr)\n",
    "                        beforereduction[frequent_substr] = item\n",
    "                else:\n",
    "                    # if the extracted pattern is already not that long\n",
    "                    if frequent_substr not in extracount_reducedpat:\n",
    "                            # this extracted pattern should have an extra count: \n",
    "                            # the times it appeared in item * times the item appeared in alignment segmentation\n",
    "                            extracount_reducedpat[frequent_substr] = allthepattern_count[item] * item.count(frequent_substr)\n",
    "                    else:\n",
    "                            #it has already been a reduction of another pattern, just add\n",
    "                            extracount_reducedpat[frequent_substr] += allthepattern_count[item] * item.count(frequent_substr) \n",
    "                    reducedfinalpat.append(frequent_substr)\n",
    "                    beforereduction[frequent_substr] = item\n",
    "            else:\n",
    "                # if the reduction failed, take the original\n",
    "                reducedfinalpat.append(item)\n",
    "        else:\n",
    "            # otherwise keep it without reduction\n",
    "            reducedfinalpat.append(item)\n",
    "    \n",
    "    return reducedfinalpat, beforereduction, extracount_reducedpat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "415284e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducedpat, beforereduction, extracount_reducedpat = reduce_length_of_each_pattern(allthepatterns, allthepattern_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "527abc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_final_pattern(reducedfinalpat, strings, beatstrengths):\n",
    "    # Analyze patterns by the beat strength of the beginning note of patterns, \n",
    "    # and check if they have repeatedly appeared in the whole piece\n",
    "\n",
    "    count_pattern = {}\n",
    "    refined_finalpat = []\n",
    "    startonsets = []\n",
    "    startpitches = []\n",
    "    endonsets = []\n",
    "    endpitches = []\n",
    "\n",
    "    for pattern in reducedfinalpat:\n",
    "        stringnum = 0\n",
    "        beat_importance = 0\n",
    "        for string in strings:\n",
    "            # find the pattern in each voice\n",
    "            patpos_start, patpos_end, count, beatcount = find_pattern_pos(string, pattern, beatstrengths[stringnum])\n",
    "            beat_importance += beatcount\n",
    "            if pattern not in count_pattern:\n",
    "                count_pattern[pattern] = count\n",
    "            else:\n",
    "                count_pattern[pattern] += count\n",
    "            if count != 0:\n",
    "                print(\"Pattern\", pattern, \"appears in voice no.\", stringnum+1, \", first pos starts at \", patpos_start[0], \"end at\", patpos_end[0])\n",
    "            num = 0\n",
    "            for startpos in patpos_start:\n",
    "                startonsets.append(noteoffsets[stringnum][startpos])\n",
    "                endonsets.append(noteoffsets[stringnum][patpos_end[num]])\n",
    "                num+=1\n",
    "            stringnum+=1\n",
    "        if count_pattern[pattern] >= 2 and beat_importance >= 1:\n",
    "            # get rid of the ones that actually appeared less than 2 times in total\n",
    "            refined_finalpat.append(pattern)\n",
    "        else:\n",
    "            if count_pattern[pattern] < 2:\n",
    "                print(\"discard pattern\", pattern, \"because it only appered once in total.\")\n",
    "            elif beat_importance == 0:\n",
    "                print(\"discard pattern\", pattern, \"because it never appeared at the start of a bar.\")\n",
    "                print(\"this pattern can be decoded as\", decode_strings(pattern))\n",
    "            \n",
    "    return refined_finalpat, count_pattern, startonsets, endonsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "099c3a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict(Counter(reducedpat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "9194c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally, reduced_pattern_count is how many times it appeared in the extraction\n",
    "# but it shouldn't be counted like this\n",
    "\n",
    "# we modify it to occ(p) to count how many times the reduced pattern appeared in the alignment+length reduction process\n",
    "# for the ones that are reduced, we call the pattern before reduction an original pattern, then its occ should be:\n",
    "# times it appeared in the original pattern*occ(original pattern)+how many times it appeared as original pattern\n",
    "reduced_pattern_count = {}\n",
    "for pattern in reducedpat:\n",
    "    # initialize\n",
    "    reduced_pattern_count[pattern] = 0    \n",
    "    if pattern in beforereduction:\n",
    "        if pattern in allthepattern_count:\n",
    "            reduced_pattern_count[pattern] = allthepattern_count[pattern]\n",
    "        # if it was reduced, then it should be extra counted here\n",
    "        reduced_pattern_count[pattern] += extracount_reducedpat[pattern]\n",
    "    else:\n",
    "        # if it's not reduced, then it keep the count as the count after segmentation\n",
    "        reduced_pattern_count[pattern] = allthepattern_count[pattern]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "be24428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced_pattern_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6feee3",
   "metadata": {},
   "source": [
    "Get longest common substring between two long patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "7df8d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcscount = {}\n",
    "dictoflcs = {}\n",
    "for i in range(0, len(reducedpat)-1):\n",
    "    for j in range(i+1, len(reducedpat)):\n",
    "        #print(i, j)\n",
    "        pat1 = reducedpat[i]\n",
    "        pat2 = reducedpat[j]\n",
    "        if len(pat1) > 11 and len(pat2) > 11 and pat1 != pat2:\n",
    "            lcs = printLCSSubStr(pat1, pat2, len(pat1), len(pat2))\n",
    "            if len(lcs) >= 4 and lcs != pat1 and lcs != pat2: \n",
    "                # if lcs is not one of themselves. \n",
    "                # we are not interested in longest common substrings that are already in the pattern set\n",
    "                # because substring relationship will be investigated in DAG\n",
    "                if pat1 not in dictoflcs:\n",
    "                    dictoflcs[pat1] = []\n",
    "                if pat2 not in dictoflcs:\n",
    "                    dictoflcs[pat2] = []\n",
    "                dictoflcs[pat1].append(lcs)\n",
    "                dictoflcs[pat2].append(lcs)\n",
    "                if lcs in lcscount:\n",
    "                    lcscount[lcs] +=1\n",
    "                else:\n",
    "                    lcscount[lcs] = 1\n",
    "\n",
    "newdict = {}\n",
    "# print out the common strings that appeared more than 3 times\n",
    "for temp in lcscount:\n",
    "    if lcscount[temp] >= 2:\n",
    "        if temp not in reducedpat:\n",
    "            newdict[temp] = lcscount[temp]\n",
    "        #print(temp, decode_strings(temp), lcscount[temp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "13a49f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist = list(newdict)\n",
    "\n",
    "listofrelated = {}\n",
    "for i in range(0, len(newlist)-1):\n",
    "    for j in range(i+1, len(newlist)):\n",
    "        if newlist[i] in newlist[j] or newlist[j] in newlist[i]:\n",
    "            if newlist[i] not in listofrelated:\n",
    "                listofrelated[newlist[i]] = []\n",
    "            if newlist[j] not in listofrelated:\n",
    "                listofrelated[newlist[j]] = []\n",
    "            listofrelated[newlist[i]].append(newlist[j])\n",
    "            listofrelated[newlist[j]].append(newlist[i])\n",
    "\n",
    "# recude one cluster into one\n",
    "final_lcs = []\n",
    "for candidate in newlist:\n",
    "    mostcounted = candidate\n",
    "    if candidate in listofrelated:\n",
    "        for related in listofrelated[candidate]:\n",
    "            if lcscount[related] > lcscount[mostcounted]:# discarded: and abs(len(related)-len(candidate)) <= 4: # if it is counted more and not way too short or longer than the candidate\n",
    "                mostcounted = related\n",
    "            elif lcscount[related] == lcscount[mostcounted] and len(related) > len(mostcounted):# discarded: and abs(len(related)-len(candidate)) <= 4:\n",
    "                # take the longer one if the count is the same\n",
    "                mostcounted = related\n",
    "    if mostcounted not in final_lcs:\n",
    "        final_lcs.append(mostcounted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "fa53f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pattern_pos(string, pattern, beatstrength):\n",
    "    patpos_start = []\n",
    "    patpos_end = []\n",
    "    count = 0\n",
    "    beatcount = 0\n",
    "    for m in re.finditer(pattern, string):\n",
    "        count +=1\n",
    "        if beatstrength[m.start()] == 1 or m.start() <= 8: # if it starts at a strong beat or is in the beginning 8 notes of a voice\n",
    "            beatcount += 1\n",
    "        patpos_start.append(m.start())\n",
    "        patpos_end.append(m.end())\n",
    "    return patpos_start, patpos_end, count, beatcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "2980dc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of LCS patterns, not filtered with beat strength\n",
    "#print(final_lcs)\n",
    "#for i in final_lcs:\n",
    "#    print(decode_strings(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "acc3c838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Filtered by beat strength:\n",
    "testpat, count_pattern_test, startonsetstest,  endonsetstest = count_final_pattern(final_lcs, strings, beatstrengths)\n",
    "print(testpat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "acc204ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcsresults = []\n",
    "for i in testpat:\n",
    "    decoded_pat = decode_strings(i)\n",
    "    print(decoded_pat)\n",
    "    lcsresults.append(decoded_pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "01a18847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_substringandparents(allthepatterns, allthepattern_count):\n",
    "    \n",
    "    issubstring = {}\n",
    "    hassubstring = {}\n",
    "    count_as_substring = {}\n",
    "    count_as_parent = {}\n",
    "\n",
    "    for i in range(0, len(allthepatterns)-1):\n",
    "        for j in range(i+1, len(allthepatterns)):\n",
    "            if allthepatterns[i] in allthepatterns[j]:\n",
    "                parent = allthepatterns[j]\n",
    "                kid = allthepatterns[i]\n",
    "                times = parent.count(kid)\n",
    "\n",
    "                if kid not in issubstring:\n",
    "                    issubstring[kid] = 1\n",
    "                    count_as_substring[kid] = times * allthepattern_count[parent]\n",
    "                else:\n",
    "                    issubstring[kid] += 1\n",
    "                    count_as_substring[kid] += times * allthepattern_count[parent]\n",
    "\n",
    "                if parent not in hassubstring:\n",
    "                    hassubstring[parent] = 1\n",
    "                    count_as_parent[parent] = 1#times\n",
    "                else:\n",
    "                    hassubstring[parent] += 1\n",
    "                    count_as_parent[parent] += 1 \n",
    "\n",
    "            elif allthepatterns[j] in allthepatterns[i]:\n",
    "                parent = allthepatterns[i]\n",
    "                kid = allthepatterns[j]\n",
    "                times = parent.count(kid)\n",
    "\n",
    "                if kid not in issubstring:\n",
    "                    issubstring[kid] =1\n",
    "                    count_as_substring[kid] = times * allthepattern_count[parent]\n",
    "                else:\n",
    "                    issubstring[kid] += 1\n",
    "                    count_as_substring[kid] += times * allthepattern_count[parent]\n",
    "\n",
    "                if parent not in hassubstring:\n",
    "                    hassubstring[parent] = 1\n",
    "                    count_as_parent[parent] = 1 #times\n",
    "                else:\n",
    "                    hassubstring[parent] += 1\n",
    "                    count_as_parent[parent] += 1 #times\n",
    "\n",
    "    return issubstring, hassubstring, count_as_substring, count_as_parent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "6f7546d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "issubstring, hassubstring, count_as_substring, count_as_parent = count_substringandparents(reducedpat, reduced_pattern_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "2695cea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# rank the ones that are substrings of another detected pattern\n",
    "sortis = dict(Counter(issubstring))\n",
    "sorthas = dict(Counter(hassubstring))\n",
    "print(len(sorthas))\n",
    "print(len(sortis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "7579ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This counts the times each pattern appeared after original segmentation plus the times they are in other patterns,\n",
    "# plus the times other patterns showed up in them.\n",
    "\n",
    "def combined_count(reducedpat, count_as_parent, count_as_substring, reduced_pattern_count):\n",
    "    refined_combined = {}\n",
    "\n",
    "    for item in reducedpat:\n",
    "        refined_combined[item] = reduced_pattern_count[item]\n",
    "        if item in count_as_parent:\n",
    "            refined_combined[item] += count_as_parent[item]\n",
    "        if item in count_as_substring:\n",
    "            refined_combined[item] += count_as_substring[item]\n",
    "    \n",
    "    return refined_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "a213b4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined_count(reducedpat, count_as_parent, count_as_substring, reduced_pattern_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "d9b810d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "3ed173cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_combined_patterns(combined):\n",
    "    \n",
    "    finalpattern = []\n",
    "    for i in combined: \n",
    "\n",
    "        if len(i) < 3:\n",
    "            # if the length is shorter than 4 notes, discard\n",
    "            continue\n",
    "\n",
    "        if combined[i] > 1:\n",
    "            # keep the ones that has substring or is substring or repeated more than once\n",
    "            finalpattern.append(i)\n",
    "\n",
    "    finalpattern_combined = {}\n",
    "        \n",
    "    for thisone in finalpattern:\n",
    "        finalpattern_combined[thisone] = combined[thisone]\n",
    "\n",
    "    dict(Counter(finalpattern_combined))\n",
    "        \n",
    "    if len(finalpattern) > 20:\n",
    "        finalpattern_combined = dict(sorted(finalpattern_combined.items(), key = lambda x:-x[1], reverse = True)[-20:])\n",
    "    \n",
    "    return finalpattern_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "4be71143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the short ones\n",
    "top20patterns_combined = filter_combined_patterns(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "3d8ef126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dict(Counter(top20patterns_combined)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "17194f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not filtered by beat strength, top 20\n",
    "#for printpattern in list(top20patterns_combined):\n",
    "#    print(decode_strings(printpattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "42b4c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"the followings are not ranked well thus discarded in the count\")\n",
    "#for i in reducedpat:\n",
    "#    if i not in top20patterns_combined:\n",
    "#        print(decode_strings(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "d10503af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern MMGMMFMFMEMIFMEMFMMMM appears in voice no. 1 , first pos starts at  987 end at 1008\n",
      "discard pattern MMGMMFMFMEMIFMEMFMMMM because it only appered once in total.\n",
      "Pattern MMMM appears in voice no. 1 , first pos starts at  0 end at 4\n",
      "Pattern MMMM appears in voice no. 2 , first pos starts at  481 end at 485\n",
      "Pattern FGFFIGM appears in voice no. 1 , first pos starts at  289 end at 296\n",
      "discard pattern FGFFIGM because it never appeared at the start of a bar.\n",
      "this pattern can be decoded as 1D1A1D1D3A1A0A\n",
      "Pattern FCFMILDI appears in voice no. 1 , first pos starts at  298 end at 306\n",
      "discard pattern FCFMILDI because it never appeared at the start of a bar.\n",
      "this pattern can be decoded as 1D4D1D0A3A6A3D3A\n",
      "Pattern MEM appears in voice no. 1 , first pos starts at  967 end at 970\n",
      "Pattern MEM appears in voice no. 2 , first pos starts at  15 end at 18\n",
      "discard pattern MEM because it never appeared at the start of a bar.\n",
      "this pattern can be decoded as 0A2D0A\n",
      "Pattern MFMFMEMIFMEMFMJFMC appears in voice no. 1 , first pos starts at  963 end at 981\n",
      "discard pattern MFMFMEMIFMEMFMJFMC because it only appered once in total.\n",
      "Pattern GFFIGM appears in voice no. 1 , first pos starts at  64 end at 70\n",
      "Pattern MGMEMGMFMMMIMDIMD appears in voice no. 2 , first pos starts at  445 end at 462\n",
      "discard pattern MGMEMGMFMMMIMDIMD because it only appered once in total.\n",
      "Pattern ILDI appears in voice no. 1 , first pos starts at  74 end at 78\n",
      "discard pattern ILDI because it never appeared at the start of a bar.\n",
      "this pattern can be decoded as 3A6A3D3A\n",
      "Pattern DEG appears in voice no. 1 , first pos starts at  62 end at 65\n",
      "discard pattern DEG because it never appeared at the start of a bar.\n",
      "this pattern can be decoded as 3D2D1A\n"
     ]
    }
   ],
   "source": [
    "#finalpat, count_pattern, startonsets,  endonsets = count_final_pattern(reducedfinalpat, strings, beatstrengths)\n",
    "\n",
    "finalpat, count_pattern, startonsets,  endonsets = count_final_pattern(list(top20patterns_combined), strings, beatstrengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "2aacc75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_results(finalpat, count_pattern, combined, beforereduction):\n",
    "    \n",
    "    decoded_patterns = []\n",
    "    decoded_patterns_weighed = {}\n",
    "    decoded_patterns_count = {}\n",
    "    decoded_patterns_combined = {}\n",
    "    \n",
    "    decode_dia_intervals = {'A': '6D', 'B': '5D', 'C': '4D', 'D': '3D', 'E': '2D', 'F': '1D', \n",
    "                            'G': '1A', 'H': '2A', 'I': '3A', 'J': '4A', 'K': '5A', 'L': '6A', 'M': '0A'}\n",
    "\n",
    "    # decode all the candidates for patterns\n",
    "    for pattern in finalpat:\n",
    "        trans_pattern = \"\"\n",
    "        for letter in pattern:\n",
    "            trans = decode_dia_intervals[letter]\n",
    "            trans_pattern += trans\n",
    "\n",
    "        decoded_patterns_count[trans_pattern] = count_pattern[pattern]\n",
    "        \n",
    "        if pattern in combined:\n",
    "            # some might be reduced to a shorter pattern\n",
    "            decoded_patterns_combined[trans_pattern] = combined[pattern]\n",
    "        else:\n",
    "            decoded_patterns_combined[trans_pattern] = combined[beforereduction[pattern]]\n",
    "        decoded_patterns.append(trans_pattern)\n",
    "        \n",
    "    return decoded_patterns, decoded_patterns_combined, decoded_patterns_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d1bacd",
   "metadata": {},
   "source": [
    "Strings of intervals of each voice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "52f91910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0A0A0A0A0A6A0A6D0A0A6A0A6D1A0A4A0A4D0A0A4A0A4D1A0A3A3D1A0A0A4A0A4D1A0A3A3D1A0A0A4A0A4D1A0A3A3D1A0A0A0A1A0A1A0A2A1D1D1D4A3D3A3D2D1A1D1D3A1A0A0A4D1D0A3A6A3D3A3D2D1A1D1D3A1A0A0A4D1D0A3A6A3D3A3D2D1A1D1D3A1A0A4D1D0A5A2A1D0A6D1A0A1D5D5A4A3D3D2D2A0A4D1D5D5A6A2A0A1D5D5A6D0A6A6D0A6A6D0A5A5D0A5A6D0A6A6D0A5A6D0A6A6D0A6A6D0A5A6D0A6A1D1A1D1D1D3D0A1D4A1D5D5A5D0A2A3D3D2D2A0A4D1D5D5A6A2A0A1D5D5A6D0A6A6D0A6A6D0A5A5D0A5A6D0A6A6D0A5A6D0A5A5D0A5A6D0A5A5D0A5A6D0A6A6D0A6A0A3D3A3D3D2A1D1D3A1A0A0A4D1D0A3A6A3D3A3D2D1A1D1D3A1A0A0A4D1D0A3A6A3D3A3D2D1A1D1D3A1A0A4D1D0A5A0A1A0A6D2A1D0A1D1D4A3D3A3D2D1A1D1A1D1D3A1A0A0A1A1D4D1D0A3A6A3D3A3D2D1A1D1A1D1D3A1A0A0A1A1D4D1D0A3A6A3D3A3D2D1A1D1A1D1D3A1A0A4D1D0A5A2A1D0A6D1A0A1D5D5A4A3D3D2D2A0A4D1D5D5A6A2A0A1D5D5A6D0A6A6D0A6A6D0A5A5D0A5A6D0A6A6D0A5A6D0A6A6D0A6A6D0A5A6D0A6A1D1A1D1D1D3D0A1D4A1D5D5A5D0A2A3D3D2D2A0A4D1D5D5A6A2A0A1D5D5A6D0A6A6D0A6A6D0A5A5D0A5A6D0A6A6D0A5A6D0A5A5D0A5A6D0A5A5D0A5A6D0A6A6D0A6A0A3D3A3D3D2A1D1D3A1A0A0A4D1D0A3A6A3D3A3D2D1A1D1D3A1A0A0A4D1D0A3A6A3D3A3D2D1A1D1D3A1A0A4D1D0A5A0A1A0A6D2A1D0A1D1D4A3D3A3D2D1A1D1A1D1D3A1A0A0A1A1D4D1D0A3A6A3D3A3D2D1A1D1A1D1D3A1A0A0A1A1D4D1D0A3A6A3D3A3D2D1A1D1A1D1D3A1A0A4D1D0A5A2A1D0A6D1A4A0A1A3D1A2D1D0A4A2A1D0A3D1A2D1D4D1A0A4A1D4A0A1D1A0A2A1D1D1D4D5A1A3D1A2D1D0A4A2A1D0A3D1A2D1D4D1A0A4A1D4A0A1D1A0A2A1D1D0A1D4D5A1A1D1D1A1A1A2A1D1D6A0A1A1D1D1D1A2D2A1A1D1D1A1A1A2A1D1D6A0A1A1D1D1D1A2D3A1A1D1D1A1A1A2A1D1D6A0A1A1D1D1D1A2D1A1A1D1D1A1A1A2A1D1D6A0A1A1D1D1D4A1D2D1A1D1D1A1A1A2A1D1D6A0A1A1D1D1D1A2D2A1A1D1D1A1A1A2A1D1D6A0A1A1D1D1D1A2D3A1A1D1D1A1A1A2A1D1D6A0A1A1D1D1D1A2D1A1D1A1A1A2A1D1D6A0A1A1D1D1D4D6A0A3A1D3D1D4D4A0A1A1D1D1D3D0A1A1D6D6A5D4A1D2A5D0A5A5D0A5A5D0A5A5D0A5A6D0A5A6D0A5A5D0A5A6D0A5A5D0A5A6D0A6A6D0A6A0A3D3A3D3D2A1D1D3A1A0A0A4D1D0A3A6A3D3A3D2D1A1D1D3A1A0A0A4D1D0A3A6A3D3A3D2D1A1D1D3A1A0A0A4D1D0A5A1A0A6D2A1D0A1D1D4A3D3A3D2D1A1D1A1D1D3A1A0A0A1A1D4D1D0A3A6A3D3A3D2D1A1D1A1D1D3A1A0A0A1A1D4D1D0A3A6A3D3A3D2D1A1D1A1D1D3A1A0A0A4D1D0A0A1D0A6D1A0A1A0A0A0A1A0A0A1D0A1D0A2D0A3A1D0A2D0A1D0A4A1D0A4D0A1D0A5A1A0A0A0A1A0A0A1D0A1D0A2D0A3A1D0A2D0A1D0A0A0A0A4A1A1D3A3D1A1D0A1D0A2D0A1D0A0A4A1A1D3A3D1A1D0A1D0A2D0A1D0A0A0A0A0A0A4A1D0A2D0A1D0A\n",
      "\n",
      "0A0A4D2A6D4D0A0A4D2A6D4D6A6D5A0A2D0A2A2A1D2A0A2D4A0A4D0A4D4D0A0A4D0A4D4D0A0A3A0A0A0A2A2D4D2A6D4D0A0A4D2A5A3D0A0A4D2A2D1A0A5D1A3A0A3D0A0A3A0A4D1A0A0A4D2A5A3D0A0A4D2A2D1A0A5D1A3A0A3D2A4D0A0A4D0A4D4D0A0A4D0A4D4D0A0A3A2A2D0A2A2A1D2A0A2D4A0A4D0A4D4D0A0A4D0A4D4D0A0A4D0A0A0A2A2D4D2A6D4D0A0A4D2A5A3D0A0A4D2A2D1A0A5D1A3A0A3D0A0A3A0A4D1A0A0A4D2A5A3D0A0A4D2A2D1A0A5D1A3A0A3D2A4D0A0A4D0A4D4D0A0A4D0A4D4D0A0A3A2A2D0A2A2A1D2A0A2D4A0A4D0A4D4D0A0A4D0A4D4D0A0A4D0A0A0A2A2D4D2A2A0A1A3D1A2D1D0A4A2A1D0A3D1A2D1D6D3A0A3D3A0A3D3A0A3D3A0A1A3D1A2D1D0A4A2A1D0A3D1A2D1D6D3A0A3D3A0A3D3A0A3D3A6D5A0A5D5A0A4D2A0A6D2A0A6D5A0A5D5A0A4D2A0A6D2A0A5D5A0A5D5A0A4D2A0A6D2A0A0A5A0A5D5A0A4D2A0A2D2A0A2D2A0A2D2A0A2D2A0A6D2A0A6D5A0A5D5A0A4D2A0A6D2A0A5D5A0A5D5A0A4D2A0A6D2A0A0A5A0A5D5A0A4D2A2D2A2D0A0A2A2D2A4D0A0A4D0A4D4D0A0A4D0A4D4D0A0A3A2A2D0A2A2A1D2A0A2D4A0A4D0A4D4D0A0A4D0A4D4D0A0A3A0A0A0A2A2D4D2A0A2D3A0A3D3A0A3D1A0A1D5A0A5D1A0A1A0A2D0A1A0A1D0A0A0A3A0A3D3A0A3D1A0A1D5A0A5D3A0A3D2A0A2D4A0A4D0A0A0A4A0A0A0A0A4D3A0A3D0A0A0A4A0A0A0A0A4D5A0A0A0A3A1D2A0A0A0A0A5D0A0A2D0A0A2D0A0A0A0A0A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Strings of intervals of each voice\n",
    "decoded_strings = []\n",
    "for string in strings:\n",
    "    decoded = decode_strings(string)\n",
    "    decoded_strings.append(decoded)\n",
    "    print(decoded)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "e3811e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern: 0A0A0A0A\n",
      "importance score: 2 occurrence: 7\n",
      "Pattern: 1A1D1D3A1A0A\n",
      "importance score: 2 occurrence: 18\n"
     ]
    }
   ],
   "source": [
    "# Decode patterns\n",
    "decoded_patterns, decoded_patterns_combined, decoded_patterns_count = decode_results(finalpat, count_pattern, combined, beforereduction)\n",
    "\n",
    "for pattern in decoded_patterns:\n",
    "        print(\"Pattern:\", pattern)\n",
    "        print(\"importance score:\", decoded_patterns_combined[pattern],\n",
    "              \"occurrence:\", decoded_patterns_count[pattern])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "01510636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0A0A0A0A', '1A1D1D3A1A0A']"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final patterns(LCS not included), FILTERED BY BEAT STRENGTH:\n",
    "decoded_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "b94f045a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0A0A0A0A', '1A1D1D3A1A0A']\n"
     ]
    }
   ],
   "source": [
    "# THE FINAL LIST\n",
    "final_results = decoded_patterns+lcsresults\n",
    "\n",
    "print(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7ba74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43819f65",
   "metadata": {},
   "source": [
    "Danny's version, ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5dfb1b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jkupddtest/gibbonsmono/H/midi/occ1.midi_part1_DD.csv', 'jkupddtest/gibbonsmono/H/midi/occ2.midi_part1_DD.csv']\n",
      "jkupddtest/gibbonsmono/H/midi/occ1.midi_part1_DD.csv\n",
      "0A1D1D1D1D0A7A1D1D4D3A1D1A2D1A3D1A0A4D\n",
      "jkupddtest/gibbonsmono/H/midi/occ2.midi_part1_DD.csv\n",
      "0A1D1D1D1D0A7A1D1D4D3A1D1A2D1A3D1A0A4D\n"
     ]
    }
   ],
   "source": [
    "#groundtruthpath1 = \"jkupddtest/gibbonsmono/silverswan.krn\"\n",
    "import pandas as pd\n",
    "gtfiles = glob.glob(\"jkupddtest/gibbonsmono/H/midi/*.csv\")\n",
    "print(gtfiles)\n",
    "gtstrings = []\n",
    "for gtfile in gtfiles:\n",
    "    print(gtfile)\n",
    "    with open(gtfile, 'r') as file:\n",
    "        df = pd.read_csv(file)\n",
    "        #print(df)\n",
    "        #for midi_note_num in df[\"midi_note_num\"]:\n",
    "        #    print(midi_note_num)\n",
    "        count = 0\n",
    "        gtstring = \"\"\n",
    "        for diatonic in df[\"diatonic_interval\"]:\n",
    "            if count == 0:\n",
    "                # ignore the first \"interval\" number which is always 0\n",
    "                count+=1\n",
    "                continue\n",
    "            count+=1\n",
    "            # just to format the input\n",
    "            if diatonic < 0:\n",
    "                dia = str(abs(diatonic)) + 'D'\n",
    "            else:\n",
    "                dia = str(abs(diatonic)) + 'A'\n",
    "            gtstring += dia\n",
    "        gtstrings.append(gtstring)\n",
    "        print(gtstring)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec20cf94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0A1D1D1D1D0A7A1D1D4D3A1D1A2D1A3D1A0A4D'}\n"
     ]
    }
   ],
   "source": [
    "# a set of strings of annotated ground truth\n",
    "print(set(gtstrings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e0df0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 0A1D1D1D1D0A7A1D1D4D3A1D1A2D1A3D1A0A4D not in original score\n",
      "pattern 0A1D1D1D1D0A7A1D1D4D3A1D1A2D1A3D1A0A4D not in original score\n"
     ]
    }
   ],
   "source": [
    "# check if they are in the scores\n",
    "for pattern in gtstrings:\n",
    "    count = 0\n",
    "    for decodedstring in decoded_strings:\n",
    "        count += decodedstring.count(pattern)\n",
    "    if count == 0:\n",
    "        print(\"pattern\", pattern, \"not in original score\")\n",
    "    elif count == 1:\n",
    "        print(\"pattern\", pattern, \"only appeared once\")\n",
    "    else:\n",
    "        print(\"pattern\", pattern, \"appeared\", count, \"times in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e070111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee6b243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "befb9cda",
   "metadata": {},
   "source": [
    "Discarded: get patterns from ground truth folders.. original ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "31669153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jkupddtest/chopinmono/D', 'jkupddtest/chopinmono/A', 'jkupddtest/chopinmono/mazurka24-4.krn']\n"
     ]
    }
   ],
   "source": [
    "# Get patterns from ground truth\n",
    "\n",
    "dict_wordtonum = {\"Unison\": '0', \"Second\": '1', \"Third\": '2', \"Fourth\": '3', \"Fifth\": '4', \"Sixth\": '5', \"Seventh\": '6'}\n",
    "\n",
    "groundtruthpatterns = []\n",
    "print(glob.glob(\"jkupddtest/chopinmono/*\"))\n",
    "filenames = glob.glob(\"jkupddtest/chopinmono/B/*.csv\")\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    with open(filename, 'r') as file:\n",
    "        csvreader = csv.reader(file)\n",
    "        gts = []\n",
    "        gtm = []\n",
    "        pattern_gt = []\n",
    "        for row in csvreader:\n",
    "            gts.append(float(row[0]))\n",
    "            gtm.append(float(row[1]))\n",
    "        for i in gtm:\n",
    "            pattern_gt.append(m21.note.Note(i))\n",
    "        pattern_string = \"\"\n",
    "        interval_string = \"\"\n",
    "        for i in pattern_gt:\n",
    "            pattern_string += str(i)\n",
    "            \n",
    "        for i in range(1, len(pattern_gt)):           \n",
    "            gap = pattern_gt[i].pitch.diatonicNoteNum - pattern_gt[i-1].pitch.diatonicNoteNum\n",
    "            if gap >= 0:\n",
    "                direction = 'A'\n",
    "            else:\n",
    "                direction = 'D'\n",
    "            m21_interval_directed = m21.interval.Interval(noteStart=pattern_gt[i-1], noteEnd=pattern_gt[i]).directedSimpleNiceName\n",
    "            arr_diatonic = m21_interval_directed.split(\" \")\n",
    "            m21_generic = dict_wordtonum[arr_diatonic[-1]]\n",
    "            m21_interval = m21_generic+direction\n",
    "            \n",
    "            interval_string+=m21_interval\n",
    "            \n",
    "        print(interval_string)\n",
    "\n",
    "        groundtruthpatterns.append(interval_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f292cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(groundtruthpatterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b761cec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pattern in groundtruthpatterns:\n",
    "    count = 0\n",
    "    for decodedstring in decoded_strings:\n",
    "        count += decodedstring.count(pattern)\n",
    "    if count == 0:\n",
    "        print(\"pattern\", pattern, \"not in original score\")\n",
    "    elif count == 1:\n",
    "        print(\"pattern\", pattern, \"only appeared once\")\n",
    "    else:\n",
    "        print(\"pattern\", pattern, \"appeared\", count, \"times in total\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
