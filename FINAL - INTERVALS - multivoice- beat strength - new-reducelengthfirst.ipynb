{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1285b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21 as m21\n",
    "import re\n",
    "from collections import Counter\n",
    "from swalign_local import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1039d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read input data:\n",
    "import music21 as m21\n",
    "import re\n",
    "from collections import Counter\n",
    "from swalign_local import *\n",
    "import csv\n",
    "import glob\n",
    "\n",
    "#score_path = \"jkupddtest/bachmono/wtc2f20.krn\"\n",
    "score_path = \"jkupddtest/beethovenmono/sonata01-3.krn\"\n",
    "#score_path = \"jkupddtest/mozartmono/sonata04-2.krn\"\n",
    "#score_path = \"jkupddtest/gibbonsmono/silverswan.krn\"\n",
    "#score_path = \"jkupddtest/chopinmono/mazurka24-4.krn\"\n",
    "#score_path = '~/facets-search-engine/data/Beethoven9thOdeToJoy.xml'\n",
    "\n",
    "raw_score = m21.converter.parse(score_path)\n",
    "num_of_parts = len(raw_score.parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccee41a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51ea7e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "voices = []\n",
    "for part in raw_score.parts:\n",
    "    voices.append(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acce90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Get diatonic scale degree sequence from all voices\n",
    "\n",
    "def get_diatonic_intervals(voice):\n",
    "    \n",
    "    # get key / root information:\n",
    "    roots = [key.tonic for key in voice.recurse().getElementsByClass(m21.key.Key)]\n",
    "    diatonic_root = roots[0].diatonicNoteNum if roots != [] else voice.analyze('key').tonic.diatonicNoteNum\n",
    "    #print(diatonic_root)\n",
    "    key = voice.analyze('key')\n",
    "\n",
    "    noteoffset = []\n",
    "    midi = []\n",
    "    #timesig = m21_score.getContextByClass(m21.meter.TimeSignature)\n",
    "    #barlength = timesig.barduration\n",
    "\n",
    "    dict_wordtonum = {\"Unison\": '0', \"Second\": '1', \"Third\": '2', \"Fourth\": '3', \"Fifth\": '4', \"Sixth\": '5', \"Seventh\": '6'}\n",
    "        \n",
    "    dict_encode_dia_intervals = {\"6D\": 'A', '5D': 'B', '4D': 'C', '3D':'D', '2D':'E', '1D':'F', \n",
    "                                     '1A':'G', '2A':'H', '3A':'I', '4A':'J', '5A': 'K', '6A':'L', '0A': 'M'}\n",
    "        \n",
    "    diatonic_intervals = []\n",
    "    beatstrength = []\n",
    "    previous_note = None\n",
    "\n",
    "    onset = 0\n",
    "    for thisnote in voice.recurse().notes:\n",
    "        onset += thisnote.offset\n",
    "        \n",
    "        # We ignore rests\n",
    "        if thisnote.isRest: \n",
    "                # If the rest is a full measure, part of a multi-measure rest: we need to adjust\n",
    "                continue\n",
    "        \n",
    "        noteoffset.append(onset)\n",
    "        beatstrength.append(thisnote.beatStrength)\n",
    "        #if thisnote.isNote:\n",
    "        #    midi.append(thisnote.pitch.midi)\n",
    "        #elif thisnote.isChord:\n",
    "        #    midi.append(thisnote.root().midi)\n",
    "            \n",
    "        if previous_note is None:\n",
    "                previous_note = thisnote\n",
    "        else:\n",
    "                if thisnote.isNote and previous_note.isNote:\n",
    "                    # gap = number of semi-tones of the current interval \n",
    "                    gap = thisnote.pitch.diatonicNoteNum - previous_note.pitch.diatonicNoteNum\n",
    "                elif thisnote.isChord and previous_note.isNote:\n",
    "                    gap = thisnote.root().diatonicNoteNum - previous_note.pitch.diatonicNoteNum\n",
    "                elif thisnote.isChord and previous_note.isChord:\n",
    "                    gap = thisnote.root().diatonicNoteNum - previous_note.root().diatonicNoteNum\n",
    "                elif thisnote.isNote and previous_note.isChord:\n",
    "                    gap = thisnote.pitch.diatonicNoteNum - previous_note.root().diatonicNoteNum\n",
    "                # if a pitch change is detected\n",
    "                    \n",
    "                if gap != 0:\n",
    "                    \n",
    "                    if gap > 0:\n",
    "                        #  if the semi-tone difference between the current and the previous item > 0, it is an ascending interval.\n",
    "                        direction = 'A'\n",
    "                    else:\n",
    "                        #  otherwise, it is a descending interval.\n",
    "                        direction = 'D'\n",
    "\n",
    "                    # Get intervals using music21\n",
    "                    \"\"\"\n",
    "                            \"directedSimpleNiceName\" examples: \"Descending Doubly-Diminished Fifth\", \"Ascending Perfect Fourth\", \"Ascending Doubly-Augmented Fourth\"\n",
    "                            \"simpleName\" examples: dd5, P5, AA4. There's no direction information\n",
    "                            Since it only executes when a pitch interval is detected, \"unison\" refers to an augmented unison, a.k.a minor second\n",
    "                    \"\"\"\n",
    "                    # take intervals between root notes if there exists any chord\n",
    "                    if previous_note.isChord:\n",
    "                        startnote = previous_note.root()\n",
    "                    else:\n",
    "                        startnote = previous_note\n",
    "                    if thisnote.isChord:\n",
    "                        endnote = thisnote.root()\n",
    "                    else:\n",
    "                        endnote = thisnote\n",
    "                        \n",
    "                    m21_interval_directed = m21.interval.Interval(noteStart=startnote, noteEnd=endnote).directedSimpleNiceName\n",
    "\n",
    "                    arr_diatonic = m21_interval_directed.split(\" \")\n",
    "\n",
    "                    m21_generic = dict_wordtonum[arr_diatonic[-1]]\n",
    "                    \n",
    "                    # m21_interval: 2A, 3D etc...\n",
    "                    m21_interval = m21_generic+direction\n",
    "                    if m21_generic == \"0\":\n",
    "                        m21_interval = '0A'\n",
    "                    # to make each m21_interval unique, show direction and each as single character in string, we encode the diatonic intervals as letters\n",
    "                    encode_interval = dict_encode_dia_intervals[m21_interval]\n",
    "                    diatonic_intervals.append(encode_interval)\n",
    "\n",
    "                else:\n",
    "                    # We take the interval between two consecutive pitches as 0A\n",
    "                    encode_interval = dict_encode_dia_intervals['0A']\n",
    "                    diatonic_intervals.append(encode_interval)\n",
    "                previous_note = thisnote\n",
    "            \n",
    "    string = \"\"\n",
    "    for i in diatonic_intervals:\n",
    "        string += str(i)\n",
    "        \n",
    "    return string, key, noteoffset, midi, beatstrength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aea3f3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677 678\n",
      "GEGEMDIDLFHMGEGEMDIDLFHMIJMMBGGIFFIBHDGLFBHDGMGEGEMDIDLFHMGEGEMDIDLFHMIJMMBGGIFFIBHDGLFBHDGHGEGEJEGEMHDGKFCHDGHFFHFFHFFGGFFGFFFGFFFGGFHAGHGHHFGGEMFGGEMFGGEMFGGEMMHDGFFBHDGDCJGEGEJEGEMHDGKFCHDGHFFHFFHFFGGFFGFFFGFFFGGFHAGHGHHFGGEMFGGEMFGGEMFGGEMMHDGFFBHDGDCJKFGEGGGFGEGGGFGGFFFFGGFEHHIBFJHALFBJFCFHEEFHFMKFGEGGGFGEGGGFGGFFFFGGFEHHIBFJHALFBJFCFHEEFHFMHFGEGGGFGEGGGFGEGGGEHHIHBFMEGGGFGEGGHGGDFGEGGJFGEGGGFFGFFFGFFFGFFCIFGEGGGFGEGGGFGGFFFFGGFEHHIECFFHICDHFGEGGGFGEGGGFGEGGGEHHIHBFMEGGGFGEGGHGGDFGEGGJFGEGGGFFGFFFGFFFGFFCIFGEGGGFGEGGGFGGFFFFGGFEHHIECFFHICHGEGEMDIDLFHMGEGEMDIDLFHMIJMMBGGIFFIBHDGLFBHDGHGEGEJEGEMHDGKFCHDGHFFHFFHFFGGFFGFFFGFFFGGFHAGHGHHFGGEMFGGEMFGGEMFGGEMMHDGFFBHDGDC\n",
      "678\n",
      "[0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.25, 1.0, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.25, 1.0, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.25, 1.0, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0]\n",
      "549 550\n",
      "MGFFGBMGFFGHFFFGGGBIHBIEMGFFGBMGFFGHFFFGGGBIHBIFHFHEHFHMBIHBIDIDIHFFGGFFGFFFGFFFGGFHAGMKGEMGEMFHMFHKFMMGHMAMLGAMKEBBIDIGHFHEHFHMBIHBIDIDIHFFGGFFGFFFGFFFGGFHAGMKGEMGEMFHMFHKFMMGHMAMLGAMKEBBIDIMHHGCFFHICHHEFGEGGGFGEGGGFGEGGGDGEICGMIMIHHGCFFHICHHEFGEGGGFGEGGGFGEGGGDGEICGMIMMMLALAKBHFGEGGGFGEGGGFGEGGGFGEGGGFGEGGGFGEGGGFFGFFFGFFFGFFFCHHGCFFHICHHEFGEGGGFGEGGGFGFFFFMJMLALAKBHFGEGGGFGEGGGFGEGGGFGEGGGFGEGGGFGEGGGFFGFFFGFFFGFFFCHHGCFFHICHHEFGEGGGFGEGGGFGFFFFMMMGFFGBMGFFGHFFFGGGBIHBIFHFHEHFHMBIHBIDIDIHFFGGFFGFFFGFFFGGFHAGMKGEMGEMFHMFHKFMMGHMAMLGAMKEBBIDI\n",
      "550\n",
      "[0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.5, 0.25, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "strings = []\n",
    "noteoffsets = []\n",
    "midis = []\n",
    "keys = []\n",
    "beatstrengths = []\n",
    "\n",
    "for voice in voices:\n",
    "    string, key, noteoffset, midi, beatstrength = get_diatonic_intervals(voice)\n",
    "    strings.append(string)\n",
    "    noteoffsets.append(noteoffset)\n",
    "    beatstrengths.append(beatstrength)\n",
    "    midis.append(midi)\n",
    "    keys.append(key)\n",
    "    print(len(string), len(beatstrength))#, len(midi))\n",
    "    print(string)\n",
    "    print(len(noteoffset))\n",
    "    #print(midi)\n",
    "    print(beatstrength)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a08b5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smith-Waterman alignment between the two input sequences\n",
    "def swm_alignment(string1, string2):\n",
    "    match = 2\n",
    "    mismatch = -2\n",
    "    scoring = NucleotideScoringMatrix(match, mismatch)\n",
    "    sw = LocalAlignment(scoring)#, gap_extension_penalty = -5) \n",
    "    \n",
    "    alignment = sw.align(string1, string2)\n",
    "    alignment_strings = alignment.dump()\n",
    "\n",
    "    simi_score = alignment.matches / (alignment.mismatches + alignment.matches)\n",
    "    \n",
    "    return alignment_strings, simi_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94591d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_gather_patterns(allthepatterns, fullseq):\n",
    "    pat = fullseq.split('-')\n",
    "    print(\"num of pat in this seq:\", len(pat))    \n",
    "    for pattern in pat:\n",
    "        # Get rid of the sequence shorter than 4; combine all alignment patterns into all pattern list\n",
    "        if len(pattern) > 2:\n",
    "            allthepatterns.append(pattern)\n",
    "    return allthepatterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ab996d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  66 HFFGGFFGFFFGFFFGGFHAGMKG-----EM--GEMF--HMFHKFMM--G---HMAMLG----------AM---KEBBIDIGH-FHEHFHMBIHBIDIDIHFFGGFFGFFFGFFFGGFHAGMKG-----EM--GEMF--HMFHKFMMGHMAMLGAMKEBBIDIMHHGCFF-H--ICHHEFGEGGGFGEGGGFGEG----GGDGEICGMIMIHHGCFFH-----IC-HHEF-----GEGGGFGEGGGFGEG----GGDGE--ICGMIMMMLALAKB----H--F-----GEGGGFGEGGGFGEGGG------FGEGGGFGEGG--G-FGEGGGFFG---FFFGFFFGFFFCHHGCFFHICHHEFGEGGGFGEGGGF-GFFFFMJMLALAKBH----F------GEGGGFGEGGGFGEGGG------FGEGGGFGEGG--G-FGEGGGFFG---FFFGFFFGFFFCHHGCFFHICHHEFGEGGGFGEGGGF-GFFFFMMMGFFGBMGFFGH---FF---FG-G---------G----BI---H-----B--I-F--H---F-H----E-------H---F-HMBIHBIDIDIHFF------GGFFGFFFGFFFGGFHAGMKG-----EM--GEMF--HMF 528\n",
      "           ||||||||||||||||||||| .|     ||  ||||  .||...||  |   |   .|          .|   | ...| || || .||           |||||||||||||||||||| .|     ||  ||||  .||     |     |.|       ||.| || |  .| ..|||||||||||||| |    || .|       ||..|.|     .| |.||     ||||||||||||| |    || .|  |    ....|| .|    |  |     |||||||||||||||||      |.|||||||||  | ||| ||.||   .||||||||||   | ||  |  .||||||||||||| |||||    .....|    |      |||||||||||||||||      |.|||||||||  | ||| ||.||   .||||||||||   | ||  |  .||||||||||||| |||||   |  |   |..|   ||   .| |         |    .|   |     |  | |  |   | |    |       |   | |      |  .|||      |||||||||||||||||| .|     ||  ||||  .||\n",
      "Ref  : 117 HFFGGFFGFFFGFFFGGFHAG-HGHHFGGEMFGGEMFGGEMFGGEMMHDGFFBH---DGDCJGEGEJEGEMHDGK-FCHD-GHFFH-FFH-----------FFGGFFGFFFGFFFGGFHAG-HGHHFGGEMFGGEMFGGEMF-----G-----GEM-------MHDG-FFBHDGDC-JKFGEGGGFGEGGGFG-GFFFFGG-FE-------HHIBFJHALFBJFCFHEEFHFMKFGEGGGFGEGGGFG-GFFFFGG-FEHHI----BFJHAL-FBJFCFHEEFHFMHFGEGGGFGEGGGFGEGGGEHHIHBFMEGGGFGEGGHGGDFGE-GGJFGEGGGFFGFFFGFFF---G-FF--C--IFGEGGGFGEGGGFGGFFFF----GGFEHHIECFFHICDHFGEGGGFGEGGGFGEGGGEHHIHBFMEGGGFGEGGHGGDFGE-GGJFGEGGGFFGFFFGFFF---G-FF--C--IFGEGGGFGEGGGFGGFFFF---G--G---FEHHIECFFHICHGEGEMDIDLFHMGEGEMDIDLFHMIJMMBGGIFFIBHDGLFBHDGHGEGEJEGEMHDGKFCH------D--GHFFHFFHFFGGFFGFFFGFFFGGFHAG-HGHHFGGEMFGGEMFGGEMF 661\n",
      "\n",
      "num of pat in this seq: 176\n",
      "num of pat in this seq: 94\n"
     ]
    }
   ],
   "source": [
    "# compare each pair of voices!\n",
    "allthepatterns = []\n",
    "\n",
    "for i in range(0, len(voices)-1):\n",
    "    for j in range(i+1, len(voices)):\n",
    "        alignment_strings, simi_score = swm_alignment(strings[i], strings[j])\n",
    "        if simi_score < 0.25:\n",
    "            print(\"ignoring voice pair:\", i, j)\n",
    "            # if two voices are very different, getting patterns from their alignment won't make sense\n",
    "            continue\n",
    "        # get the patterns from the first voice of this pair\n",
    "        fullseq1 = alignment_strings[0]\n",
    "        fullseq2 = alignment_strings[1]\n",
    "        allthepatterns = filter_and_gather_patterns(allthepatterns, fullseq1)\n",
    "        allthepatterns = filter_and_gather_patterns(allthepatterns, fullseq2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf861fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "allthepattern_count = dict(Counter(allthepatterns))\n",
    "# elimiate the repeated strings\n",
    "\n",
    "allthepatterns = list(set(allthepatterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c01a5bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allthepatterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2922422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_strings(string):\n",
    "    \n",
    "    decode_dia_intervals = {'A': '6D', 'B': '5D', 'C': '4D', 'D': '3D', 'E': '2D', 'F': '1D', \n",
    "                            'G': '1A', 'H': '2A', 'I': '3A', 'J': '4A', 'K': '5A', 'L': '6A', 'M': '0A'}\n",
    "    \n",
    "    decode_string = \"\"\n",
    "\n",
    "    for letter in string:\n",
    "        trans = decode_dia_intervals[letter]\n",
    "        decode_string+=trans\n",
    "\n",
    "    return decode_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5d072e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printLCSSubStr(X: str, Y: str,\n",
    "                   m: int, n: int):\n",
    " \n",
    "    # Create a table to store lengths of longest common suffixes of substrings.\n",
    "    # Note that LCSuff[i][j] contains length of longest common suffix of X[0..i-1] and\n",
    "    # Y[0..j-1]. The first row and first column entries have no logical meaning,\n",
    "    # they are used only for simplicity of program\n",
    "    LCSuff = [[0 for i in range(n + 1)]\n",
    "                 for j in range(m + 1)]\n",
    " \n",
    "    # To store length of the\n",
    "    # longest common substring\n",
    "    length = 0\n",
    " \n",
    "    # To store the index of the cell\n",
    "    # which contains the maximum value.\n",
    "    # This cell's index helps in building\n",
    "    # up the longest common substring\n",
    "    # from right to left.\n",
    "    row, col = 0, 0\n",
    " \n",
    "    # Following steps build LCSuff[m+1][n+1]\n",
    "    # in bottom up fashion.\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if i == 0 or j == 0:\n",
    "                LCSuff[i][j] = 0\n",
    "            elif X[i - 1] == Y[j - 1]:\n",
    "                LCSuff[i][j] = LCSuff[i - 1][j - 1] + 1\n",
    "                if length < LCSuff[i][j]:\n",
    "                    length = LCSuff[i][j]\n",
    "                    row = i\n",
    "                    col = j\n",
    "            else:\n",
    "                LCSuff[i][j] = 0\n",
    " \n",
    "    # if true, then no common substring exists\n",
    "    if length == 0:\n",
    "        #print(\"No common substring\")\n",
    "        return \"\"\n",
    " \n",
    "    # allocate space for the longest\n",
    "    # common substring\n",
    "    resultStr = ['0'] * length\n",
    " \n",
    "    # traverse up diagonally form the\n",
    "    # (row, col) cell until LCSuff[row][col] != 0\n",
    "    while LCSuff[row][col] != 0:\n",
    "        length -= 1\n",
    "        resultStr[length] = X[row - 1] # or Y[col-1]\n",
    " \n",
    "        # move diagonally up to previous cell\n",
    "        row -= 1\n",
    "        col -= 1\n",
    " \n",
    "    # required longest common substring\n",
    "    return ''.join(resultStr) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "164a2096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_pattern_length(seq):\n",
    "        # the function returns the longest substring that appeared at least once\n",
    "        # if there is length 4 substring repeated 4 times and a length 7 substring repeated 2 times, we take the length 7\n",
    "        best_performance = \"\"\n",
    "        candidates = []\n",
    "        for length in range(int(0.3*len(seq)), int(len(seq)*0.5)+1): \n",
    "            for start in range(0, len(seq)-length):\n",
    "                # get all the substrings of this length within the string, save in candidates\n",
    "                candidates.append(seq[start:start+length])\n",
    "        count_can = {}\n",
    "        allthepattern_count = dict(Counter(allthepatterns))\n",
    "\n",
    "        for candidate in candidates:\n",
    "                count_can[candidate] = seq.count(candidate)\n",
    "                if count_can[candidate] > 1:\n",
    "                    # if it is repeated more than once in the string\n",
    "                    if len(candidate) > len(best_performance):\n",
    "                        best_performance = candidate\n",
    "                    elif len(candidate) == len(best_performance) and count_can[candidate] > count_can[best_performance]:\n",
    "                        best_performance = candidate\n",
    "        \n",
    "        return best_performance\n",
    "\n",
    "def check_reduction(item):\n",
    "    success = False\n",
    "    frequent_substr = reduce_pattern_length(item)\n",
    "    if len(frequent_substr) > 4 and len(frequent_substr) > 0.3*len(item):\n",
    "        print(\"extracted\", frequent_substr, \"from\", item)\n",
    "        # sucessfully reduced the pattern\n",
    "        return frequent_substr\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59573055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_length_of_each_pattern(patterns_to_reduce):\n",
    "    beforereduction = {}\n",
    "    # reducedfinalpat is the new list that contains all valid patterns after reduction plus the ones that does not need to be reduced\n",
    "    reducedfinalpat = []\n",
    "\n",
    "    for item in patterns_to_reduce:\n",
    "        # check the ones that has substring, see if their length can be reduced\n",
    "        if len(item) > 11:\n",
    "            #if the extracted pattern is too long, find longest repeated pattern within it\n",
    "            frequent_substr = check_reduction(item)\n",
    "            if frequent_substr != None:\n",
    "                if len(frequent_substr) > 23:\n",
    "                    # second attempt, if a frequent substring is takend and it is still quite long\n",
    "                    new_frequent_substr = check_reduction(frequent_substr)\n",
    "                    if new_frequent_substr != None:\n",
    "                        # if the second attempt is a success, take the twice reduced pattern\n",
    "                        reducedfinalpat.append(new_frequent_substr)\n",
    "                        beforereduction[new_frequent_substr] = item\n",
    "                    else:\n",
    "                        # if the second attempt failed, take the result of first reduction\n",
    "                        reducedfinalpat.append(frequent_substr)\n",
    "                        beforereduction[frequent_substr] = item\n",
    "                else:\n",
    "                    # if the extracted pattern is already not very long\n",
    "                    reducedfinalpat.append(frequent_substr)\n",
    "                    beforereduction[frequent_substr] = item\n",
    "            else:\n",
    "                # if the reduction failed, take the original\n",
    "                reducedfinalpat.append(item)\n",
    "        else:\n",
    "            # otherwise keep it without reduction\n",
    "            reducedfinalpat.append(item)\n",
    "    \n",
    "    return reducedfinalpat, beforereduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "415284e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted FGEGGG from IFGEGGGFGEGGGFGGFFFF\n",
      "extracted GEGGGF from GEGGGFGEGGGFGEGGG\n",
      "extracted FGEGGG from JKFGEGGGFGEGGGFG\n",
      "extracted MGFFG from GFFFFMMMGFFGBMGFFGH\n",
      "extracted GEGGGF from GEGGGFGEGGGFGEG\n",
      "extracted FGGEMFGGEM from HGHHFGGEMFGGEMFGGEMFGGEMMHDGFFBH\n",
      "extracted FGEGGG from ICHHEFGEGGGFGEGGGFGEG\n",
      "extracted FGGEMF from HGHHFGGEMFGGEMFGGEMF\n"
     ]
    }
   ],
   "source": [
    "reducedpat, beforereduction = reduce_length_of_each_pattern(allthepatterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa51fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_pattern_count = dict(Counter(reducedpat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "527abc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_final_pattern(reducedfinalpat, strings, beatstrengths):\n",
    "\n",
    "    count_pattern = {}\n",
    "    refined_finalpat = []\n",
    "    startonsets = []\n",
    "    startpitches = []\n",
    "    endonsets = []\n",
    "    endpitches = []\n",
    "\n",
    "    for pattern in reducedfinalpat:\n",
    "        stringnum = 0\n",
    "        beat_importance = 0\n",
    "        for string in strings:\n",
    "            # find the pattern in eachvoice\n",
    "            patpos_start, patpos_end, count, beatcount = find_pattern_pos(string, pattern, beatstrengths[stringnum])\n",
    "            beat_importance += beatcount\n",
    "            if pattern not in count_pattern:\n",
    "                count_pattern[pattern] = count\n",
    "            else:\n",
    "                count_pattern[pattern] += count\n",
    "            if count != 0:\n",
    "                print(\"Pattern\", pattern, \"appears in voice no.\", stringnum+1, \", first pos starts at \", patpos_start[0], \"end at\", patpos_end[0])\n",
    "            num = 0\n",
    "            for startpos in patpos_start:\n",
    "                startonsets.append(noteoffsets[stringnum][startpos])\n",
    "                endonsets.append(noteoffsets[stringnum][patpos_end[num]])\n",
    "                num+=1\n",
    "            stringnum+=1\n",
    "        if count_pattern[pattern] >= 2 and beat_importance >= 1:\n",
    "            # get rid of the ones that actually appeared less than 2 times in total\n",
    "            refined_finalpat.append(pattern)\n",
    "        else:\n",
    "            if count_pattern[pattern] < 2:\n",
    "                print(\"discard pattern\", pattern, \"because it only appered once in total.\")\n",
    "            elif beat_importance == 0:\n",
    "                print(\"discard pattern\", pattern, \"because it never appeared at the start of a bar.\")\n",
    "                print(\"this pattern can be decoded as\", decode_strings(pattern))\n",
    "            \n",
    "    return refined_finalpat, count_pattern, startonsets, endonsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "099c3a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DGDCJGEGEJEGEMHDGK': 1,\n",
       " 'GGFEHHIECFFHICDHFGEGGGFGEGGGFGEGGGEHHIHBFMEGGGFGEGGHGGDFGE': 1,\n",
       " 'GGFFGFFFGFFFGGFHAGMKG': 1,\n",
       " 'FGEGGG': 3,\n",
       " 'HMFHKFMMGHMAMLGAMKEBBIDIMHHGCFF': 1,\n",
       " 'ICGMIMMMLALAKB': 1,\n",
       " 'GEGGGF': 2,\n",
       " 'MHDG': 1,\n",
       " 'HHIBFJHALFBJFCFHEEFHFMKFGEGGGFGEGGGFG': 1,\n",
       " 'HHEF': 1,\n",
       " 'FBJFCFHEEFHFMHFGEGGGFGEGGGFGEGGGEHHIHBFMEGGGFGEGGHGGDFGE': 1,\n",
       " 'FFH': 1,\n",
       " 'FFBHDGDC': 1,\n",
       " 'HMBIHBIDIDIHFF': 1,\n",
       " 'FHEHFHMBIHBIDIDIHFFGGFFGFFFGFFFGGFHAGMKG': 1,\n",
       " 'HMAMLG': 1,\n",
       " 'GFFFFGG': 1,\n",
       " 'KEBBIDIGH': 1,\n",
       " 'BFJHAL': 1,\n",
       " 'MGFFG': 1,\n",
       " 'GGJFGEGGGFFGFFFGFFF': 1,\n",
       " 'FEHHIECFFHICHGEGEMDIDLFHMGEGEMDIDLFHMIJMMBGGIFFIBHDGLFBHDGHGEGEJEGEMHDGKFCH': 1,\n",
       " 'GHFFHFFHFFGGFFGFFFGFFFGGFHAG': 1,\n",
       " 'HMFHKFMM': 1,\n",
       " 'FGGEMFGGEM': 1,\n",
       " 'FFFGFFFGFFFCHHGCFFHICHHEFGEGGGFGEGGGF': 1,\n",
       " 'HFFGGFFGFFFGFFFGGFHAGMKG': 1,\n",
       " 'GGDGEICGMIMIHHGCFFH': 1,\n",
       " 'GGDGE': 1,\n",
       " 'FCHD': 1,\n",
       " 'GEMF': 1,\n",
       " 'FGGEMF': 1,\n",
       " 'GFFFFMJMLALAKBH': 1,\n",
       " 'FGEGGGFGEGG': 1,\n",
       " 'FFGGFFGFFFGFFFGGFHAG': 1,\n",
       " 'FGEGGGFFG': 1,\n",
       " 'GHFFH': 1,\n",
       " 'FEHHI': 1,\n",
       " 'HMF': 1,\n",
       " 'HFFGGFFGFFFGFFFGGFHAG': 1,\n",
       " 'GEM': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_pattern_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7df8d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcscount = {}\n",
    "dictoflcs = {}\n",
    "for i in range(0, len(reducedpat)-1):\n",
    "    for j in range(i+1, len(reducedpat)):\n",
    "        #print(i, j)\n",
    "        pat1 = reducedpat[i]\n",
    "        pat2 = reducedpat[j]\n",
    "        if len(pat1) > 11 and len(pat2) > 11 and pat1 != pat2:\n",
    "            lcs = printLCSSubStr(pat1, pat2, len(pat1), len(pat2))\n",
    "            if len(lcs) >= 4 and lcs != pat1 and lcs != pat2: \n",
    "                # if lcs is not one of themselves..\n",
    "                # 4 can change... I guess? but better not\n",
    "                if pat1 not in dictoflcs:\n",
    "                    dictoflcs[pat1] = []\n",
    "                if pat2 not in dictoflcs:\n",
    "                    dictoflcs[pat2] = []\n",
    "                dictoflcs[pat1].append(lcs)\n",
    "                dictoflcs[pat2].append(lcs)\n",
    "                if lcs in lcscount:\n",
    "                    lcscount[lcs] +=1\n",
    "                else:\n",
    "                    lcscount[lcs] = 1\n",
    "\n",
    "newdict = {}\n",
    "# print out the common strings that appeared more than 3 times\n",
    "for temp in lcscount:\n",
    "    if lcscount[temp] >= 2:\n",
    "        if temp not in reducedpat:\n",
    "            #print(\"new pattern:\")\n",
    "            newdict[temp] = lcscount[temp]\n",
    "        #print(temp, decode_strings(temp), lcscount[temp])\n",
    "\n",
    "# note to self: many of them are substring of themselves, take the longer or shorter?\n",
    "# take the shorter ones and elimiate the longer ones can be practical but can miss information..\n",
    "# only for the ones that are not reduceable? only between long strings? does it make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13a49f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist = list(newdict)\n",
    "\n",
    "listofrelated = {}\n",
    "for i in range(0, len(newlist)-1):\n",
    "    for j in range(i+1, len(newlist)):\n",
    "        if newlist[i] in newlist[j] or newlist[j] in newlist[i]:\n",
    "            if newlist[i] not in listofrelated:\n",
    "                listofrelated[newlist[i]] = []\n",
    "            if newlist[j] not in listofrelated:\n",
    "                listofrelated[newlist[j]] = []\n",
    "            listofrelated[newlist[i]].append(newlist[j])\n",
    "            listofrelated[newlist[j]].append(newlist[i])\n",
    "\n",
    "# recude one cluster into one\n",
    "final_lcs = []\n",
    "for candidate in newlist:\n",
    "    mostcounted = candidate\n",
    "    if candidate in listofrelated:\n",
    "        for related in listofrelated[candidate]:\n",
    "            if lcscount[related] > lcscount[mostcounted]:# and abs(len(related)-len(candidate)) <= 4:\n",
    "                # if it is counted more and not way too short or longer than the candidate\n",
    "                mostcounted = related\n",
    "            elif lcscount[related] == lcscount[mostcounted] and len(related) > len(mostcounted):# and abs(len(related)-len(candidate)) <= 4:\n",
    "                # or same count but longer\n",
    "                mostcounted = related\n",
    "    if mostcounted not in final_lcs:\n",
    "        final_lcs.append(mostcounted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa53f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pattern_pos(string, pattern, beatstrength):\n",
    "    patpos_start = []\n",
    "    patpos_end = []\n",
    "    count = 0\n",
    "    beatcount = 0\n",
    "    for m in re.finditer(pattern, string):\n",
    "        count +=1\n",
    "        if beatstrength[m.start()] == 1 or m.start() <= 8: # if it starts in the beginning of the score, exception\n",
    "            beatcount += 1\n",
    "        patpos_start.append(m.start())\n",
    "        patpos_end.append(m.end())\n",
    "    return patpos_start, patpos_end, count, beatcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2980dc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of LCS patterns, not filtered with beat strength\n",
    "\n",
    "#print(final_lcs)\n",
    "#for i in final_lcs:\n",
    "#    print(decode_strings(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acc3c838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern FGEGGGFGEGGGF appears in voice no. 1 , first pos starts at  257 end at 270\n",
      "Pattern FGEGGGFGEGGGF appears in voice no. 2 , first pos starts at  204 end at 217\n",
      "Pattern CFFH appears in voice no. 1 , first pos starts at  442 end at 446\n",
      "Pattern CFFH appears in voice no. 2 , first pos starts at  195 end at 199\n",
      "Pattern GFFF appears in voice no. 1 , first pos starts at  123 end at 127\n",
      "Pattern GFFF appears in voice no. 2 , first pos starts at  72 end at 76\n",
      "Pattern BIDI appears in voice no. 2 , first pos starts at  59 end at 63\n",
      "Pattern HHGCFF appears in voice no. 2 , first pos starts at  192 end at 198\n",
      "['FGEGGGFGEGGGF', 'CFFH', 'GFFF', 'BIDI', 'HHGCFF']\n"
     ]
    }
   ],
   "source": [
    "# this is filtered by beat strength:\n",
    "testpat, count_pattern_test, startonsetstest,  endonsetstest = count_final_pattern(final_lcs, strings, beatstrengths)\n",
    "print(testpat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acc204ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D1A2D1A1A1A1D1A2D1A1A1A1D\n",
      "4D1D1D2A\n",
      "1A1D1D1D\n",
      "5D3A3D3A\n",
      "2A2A1A4D1D1D\n"
     ]
    }
   ],
   "source": [
    "# PRINT OUT THE LCS PATTERNS FILTERED BY beat strength\n",
    "\n",
    "#print(testpat)\n",
    "lcsresults = []\n",
    "for i in testpat:\n",
    "    decoded_pat = decode_strings(i)\n",
    "    print(decoded_pat)\n",
    "    lcsresults.append(decoded_pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9194c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pattern in reducedpat:\n",
    "    if pattern in beforereduction:\n",
    "        # if it was reduced, then it at least appeared more than once in the original string, \n",
    "        # which should be extrac counted here\n",
    "        reduced_pattern_count[pattern] +=1\n",
    "        if pattern in allthepattern_count:\n",
    "            # if it was also originally a pattern\n",
    "            reduced_pattern_count[pattern]+=allthepattern_count[pattern]-1\n",
    "    else:\n",
    "        reduced_pattern_count[pattern]+=allthepattern_count[pattern]-1\n",
    "        # if it was not reduced, let's check if it was repeated at first, we should add them here minus the once that is counted already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01a18847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_substringandparents(allthepatterns, allthepattern_count):\n",
    "    \n",
    "    issubstring = {}\n",
    "    hassubstring = {}\n",
    "    count_as_substring = {}\n",
    "    count_as_parent = {}\n",
    "\n",
    "    for i in range(0, len(allthepatterns)-1):\n",
    "        for j in range(i+1, len(allthepatterns)):\n",
    "            if allthepatterns[i] in allthepatterns[j]:\n",
    "                parent = allthepatterns[j]\n",
    "                kid = allthepatterns[i]\n",
    "                times = parent.count(kid)\n",
    "\n",
    "                if kid not in issubstring:\n",
    "                    issubstring[kid] = 1\n",
    "                    count_as_substring[kid] = times * allthepattern_count[parent]\n",
    "                else:\n",
    "                    issubstring[kid] += 1\n",
    "                    count_as_substring[kid] += times * allthepattern_count[parent]\n",
    "\n",
    "                if parent not in hassubstring:\n",
    "                    hassubstring[parent] = 1\n",
    "                    count_as_parent[parent] = 1#times\n",
    "                else:\n",
    "                    hassubstring[parent] += 1\n",
    "                    count_as_parent[parent] += 1 \n",
    "\n",
    "            elif allthepatterns[j] in allthepatterns[i]:\n",
    "                parent = allthepatterns[i]\n",
    "                kid = allthepatterns[j]\n",
    "                times = parent.count(kid)\n",
    "\n",
    "                if kid not in issubstring:\n",
    "                    issubstring[kid] =1\n",
    "                    count_as_substring[kid] = times * allthepattern_count[parent]\n",
    "                else:\n",
    "                    issubstring[kid] += 1\n",
    "                    count_as_substring[kid] += times * allthepattern_count[parent]\n",
    "\n",
    "                if parent not in hassubstring:\n",
    "                    hassubstring[parent] = 1\n",
    "                    count_as_parent[parent] = 1 #times\n",
    "                else:\n",
    "                    hassubstring[parent] += 1\n",
    "                    count_as_parent[parent] += 1 #times\n",
    "\n",
    "    return issubstring, hassubstring, count_as_substring, count_as_parent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f7546d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "issubstring, hassubstring, count_as_substring, count_as_parent = count_substringandparents(reducedpat, reduced_pattern_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2695cea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# rank the ones that are substrings of another detected pattern\n",
    "sortis = dict(Counter(issubstring))\n",
    "sorthas = dict(Counter(hassubstring))\n",
    "print(len(sorthas))\n",
    "print(len(sortis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7579ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This counts the times each pattern appeared after original segmentation plus the times they are in other patterns,\n",
    "# plus the times other patterns showed up in them.\n",
    "\n",
    "def combined_count(reducedpat, count_as_parent, count_as_substring, reduced_pattern_count):\n",
    "    refined_combined = {}\n",
    "\n",
    "    for item in reducedpat:\n",
    "        refined_combined[item] = reduced_pattern_count[item]\n",
    "        if item in count_as_parent:\n",
    "            refined_combined[item] += count_as_parent[item]\n",
    "        if item in count_as_substring:\n",
    "            refined_combined[item] += count_as_substring[item]\n",
    "    \n",
    "    return refined_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a213b4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined_count(reducedpat, count_as_parent, count_as_substring, reduced_pattern_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9b810d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ed173cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_combined_patterns(combined):\n",
    "    \n",
    "    finalpattern = []\n",
    "    for i in combined: \n",
    "\n",
    "        if len(i) < 3:\n",
    "            # if the length is shorter than 4 notes, discard\n",
    "            continue\n",
    "\n",
    "        if combined[i] > 1:\n",
    "            # keep the ones that has substring or is substring or repeated more than once\n",
    "            finalpattern.append(i)\n",
    "\n",
    "    finalpattern_combined = {}\n",
    "        \n",
    "    for thisone in finalpattern:\n",
    "        finalpattern_combined[thisone] = combined[thisone]\n",
    "\n",
    "    dict(Counter(finalpattern_combined))\n",
    "        \n",
    "    if len(finalpattern) > 20:\n",
    "        # if more than 30 patterns, only take the top 30\n",
    "        finalpattern_combined = dict(sorted(finalpattern_combined.items(), key = lambda x:-x[1], reverse = True)[-20:])\n",
    "    \n",
    "    return finalpattern_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4be71143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the short ones\n",
    "top20patterns_combined = filter_combined_patterns(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d8ef126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dict(Counter(top20patterns_combined)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17194f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not filtered by beat strength, top 20\n",
    "#for printpattern in list(top20patterns_combined):\n",
    "#    print(decode_strings(printpattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42b4c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"the followings are not ranked well thus discarded in the count\")\n",
    "#for i in reducedpat:\n",
    "#    if i not in top20patterns_combined:\n",
    "#        print(decode_strings(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d10503af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern FEHHIECFFHICHGEGEMDIDLFHMGEGEMDIDLFHMIJMMBGGIFFIBHDGLFBHDGHGEGEJEGEMHDGKFCH appears in voice no. 1 , first pos starts at  537 end at 612\n",
      "discard pattern FEHHIECFFHICHGEGEMDIDLFHMGEGEMDIDLFHMIJMMBGGIFFIBHDGLFBHDGHGEGEJEGEMHDGKFCH because it only appered once in total.\n",
      "Pattern GHFFHFFHFFGGFFGFFFGFFFGGFHAG appears in voice no. 1 , first pos starts at  109 end at 137\n",
      "discard pattern GHFFHFFHFFGGFFGFFFGFFFGGFHAG because it never appeared at the start of a bar.\n",
      "this pattern can be decoded as 1A2A1D1D2A1D1D2A1D1D1A1A1D1D1A1D1D1D1A1D1D1D1A1A1D2A6D1A\n",
      "Pattern FGGEMFGGEM appears in voice no. 1 , first pos starts at  141 end at 151\n",
      "discard pattern FGGEMFGGEM because it never appeared at the start of a bar.\n",
      "this pattern can be decoded as 1D1A1A2D0A1D1A1A2D0A\n",
      "Pattern HFFGGFFGFFFGFFFGGFHAGMKG appears in voice no. 2 , first pos starts at  65 end at 89\n",
      "Pattern FFGGFFGFFFGFFFGGFHAG appears in voice no. 1 , first pos starts at  117 end at 137\n",
      "Pattern FFGGFFGFFFGFFFGGFHAG appears in voice no. 2 , first pos starts at  66 end at 86\n",
      "discard pattern FFGGFFGFFFGFFFGGFHAG because it never appeared at the start of a bar.\n",
      "this pattern can be decoded as 1D1D1A1A1D1D1A1D1D1D1A1D1D1D1A1A1D2A6D1A\n",
      "Pattern HFFGGFFGFFFGFFFGGFHAG appears in voice no. 1 , first pos starts at  116 end at 137\n",
      "Pattern HFFGGFFGFFFGFFFGGFHAG appears in voice no. 2 , first pos starts at  65 end at 86\n",
      "Pattern FHEHFHMBIHBIDIDIHFFGGFFGFFFGFFFGGFHAGMKG appears in voice no. 2 , first pos starts at  49 end at 89\n",
      "discard pattern FHEHFHMBIHBIDIDIHFFGGFFGFFFGFFFGGFHAGMKG because it never appeared at the start of a bar.\n",
      "this pattern can be decoded as 1D2A2D2A1D2A0A5D3A2A5D3A3D3A3D3A2A1D1D1A1A1D1D1A1D1D1D1A1D1D1D1A1A1D2A6D1A0A5A1A\n",
      "Pattern FGGEMF appears in voice no. 1 , first pos starts at  141 end at 147\n",
      "discard pattern FGGEMF because it never appeared at the start of a bar.\n",
      "this pattern can be decoded as 1D1A1A2D0A1D\n",
      "Pattern FBJFCFHEEFHFMHFGEGGGFGEGGGFGEGGGEHHIHBFMEGGGFGEGGHGGDFGE appears in voice no. 1 , first pos starts at  335 end at 391\n",
      "discard pattern FBJFCFHEEFHFMHFGEGGGFGEGGGFGEGGGEHHIHBFMEGGGFGEGGHGGDFGE because it only appered once in total.\n",
      "Pattern HHIBFJHALFBJFCFHEEFHFMKFGEGGGFGEGGGFG appears in voice no. 1 , first pos starts at  280 end at 317\n",
      "discard pattern HHIBFJHALFBJFCFHEEFHFMKFGEGGGFGEGGGFG because it only appered once in total.\n",
      "Pattern GGJFGEGGGFFGFFFGFFF appears in voice no. 1 , first pos starts at  391 end at 410\n",
      "discard pattern GGJFGEGGGFFGFFFGFFF because it never appeared at the start of a bar.\n",
      "this pattern can be decoded as 1A1A4A1D1A2D1A1A1A1D1D1A1D1D1D1A1D1D1D\n",
      "Pattern GEMF appears in voice no. 1 , first pos starts at  143 end at 147\n",
      "Pattern GEMF appears in voice no. 2 , first pos starts at  91 end at 95\n",
      "Pattern GGFEHHIECFFHICDHFGEGGGFGEGGGFGEGGGEHHIHBFMEGGGFGEGGHGGDFGE appears in voice no. 1 , first pos starts at  434 end at 492\n",
      "discard pattern GGFEHHIECFFHICDHFGEGGGFGEGGGFGEGGGEHHIHBFMEGGGFGEGGHGGDFGE because it only appered once in total.\n",
      "Pattern FFH appears in voice no. 1 , first pos starts at  111 end at 114\n",
      "Pattern FFH appears in voice no. 2 , first pos starts at  196 end at 199\n",
      "discard pattern FFH because it never appeared at the start of a bar.\n",
      "this pattern can be decoded as 1D1D2A\n",
      "Pattern FGEGGGFFG appears in voice no. 1 , first pos starts at  394 end at 403\n",
      "Pattern FGEGGGFFG appears in voice no. 2 , first pos starts at  310 end at 319\n",
      "Pattern FFFGFFFGFFFCHHGCFFHICHHEFGEGGGFGEGGGF appears in voice no. 2 , first pos starts at  319 end at 356\n",
      "discard pattern FFFGFFFGFFFCHHGCFFHICHHEFGEGGGFGEGGGF because it never appeared at the start of a bar.\n",
      "this pattern can be decoded as 1D1D1D1A1D1D1D1A1D1D1D4D2A2A1A4D1D1D2A3A4D2A2A2D1D1A2D1A1A1A1D1A2D1A1A1A1D\n",
      "Pattern FGEGGGFGEGG appears in voice no. 1 , first pos starts at  257 end at 268\n",
      "Pattern FGEGGGFGEGG appears in voice no. 2 , first pos starts at  204 end at 215\n",
      "Pattern GEM appears in voice no. 1 , first pos starts at  2 end at 5\n",
      "Pattern GEM appears in voice no. 2 , first pos starts at  88 end at 91\n",
      "Pattern GEGGGF appears in voice no. 1 , first pos starts at  258 end at 264\n",
      "Pattern GEGGGF appears in voice no. 2 , first pos starts at  205 end at 211\n",
      "discard pattern GEGGGF because it never appeared at the start of a bar.\n",
      "this pattern can be decoded as 1A2D1A1A1A1D\n",
      "Pattern FGEGGG appears in voice no. 1 , first pos starts at  257 end at 263\n",
      "Pattern FGEGGG appears in voice no. 2 , first pos starts at  204 end at 210\n"
     ]
    }
   ],
   "source": [
    "#finalpat, count_pattern, startonsets,  endonsets = count_final_pattern(reducedfinalpat, strings, beatstrengths)\n",
    "\n",
    "finalpat, count_pattern, startonsets,  endonsets = count_final_pattern(list(top20patterns_combined), strings, beatstrengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2aacc75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_results(finalpat, count_pattern, combined, beforereduction):\n",
    "    \n",
    "    decoded_patterns = []\n",
    "    decoded_patterns_weighed = {}\n",
    "    decoded_patterns_count = {}\n",
    "    decoded_patterns_combined = {}\n",
    "    \n",
    "    decode_dia_intervals = {'A': '6D', 'B': '5D', 'C': '4D', 'D': '3D', 'E': '2D', 'F': '1D', \n",
    "                            'G': '1A', 'H': '2A', 'I': '3A', 'J': '4A', 'K': '5A', 'L': '6A', 'M': '0A'}\n",
    "\n",
    "    # decode all the candidates for patterns\n",
    "    for pattern in finalpat:\n",
    "        trans_pattern = \"\"\n",
    "        for letter in pattern:\n",
    "            trans = decode_dia_intervals[letter]\n",
    "            trans_pattern += trans\n",
    "\n",
    "        decoded_patterns_count[trans_pattern] = count_pattern[pattern]\n",
    "        \n",
    "        if pattern in combined:\n",
    "            # some might be reduced to a shorter pattern\n",
    "            decoded_patterns_combined[trans_pattern] = combined[pattern]\n",
    "        else:\n",
    "            decoded_patterns_combined[trans_pattern] = combined[beforereduction[pattern]]\n",
    "        decoded_patterns.append(trans_pattern)\n",
    "        \n",
    "    return decoded_patterns, decoded_patterns_combined, decoded_patterns_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d1bacd",
   "metadata": {},
   "source": [
    "Strings of intervals of each voice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52f91910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1A2D1A2D0A3D3A3D6A1D2A0A1A2D1A2D0A3D3A3D6A1D2A0A3A4A0A0A5D1A1A3A1D1D3A5D2A3D1A6A1D5D2A3D1A0A1A2D1A2D0A3D3A3D6A1D2A0A1A2D1A2D0A3D3A3D6A1D2A0A3A4A0A0A5D1A1A3A1D1D3A5D2A3D1A6A1D5D2A3D1A2A1A2D1A2D4A2D1A2D0A2A3D1A5A1D4D2A3D1A2A1D1D2A1D1D2A1D1D1A1A1D1D1A1D1D1D1A1D1D1D1A1A1D2A6D1A2A1A2A2A1D1A1A2D0A1D1A1A2D0A1D1A1A2D0A1D1A1A2D0A0A2A3D1A1D1D5D2A3D1A3D4D4A1A2D1A2D4A2D1A2D0A2A3D1A5A1D4D2A3D1A2A1D1D2A1D1D2A1D1D1A1A1D1D1A1D1D1D1A1D1D1D1A1A1D2A6D1A2A1A2A2A1D1A1A2D0A1D1A1A2D0A1D1A1A2D0A1D1A1A2D0A0A2A3D1A1D1D5D2A3D1A3D4D4A5A1D1A2D1A1A1A1D1A2D1A1A1A1D1A1A1D1D1D1D1A1A1D2D2A2A3A5D1D4A2A6D6A1D5D4A1D4D1D2A2D2D1D2A1D0A5A1D1A2D1A1A1A1D1A2D1A1A1A1D1A1A1D1D1D1D1A1A1D2D2A2A3A5D1D4A2A6D6A1D5D4A1D4D1D2A2D2D1D2A1D0A2A1D1A2D1A1A1A1D1A2D1A1A1A1D1A2D1A1A1A2D2A2A3A2A5D1D0A2D1A1A1A1D1A2D1A1A2A1A1A3D1D1A2D1A1A4A1D1A2D1A1A1A1D1D1A1D1D1D1A1D1D1D1A1D1D4D3A1D1A2D1A1A1A1D1A2D1A1A1A1D1A1A1D1D1D1D1A1A1D2D2A2A3A2D4D1D1D2A3A4D3D2A1D1A2D1A1A1A1D1A2D1A1A1A1D1A2D1A1A1A2D2A2A3A2A5D1D0A2D1A1A1A1D1A2D1A1A2A1A1A3D1D1A2D1A1A4A1D1A2D1A1A1A1D1D1A1D1D1D1A1D1D1D1A1D1D4D3A1D1A2D1A1A1A1D1A2D1A1A1A1D1A1A1D1D1D1D1A1A1D2D2A2A3A2D4D1D1D2A3A4D2A1A2D1A2D0A3D3A3D6A1D2A0A1A2D1A2D0A3D3A3D6A1D2A0A3A4A0A0A5D1A1A3A1D1D3A5D2A3D1A6A1D5D2A3D1A2A1A2D1A2D4A2D1A2D0A2A3D1A5A1D4D2A3D1A2A1D1D2A1D1D2A1D1D1A1A1D1D1A1D1D1D1A1D1D1D1A1A1D2A6D1A2A1A2A2A1D1A1A2D0A1D1A1A2D0A1D1A1A2D0A1D1A1A2D0A0A2A3D1A1D1D5D2A3D1A3D4D\n",
      "\n",
      "0A1A1D1D1A5D0A1A1D1D1A2A1D1D1D1A1A1A5D3A2A5D3A2D0A1A1D1D1A5D0A1A1D1D1A2A1D1D1D1A1A1A5D3A2A5D3A1D2A1D2A2D2A1D2A0A5D3A2A5D3A3D3A3D3A2A1D1D1A1A1D1D1A1D1D1D1A1D1D1D1A1A1D2A6D1A0A5A1A2D0A1A2D0A1D2A0A1D2A5A1D0A0A1A2A0A6D0A6A1A6D0A5A2D5D5D3A3D3A1A2A1D2A2D2A1D2A0A5D3A2A5D3A3D3A3D3A2A1D1D1A1A1D1D1A1D1D1D1A1D1D1D1A1A1D2A6D1A0A5A1A2D0A1A2D0A1D2A0A1D2A5A1D0A0A1A2A0A6D0A6A1A6D0A5A2D5D5D3A3D3A0A2A2A1A4D1D1D2A3A4D2A2A2D1D1A2D1A1A1A1D1A2D1A1A1A1D1A2D1A1A1A3D1A2D3A4D1A0A3A0A3A2A2A1A4D1D1D2A3A4D2A2A2D1D1A2D1A1A1A1D1A2D1A1A1A1D1A2D1A1A1A3D1A2D3A4D1A0A3A0A0A0A6A6D6A6D5A5D2A1D1A2D1A1A1A1D1A2D1A1A1A1D1A2D1A1A1A1D1A2D1A1A1A1D1A2D1A1A1A1D1A2D1A1A1A1D1D1A1D1D1D1A1D1D1D1A1D1D1D4D2A2A1A4D1D1D2A3A4D2A2A2D1D1A2D1A1A1A1D1A2D1A1A1A1D1A1D1D1D1D0A4A0A6A6D6A6D5A5D2A1D1A2D1A1A1A1D1A2D1A1A1A1D1A2D1A1A1A1D1A2D1A1A1A1D1A2D1A1A1A1D1A2D1A1A1A1D1D1A1D1D1D1A1D1D1D1A1D1D1D4D2A2A1A4D1D1D2A3A4D2A2A2D1D1A2D1A1A1A1D1A2D1A1A1A1D1A1D1D1D1D0A0A0A1A1D1D1A5D0A1A1D1D1A2A1D1D1D1A1A1A5D3A2A5D3A1D2A1D2A2D2A1D2A0A5D3A2A5D3A3D3A3D3A2A1D1D1A1A1D1D1A1D1D1D1A1D1D1D1A1A1D2A6D1A0A5A1A2D0A1A2D0A1D2A0A1D2A5A1D0A0A1A2A0A6D0A6A1A6D0A5A2D5D5D3A3D3A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Strings of intervals of each voice\n",
    "decoded_strings = []\n",
    "for string in strings:\n",
    "    decoded = decode_strings(string)\n",
    "    decoded_strings.append(decoded)\n",
    "    print(decoded)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3811e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern: 2A1D1D1A1A1D1D1A1D1D1D1A1D1D1D1A1A1D2A6D1A0A5A1A\n",
      "importance score: 5 occurrence: 3\n",
      "Pattern: 2A1D1D1A1A1D1D1A1D1D1D1A1D1D1D1A1A1D2A6D1A\n",
      "importance score: 5 occurrence: 6\n",
      "Pattern: 1A2D0A1D\n",
      "importance score: 8 occurrence: 12\n",
      "Pattern: 1D1A2D1A1A1A1D1D1A\n",
      "importance score: 9 occurrence: 4\n",
      "Pattern: 1D1A2D1A1A1A1D1A2D1A1A\n",
      "importance score: 12 occurrence: 16\n",
      "Pattern: 1A2D0A\n",
      "importance score: 14 occurrence: 27\n",
      "Pattern: 1D1A2D1A1A1A\n",
      "importance score: 81 occurrence: 38\n"
     ]
    }
   ],
   "source": [
    "# Decode patterns\n",
    "decoded_patterns, decoded_patterns_combined, decoded_patterns_count = decode_results(finalpat, count_pattern, combined, beforereduction)\n",
    "\n",
    "for pattern in decoded_patterns:\n",
    "        print(\"Pattern:\", pattern)\n",
    "        print(\"importance score:\", decoded_patterns_combined[pattern],\n",
    "              \"occurrence:\", decoded_patterns_count[pattern])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01510636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2A1D1D1A1A1D1D1A1D1D1D1A1D1D1D1A1A1D2A6D1A0A5A1A',\n",
       " '2A1D1D1A1A1D1D1A1D1D1D1A1D1D1D1A1A1D2A6D1A',\n",
       " '1A2D0A1D',\n",
       " '1D1A2D1A1A1A1D1D1A',\n",
       " '1D1A2D1A1A1A1D1A2D1A1A',\n",
       " '1A2D0A',\n",
       " '1D1A2D1A1A1A']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final patterns(LCS not included), FILTERED BY BEAT STRENGTH:\n",
    "decoded_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b94f045a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2A1D1D1A1A1D1D1A1D1D1D1A1D1D1D1A1A1D2A6D1A0A5A1A', '2A1D1D1A1A1D1D1A1D1D1D1A1D1D1D1A1A1D2A6D1A', '1A2D0A1D', '1D1A2D1A1A1A1D1D1A', '1D1A2D1A1A1A1D1A2D1A1A', '1A2D0A', '1D1A2D1A1A1A', '1D1A2D1A1A1A1D1A2D1A1A1A1D', '4D1D1D2A', '1A1D1D1D', '5D3A3D3A', '2A2A1A4D1D1D']\n"
     ]
    }
   ],
   "source": [
    "# THE FINAL LIST\n",
    "final_results = decoded_patterns+lcsresults\n",
    "\n",
    "print(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7ba74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43819f65",
   "metadata": {},
   "source": [
    "Danny's version, ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5dfb1b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jkupddtest/gibbonsmono/H/midi/occ1.midi_part1_DD.csv', 'jkupddtest/gibbonsmono/H/midi/occ2.midi_part1_DD.csv']\n",
      "jkupddtest/gibbonsmono/H/midi/occ1.midi_part1_DD.csv\n",
      "0A1D1D1D1D0A7A1D1D4D3A1D1A2D1A3D1A0A4D\n",
      "jkupddtest/gibbonsmono/H/midi/occ2.midi_part1_DD.csv\n",
      "0A1D1D1D1D0A7A1D1D4D3A1D1A2D1A3D1A0A4D\n"
     ]
    }
   ],
   "source": [
    "#groundtruthpath1 = \"jkupddtest/gibbonsmono/silverswan.krn\"\n",
    "import pandas as pd\n",
    "gtfiles = glob.glob(\"jkupddtest/gibbonsmono/H/midi/*.csv\")\n",
    "print(gtfiles)\n",
    "gtstrings = []\n",
    "for gtfile in gtfiles:\n",
    "    print(gtfile)\n",
    "    with open(gtfile, 'r') as file:\n",
    "        df = pd.read_csv(file)\n",
    "        #print(df)\n",
    "        #for midi_note_num in df[\"midi_note_num\"]:\n",
    "        #    print(midi_note_num)\n",
    "        count = 0\n",
    "        gtstring = \"\"\n",
    "        for diatonic in df[\"diatonic_interval\"]:\n",
    "            if count == 0:\n",
    "                # ignore the first \"interval\" number which is always 0\n",
    "                count+=1\n",
    "                continue\n",
    "            count+=1\n",
    "            # just to format the input\n",
    "            if diatonic < 0:\n",
    "                dia = str(abs(diatonic)) + 'D'\n",
    "            else:\n",
    "                dia = str(abs(diatonic)) + 'A'\n",
    "            gtstring += dia\n",
    "        gtstrings.append(gtstring)\n",
    "        print(gtstring)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec20cf94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0A1D1D1D1D0A7A1D1D4D3A1D1A2D1A3D1A0A4D'}\n"
     ]
    }
   ],
   "source": [
    "# a set of strings of annotated ground truth\n",
    "print(set(gtstrings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e0df0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern 0A1D1D1D1D0A7A1D1D4D3A1D1A2D1A3D1A0A4D not in original score\n",
      "pattern 0A1D1D1D1D0A7A1D1D4D3A1D1A2D1A3D1A0A4D not in original score\n"
     ]
    }
   ],
   "source": [
    "# check if they are in the scores\n",
    "for pattern in gtstrings:\n",
    "    count = 0\n",
    "    for decodedstring in decoded_strings:\n",
    "        count += decodedstring.count(pattern)\n",
    "    if count == 0:\n",
    "        print(\"pattern\", pattern, \"not in original score\")\n",
    "    elif count == 1:\n",
    "        print(\"pattern\", pattern, \"only appeared once\")\n",
    "    else:\n",
    "        print(\"pattern\", pattern, \"appeared\", count, \"times in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e070111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee6b243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "befb9cda",
   "metadata": {},
   "source": [
    "Discarded: get patterns from ground truth folders.. original ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "31669153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jkupddtest/chopinmono/D', 'jkupddtest/chopinmono/A', 'jkupddtest/chopinmono/mazurka24-4.krn']\n"
     ]
    }
   ],
   "source": [
    "# Get patterns from ground truth\n",
    "\n",
    "dict_wordtonum = {\"Unison\": '0', \"Second\": '1', \"Third\": '2', \"Fourth\": '3', \"Fifth\": '4', \"Sixth\": '5', \"Seventh\": '6'}\n",
    "\n",
    "groundtruthpatterns = []\n",
    "print(glob.glob(\"jkupddtest/chopinmono/*\"))\n",
    "filenames = glob.glob(\"jkupddtest/chopinmono/B/*.csv\")\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    with open(filename, 'r') as file:\n",
    "        csvreader = csv.reader(file)\n",
    "        gts = []\n",
    "        gtm = []\n",
    "        pattern_gt = []\n",
    "        for row in csvreader:\n",
    "            gts.append(float(row[0]))\n",
    "            gtm.append(float(row[1]))\n",
    "        for i in gtm:\n",
    "            pattern_gt.append(m21.note.Note(i))\n",
    "        pattern_string = \"\"\n",
    "        interval_string = \"\"\n",
    "        for i in pattern_gt:\n",
    "            pattern_string += str(i)\n",
    "            \n",
    "        for i in range(1, len(pattern_gt)):           \n",
    "            gap = pattern_gt[i].pitch.diatonicNoteNum - pattern_gt[i-1].pitch.diatonicNoteNum\n",
    "            if gap >= 0:\n",
    "                direction = 'A'\n",
    "            else:\n",
    "                direction = 'D'\n",
    "            m21_interval_directed = m21.interval.Interval(noteStart=pattern_gt[i-1], noteEnd=pattern_gt[i]).directedSimpleNiceName\n",
    "            arr_diatonic = m21_interval_directed.split(\" \")\n",
    "            m21_generic = dict_wordtonum[arr_diatonic[-1]]\n",
    "            m21_interval = m21_generic+direction\n",
    "            \n",
    "            interval_string+=m21_interval\n",
    "            \n",
    "        print(interval_string)\n",
    "\n",
    "        groundtruthpatterns.append(interval_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f292cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(groundtruthpatterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b761cec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pattern in groundtruthpatterns:\n",
    "    count = 0\n",
    "    for decodedstring in decoded_strings:\n",
    "        count += decodedstring.count(pattern)\n",
    "    if count == 0:\n",
    "        print(\"pattern\", pattern, \"not in original score\")\n",
    "    elif count == 1:\n",
    "        print(\"pattern\", pattern, \"only appeared once\")\n",
    "    else:\n",
    "        print(\"pattern\", pattern, \"appeared\", count, \"times in total\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
